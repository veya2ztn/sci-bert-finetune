{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28f65b08",
   "metadata": {},
   "source": [
    "### Unsupervise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b960c9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tasks.dense_retriever.zero_shot_training.train_data_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7275d6b7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Supervised Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0955aec2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    return {'num_layers': 24, 'num_unique_layers': None, 'param_sharing_style': 'grouped', 'hidden_size': 1024, 'ffn_hidden_size': 4096, 'num_attention_heads': 16, 'kv_channels': 64, 'max_position_embeddings': 512, 'make_vocab_size_divisible_by': 128, 'layernorm_epsilon': 1e-05, 'apply_residual_connection_post_layernorm': False, 'openai_gelu': False, 'onnx_safe': None, 'attention_dropout': 0.1, 'hidden_dropout': 0.1, 'weight_decay': 0.1, 'clip_grad': 1.0, 'find_unused_parameters': False, 'batch_size': 2, 'checkpoint_activations': False, 'distribute_checkpointed_activations': False, 'checkpoint_num_layers': 1, 'train_iters': None, 'log_interval': 20, 'exit_interval': None, 'tensorboard_dir': None, 'scaled_upper_triang_masked_softmax_fusion': False, 'scaled_masked_softmax_fusion': False, 'bias_gelu_fusion': False, 'bias_dropout_fusion': False, 'seed': 1234, 'init_method_std': 0.02, 'lr': 2e-05, 'lr_decay_style': 'linear', 'lr_decay_iters': None, 'min_lr': 0.0, 'warmup': 0.01, 'override_lr_scheduler': False, 'use_checkpoint_lr_scheduler': False, 'save': './checkpoints/dualencoder-mss-dpr-large-epochs20-webq', 'save_interval': 5000, 'no_save_optim': False, 'no_save_rng': False, 'load': './checkpoints/dualencoder-mss-dpr-large-epochs20-webq', 'no_load_optim': False, 'no_load_rng': False, 'finetune': False, 'fp16': True, 'apply_query_key_layer_scaling': False, 'attention_softmax_in_fp32': False, 'fp32_allreduce': False, 'hysteresis': 2, 'loss_scale': None, 'loss_scale_window': 1000, 'min_scale': 1, 'fp16_lm_cross_entropy': False, 'model_parallel_size': 1, 'distributed_backend': 'nccl', 'DDP_impl': 'torch', 'local_rank': None, 'lazy_mpu_init': None, 'use_cpu_initialization': False, 'eval_iters': 100, 'eval_interval': 500, 'data_path': None, 'glob': False, 'qa_file_dev': './data/qas/webq-dev.csv', 'qa_file_test': './data/qas/webq-test.csv', 'qa_file_train': None, 'split': '969, 30, 1', 'vocab_file': './bert-vocab/bert-large-uncased-vocab.txt', 'merge_file': None, 'vocab_extra_ids': 0, 'seq_length': 512, 'encoder_seq_length': 512, 'decoder_seq_length': None, 'seq_length_retriever': 256, 'sample_rate': 1.0, 'mask_prob': 0.15, 'short_seq_prob': 0.1, 'mmap_warmup': False, 'num_workers': 2, 'tokenizer_type': 'BertWordPieceLowerCase', 'data_impl': 'infer', 'reset_position_ids': False, 'reset_attention_mask': False, 'eod_mask_loss': False, 'bert_load': './checkpoints/megatron_bert_345m/release/mp_rank_00/model_optim_rng.pt', 'pretrained_dualencoder_load': None, 'evidence_data_path': './data/wikipedia-split/psgs_w100.tsv', 'indexed_evidence_bert_tokenized_data_path': 'data/evidence-wikipedia-indexed-mmap/wikipedia-evidence_text_document', 'indexed_title_bert_tokenized_data_path': 'data/evidence-wikipedia-indexed-mmap/wikipedia-evidence_title_document', 'indexed_evidence_t0_tokenized_data_path': 'data/evidence-wikipedia-indexed-mmap/t0/wikipedia-evidence-t0_text_document', 'indexed_title_t0_tokenized_data_path': 'data/evidence-wikipedia-indexed-mmap/t0/wikipedia-evidence-t0_title_document', 'log_interval_input_data': 100000, 'report_topk_accuracies': [1, 5, 10, 20, 50, 100], 'retriever_score_scaling': True, 'inverse_temperature_multiplier': 1.0, 'art_training': False, 'no_context_embedder_training': False, 'no_query_embedder_training': False, 'disable_retriever_dropout': False, 'index_reload_interval': 500, 'max_training_rank': 1, 'update_retriever': False, 'hf_model_name': 'bigscience/T0_3B', 'verbalizer': ' . Please write a question based on this passage.', 'verbalizer_head': 'Passage: ', 'shard_size': 16, 'initialize_t0_model_tokenizer_evidence': False, 't0_model_in_bf16': False, 'compute_fresh_evidence_embeddings': False, 'faiss_use_gpu': True, 'embedding_path': './embedding-path/psgs_w100-dualencoder-mss-dpr-large-epochs20-webq.pkl', 'match': 'string', 'topk_retrievals': 100, 'save_topk_outputs_path': None, 'indexer_batch_size': 128, 'indexer_log_interval': 1000, 'allow_trivial_doc': False, 'run_indexer': False, 'trec_eval': False, 'task': 'RETRIEVER', 'epochs': 20, 'pretrained_checkpoint': None, 'keep_last': False, 'train_with_neg': True, 'train_data': ['./data/webq/biencoder-webquestions-train.json'], 'valid_data': ['./data/webq/biencoder-webquestions-dev.json'], 'eval_batch_size': 16, 'seq_length_ret': 256, 'train_hard_neg': 7, 'val_av_rank_hard_neg': 5, 'val_av_rank_other_neg': 5, 'rank': 0, 'world_size': 1, 'dynamic_loss_scale': True, 'params_dtype': torch.float16, 'padded_vocab_size': 30592}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240c3f39",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### modify the dataset for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31e17ede",
   "metadata": {
    "code_folding": [
     0,
     35,
     82,
     88
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class OpenRetrievalAbstractDataset(Dataset):\n",
    "    \"\"\"Open Retrieval base dataset class.\"\"\"\n",
    "\n",
    "    def __init__(self, task_name, dataset_name, datapaths, tokenizer, max_seq_length, evaluate=False,args=None):\n",
    "        # Store inputs.\n",
    "        self.args = args\n",
    "        self.evaluate = evaluate\n",
    "        self.val_av_rank_hard_neg = args.val_av_rank_hard_neg\n",
    "        self.val_av_rank_other_neg = args.val_av_rank_other_neg\n",
    "        self.train_with_neg = args.train_with_neg\n",
    "        self.train_hard_neg = args.train_hard_neg\n",
    "\n",
    "        self.task_name = task_name\n",
    "        self.dataset_name = dataset_name\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "        print_rank_0(' > building {} dataset for {}:'.format(self.task_name,\n",
    "                                                             self.dataset_name))\n",
    "        # Process the files.\n",
    "        string = '  > paths:'\n",
    "        for path in datapaths:\n",
    "            string += ' ' + path\n",
    "        print_rank_0(string)\n",
    "        self.samples = []\n",
    "        for datapath in datapaths:\n",
    "            self.samples.extend(self.process_samples_from_single_path(datapath))\n",
    "\n",
    "        \n",
    "        if args.sample_rate < 1:  # subsample\n",
    "            k = int(len(self.samples) * args.sample_rate)\n",
    "            self.samples = random.sample(self.samples, k)\n",
    "\n",
    "        print_rank_0('  >> total number of samples: {}'.format(\n",
    "            len(self.samples)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raw_sample = self.samples[idx]\n",
    "\n",
    "        query_ids, query_types, query_pad_mask, ctx_ids, ctx_types, ctx_pad_mask = build_tokens_types_paddings_from_text(\n",
    "            raw_sample['question'],\n",
    "            raw_sample['pos_context'],\n",
    "            self.tokenizer,\n",
    "            self.max_seq_length)\n",
    "\n",
    "        if self.evaluate:\n",
    "            neg_ctx_list = raw_sample['negative_context'][:self.val_av_rank_other_neg] + \\\n",
    "                           raw_sample['hard_negative_context'][:self.val_av_rank_hard_neg]\n",
    "            neg_ctx_id_list, neg_ctx_types_list = build_token_types_from_context_list(neg_ctx_list,\n",
    "                                                                                      self.tokenizer,\n",
    "                                                                                      self.max_seq_length)\n",
    "        elif self.train_with_neg:\n",
    "            hard_negative_ctx = raw_sample['hard_negative_context']\n",
    "            negative_ctx = raw_sample['negative_context']\n",
    "            if True:  # TODO: fix this or remove this condition\n",
    "                random.shuffle(hard_negative_ctx)\n",
    "                random.shuffle(negative_ctx)\n",
    "\n",
    "            neg_ctx_list = hard_negative_ctx[:self.train_hard_neg]\n",
    "            # In the Google NQ dataset by DPR paper, there are around more than 50 missing hard negatives in training data.\n",
    "            # In those cases, substitute hard negatives by simple negatives.\n",
    "            if len(neg_ctx_list) < self.train_hard_neg:\n",
    "                neg_ctx_list += negative_ctx[:self.train_hard_neg - len(neg_ctx_list)]\n",
    "\n",
    "            neg_ctx_id_list, neg_ctx_types_list = build_token_types_from_context_list(neg_ctx_list,\n",
    "                                                                                      self.tokenizer,\n",
    "                                                                                      self.max_seq_length)\n",
    "        else:\n",
    "            neg_ctx_id_list = None\n",
    "            neg_ctx_types_list = None\n",
    "\n",
    "        sample = build_sample(query_ids, query_types, query_pad_mask,\n",
    "                              ctx_ids, ctx_types, ctx_pad_mask,\n",
    "                              raw_sample['answers'],\n",
    "                              neg_ctx_id_list, neg_ctx_types_list,\n",
    "                              include_neg=self.evaluate or self.train_with_neg)\n",
    "        return sample\n",
    "\n",
    "    @staticmethod\n",
    "    @abstractmethod\n",
    "    def process_samples_from_single_path(filename):\n",
    "        \"\"\"Abstract method that takes a filename and\n",
    "        returns a list of dataset samples, each sample being a dict of\n",
    "            {'text': string, 'text': string}\n",
    "        \"\"\"\n",
    "        pass\n",
    "class Dataset(OpenRetrievalAbstractDataset):\n",
    "\n",
    "    def __init__(self, name, datapaths, tokenizer, max_seq_length, args=None, evaluate=False):\n",
    "        super().__init__(\"open-domain retrieval\",\n",
    "                         name,\n",
    "                         datapaths,\n",
    "                         tokenizer,\n",
    "                         max_seq_length,\n",
    "                         evaluate=evaluate,args=args)\n",
    "\n",
    "\n",
    "    def process_samples_from_single_path(self,filename):\n",
    "        \"\"\"\"Implement abstract method.\"\"\"\n",
    "        #args = get_args()\n",
    "        args = self.args\n",
    "        print_rank_0(' > Processing {} ...'.format(filename))\n",
    "        samples = []\n",
    "        total = 0\n",
    "\n",
    "        with open(filename, 'r', encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            for row in data:\n",
    "                question = normalize_question(row['question'])\n",
    "\n",
    "                # In some datasets, such as Trivia-QA, some positive contexts are also empty\n",
    "                if len(row['positive_ctxs']) > 0:\n",
    "                    pos_context = row['positive_ctxs'][0]\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                # Hard Negative Contexts\n",
    "                if len(row['hard_negative_ctxs']) > 0:\n",
    "                    hard_neg_context = row['hard_negative_ctxs']\n",
    "                else:\n",
    "                    hard_neg_context = []\n",
    "\n",
    "                # Negative Contexts\n",
    "                if len(row['negative_ctxs']) > 0:\n",
    "                    neg_context = row['negative_ctxs']\n",
    "                else:\n",
    "                    neg_context = []\n",
    "\n",
    "                if len(hard_neg_context) + len(neg_context) < args.train_hard_neg:\n",
    "                    continue\n",
    "\n",
    "                answers = row['answers']\n",
    "                sample = {'question': question,\n",
    "                          'pos_context': pos_context,\n",
    "                          'hard_negative_context': hard_neg_context,\n",
    "                          'negative_context': neg_context,\n",
    "                          'answers': answers}\n",
    "                total += 1\n",
    "                samples.append(sample)\n",
    "\n",
    "                if total % 5000 == 0:\n",
    "                    print_rank_0('  > processed {} so far ...'.format(total))\n",
    "\n",
    "        print_rank_0(' >> processed {} samples.'.format(len(samples)))\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "816648d9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Config:pass\n",
    "args = Config()\n",
    "args.val_av_rank_hard_neg = 10\n",
    "args.val_av_rank_other_neg = 10\n",
    "args.train_with_neg = 10\n",
    "args.train_hard_neg = 10\n",
    "args.sample_rate    =0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f386c1c1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('./data/webq/biencoder-webquestions-train.json', 'r', encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91f0dbfa",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who was the man behind The Chipmunks?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Data'][0]['Question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29bc06d8",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > building open-domain retrieval dataset for validation:\n",
      "  > paths: ./data/webq/biencoder-webquestions-train.json\n",
      " > Processing ./data/webq/biencoder-webquestions-train.json ...\n",
      " >> processed 2444 samples.\n",
      "  >> total number of samples: 977\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = Dataset(\"validation\",\n",
    "['./data/webq/biencoder-webquestions-train.json'],\n",
    "None,\n",
    "512,\n",
    "evaluate=True,args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e4101d9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "self=valid_dataset\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac5ef111",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'who plays jason gideon',\n",
       " 'pos_context': {'psg_id': '16520195',\n",
       "  'text': 'named Donnie Mallick (Arye Gross), which prompts the BAU team to investigate Gideon\\'s murder. During the flashbacks focusing on a young version of him for the episode which show him working at the BAU in 1978, he is played by Ben Savage. Jason Gideon Jason Gideon was a fictional character in the CBS crime drama \"Criminal Minds\", portrayed by Mandy Patinkin. Gideon was a Senior Supervisory Special Agent and the unit chief of the FBI\\'s Behavioral Analysis Unit, and has appeared from the series\\' pilot episode \"Extreme Aggressor,\" which was originally broadcast on September 22, 2005. He is also portrayed',\n",
       "  'score': 20.537924,\n",
       "  'title_score': 0,\n",
       "  'title': 'Jason Gideon'},\n",
       " 'hard_negative_context': [{'psg_id': '16520181',\n",
       "   'text': 'was implied that they have not seen each other very recently. Gideon also has an obsession for birds and bird-watching. The character of Jason Gideon was partially based on real-life criminal profiler John E. Douglas, one of the founders of modern Behavioral Science. He helped Derek Morgan and Spencer Reid through their nightmares. He was shown to have a very close relationship with Reid, having hand-picked him from the FBI Academy for his team, helping Reid through many difficulties and even leaving the good-bye letter for Reid to find. Gideon knew Garcia very well but Reid had a very close',\n",
       "   'score': 19.461576,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Gideon'},\n",
       "  {'psg_id': '16520192',\n",
       "   'text': 'in Jane, who refuses to go with Frank. Gideon shows up and tells Frank about Sarah, Frank\\'s mother, whom Gideon claims was a whore. As Gideon and Hotch describe Frank\\'s mother, JJ and Reid locate Tracy, who is bound and gagged but alive and unharmed. Frank convinces Jane to come back to him, and the two commit suicide. Later, Tracy calls Gideon and thanks him for saving her once again. Gideon began to lose confidence in his profiling skills after Frank Breitkopf murdered his girlfriend, Sarah Jacobs. During his final case in Arizona (\"Doubt,\" season 3), he further lost faith',\n",
       "   'score': 18.265245,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Gideon'},\n",
       "  {'psg_id': '16520184',\n",
       "   'text': 'found. Gideon intentionally demeans and insults the killer, increasingly agitating him and making his stutter worse. He takes his eyes off Gideon just long enough for him to grab the gun and subdue the killer. In \"Won\\'t Get Fooled Again,\" a copycat bomber uses the methods of serial bomber Adrian Bale (the same criminal who committed the warehouse bombing that killed his six colleagues), and Gideon has to face his past and Bale, to find out who the bomber is and stop him. After saving the lives of more agents from a suicide bombing, Gideon was forced to make a',\n",
       "   'score': 18.005491,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Gideon'},\n",
       "  {'psg_id': '16520183',\n",
       "   'text': 'with a shotgun, insisting that he tell him who he is. When Gideon reveals he is with the FBI, the gunman gets even more agitated. Gideon then tells the man that he can tell him the one thing no one has ever been able to tell him: why he stutters. However, Gideon did not truly know the answer but was merely trying to provoke a stutter in order to distract the killer. The killer forced Gideon down a hall and into a small room full of pictures of his many victims, an amount that was more than law enforcement had',\n",
       "   'score': 17.709991,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Gideon'},\n",
       "  {'psg_id': '16520182',\n",
       "   'text': 'relationship with Gideon. In the show\\'s first episode, \"Extreme Aggressor,\" Gideon was called back to work to help profile a killer, called \"The Seattle Strangler\" by the media, who abducts women and holds them prisoner before strangling them and dumping their bodies. After solving the case of the Seattle Strangler, Gideon is seen at an old-fashioned gas station in Dumfries, Virginia. While inside, Gideon notices that the cashier fits his profile of the Footpath Killer, a serial killer he had been investigating prior to being called in for the Seattle Strangler case. The man notices Gideon\\'s gun and threatens him',\n",
       "   'score': 17.709991,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Gideon'},\n",
       "  {'psg_id': '16520191',\n",
       "   'text': \"Belle, the sole survivor of Jeffrey Charles, goes missing. Gideon and Garcia are later able to figure out that the only story that moved Frank the first time Gideon met him was the body of a woman who was found in an apartment on the Upper East Side of New York City because he was talking about his mother. Gideon then realizes that Frank was hiding his mother's existence from everyone. Later, the team manages to find Frank, who is calmly sitting on a bench at the Union Train Station, waiting for them to bring him Jane. The team brings\",\n",
       "   'score': 17.611897,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Gideon'},\n",
       "  {'psg_id': '16520190',\n",
       "   'text': \"has disappeared. Gideon then receives a call from Frank, who is in Gideon's apartment, having murdered Sarah. He demands to have Jane back before hanging up. When the BAU begin to investigate, Gideon contacts Hotch from a payphone and tells him that Frank dumped something in the trash on the street, later revealed to be bloody clothing. During the investigation, it is deduced that Frank is hunting down people Gideon previously rescued. Frank later kills one such person, Rebecca Bryant, who was abducted by Randall Garner and held captive for two years before being rescued by the BAU. Later, Tracy\",\n",
       "   'score': 17.611897,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Gideon'},\n",
       "  {'psg_id': '16520189',\n",
       "   'text': 'After they pick up Jane and deliver her to Frank, Gideon drives the two to the desert and drops them off, to which Frank tells Gideon where the children are. Frank and Jane then walk off while Gideon runs in the opposite way and finds the children, all unharmed. Gideon and Hotch try to follow Frank\\'s tracks, but they suddenly disappear in the desert. In \"No Way Out II: The Evilution of Frank,\" while Gideon is trying to make up his mind about what flowers to buy his friend, Sarah Jacobs, he sees Jane. When he looks up again, she',\n",
       "   'score': 17.003847,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Gideon'},\n",
       "  {'psg_id': '16520176',\n",
       "   'text': 'show \"was very destructive to my soul and my personality. After that, I didn\\'t think I would get to work in television again.\" Gideon\\'s position is now held by his former partner and best friend, David Rossi, who has held it to this day. In Season Ten, Gideon was murdered by Donnie Mallick. Gideon was the protege of Max Ryan who taught him everything he knew about profiling, but he didn\\'t escape the hazing of being a new recruit. One of Gideon\\'s earliest cases was a bomber case, which was supervised by Max. As a prank for the new member,',\n",
       "   'score': 16.945124,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Gideon'},\n",
       "  {'psg_id': '16520188',\n",
       "   'text': \"alien had abducted her; she survived the abduction. Gideon knew that the unsub allowed Jane to survive because she wasn't scared of him. Eventually, Gideon discovered Frank in Fat Sam's Diner and Deputy Silo told Gideon he had fifteen minutes to negotiate with the unsub. Frank tells them that he had left the schoolchildren in the middle of a desert, and that if he gets Jane, he will tell them where they are. Gideon makes a deal with Frank: he and Jane will come with him if he takes them to where the children are. Frank happily agrees to that.\",\n",
       "   'score': 16.744093,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Gideon'},\n",
       "  {'psg_id': '16520193',\n",
       "   'text': 'in his abilities when his decision to release the unsub resulted in the deaths of both the unsub and a young woman. As a result of his actions, Aaron Hotchner was suspended, which was the final straw for Gideon. At the end of the following episode, \"In Name and Blood,\" Reid visited Gideon\\'s cabin but found only his gun and badge, along with a letter meant for Reid in which Gideon explained his desire to regain his belief in happy endings. Gideon was last seen entering a Nevada diner; asked by a waitress where he was going, he replied that',\n",
       "   'score': 16.350498,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Gideon'},\n",
       "  {'psg_id': '16520177',\n",
       "   'text': 'Max and the other investigators involved planted a list of the FBI director\\'s whereabouts over the next 48 hours in the bomber\\'s car for Gideon to find. When he found it, before Max could stop him, Gideon rushed up 25 flights of stairs and interrupted a meeting between the director and the U.S. Attorney General in an attempt to save him. While investigating the case of Adrian Bale, a.k.a. \"The Boston Shrapnel Bomber,\" Gideon had reportedly suffered a nervous breakdown after he sent six men into a warehouse before Bale detonated a bomb inside. All six agents and a hostage',\n",
       "   'score': 16.350498,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Gideon'},\n",
       "  {'psg_id': '12682404',\n",
       "   'text': 'of a documentary called \"Hitting Home: Good Luck Gideon\" which was broadcast on Channel M. He was included on the \\'A-Z Bestival\\' Compilation as the letter \\'G\\'. With the likes of Scroobius Pip and Ed Sheeran as self-professed fans, he supported popular American singer-songwriter Jason Mraz on his 2008 UK Tour. Gideon Conn – Vocals & Guitar Nick Gosling – drums, percussion, beats Joe \"Enrique\" Harrison – bass, guitar, keyboard, harmonica Jon Donohue – guitar, pedals + fx, bass, keyboard Wil Hesketh – decks + synth JJ Lees – cornet, keyboard Dan Hall – trombone Gideon Conn Gideon Marc Conn',\n",
       "   'score': 15.7774,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Conn'},\n",
       "  {'psg_id': '16520187',\n",
       "   'text': \"his victims. With this information, Gideon and the team were able to build a profile of the killer. In order to find the unsub, the Sheriff's Department set up a road-block looking for an RV, truck, or trailer, which was believed was the killer's mode of transportation. Gideon later noticed that something was bothering Sheriff Davis, and she told him that the profile the BAU gave them reminded her of the experience made by a local named Jane Hanratty, a.k.a. Crazy Jane. Jane had encountered the unsub thirty years ago when her car broke down, but she believed that an\",\n",
       "   'score': 15.683724,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Gideon'},\n",
       "  {'psg_id': '16520185',\n",
       "   'text': 'deal with Bale to have him help them get a bomb off of an innocent man. When Gideon realizes that Bale is lying about how dismantle it, he calls his bluff, saving them all from a bomb going off. He then has the pleasure of returning Bale to prison, the burden of the six agents\\' deaths presumably gone, even mocking him while he was being placed in a cell by using Bale\\'s own words (\"[A]n emotional release\") in a sentence; he states that he finds it an emotional release in putting away criminals like Bale. In \"No Way Out,\" Gideon',\n",
       "   'score': 15.683724,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Gideon'},\n",
       "  {'psg_id': '12318474',\n",
       "   'text': \"CS Visé in order to help the Belgian club gain promotion from the 2011–12 Belgian Second Division to the 2012–2013 Belgian Pro League. Gideon wasn't a professional footballer Gideon Boateng Gideon Acheampong Boateng (born 26 August 1991 in Accra) is a Ghanaian professional footballer, who plays in Belgium for CS Visé as a striker. He holds both a Ghanaian passport and a Belgian passport. Boateng began his career 2004 by Royal Antwerp, he joined later to Lierse in 2005. He played with Lierse one year before scouted in 2006 from Anderlecht. Boateng played in Brussels 3 years before he transferred\",\n",
       "   'score': 15.435173,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Boateng'},\n",
       "  {'psg_id': '16520186',\n",
       "   'text': \"faces the scariest and most evil serial killer in his entire career, Frank Breitkopf (Keith Carradine). The BAU had received a call from Georgia Davis, the Sheriff of the Golconda, Nevada Sheriff's Department, who had recently found two murder victims, both missing their right rib bones, similar to a case that took place in 1996. However, Gideon realized that this unsub has been killing for thirty years. After studying one of the murder victims, he determined that the unsub has extensive medical knowledge, his victims are alive when he cut off their limbs, and that he uses Ketamine to immobilize\",\n",
       "   'score': 15.274107,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Gideon'},\n",
       "  {'psg_id': '20072226',\n",
       "   'text': \"Gideon Gela-Mosby Gideon Gela-Mosby (born 27 December 1996) is an Australian professional rugby league footballer who plays for the North Queensland Cowboys in the National Rugby League. He plays at and . Born in Cairns and of Torres Strait Islander descent, Gela-Mosby grew up on the tiny Darnley Island in the Torres Strait. Gela-Mosby had never played rugby league until he moved back to Cairns to attend high school. While in Cairns he played his junior rugby league for the Cairns Kangaroos and Edmonton Storm. Gela-Mosby may be eligible for the Papua New Guinean national team through his parents' connection\",\n",
       "   'score': 15.039145,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Gela-Mosby'},\n",
       "  {'psg_id': '6289930',\n",
       "   'text': 'at international level including representing his country at the 2006, 2007 and 2008 Beach Soccer World Cups. He has skippered the national team on several occasions. He played in 17 World Cup qualification games from 1996 through 2007. Omokirio was the national champion in the 200 metres running and the long jump. Gideon Omokirio Gideon Omokirio (born 12 October 1976 in Honiara) is a Solomon Islands footballer who currently plays for PRK Hekari United. His brother Eddie was also active in football. \"Giggs\" Omokirio had played most of his club football in his home country, only for a short spell',\n",
       "   'score': 14.768398,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Omokirio'},\n",
       "  {'psg_id': '6289929',\n",
       "   'text': 'Gideon Omokirio Gideon Omokirio (born 12 October 1976 in Honiara) is a Solomon Islands footballer who currently plays for PRK Hekari United. His brother Eddie was also active in football. \"Giggs\" Omokirio had played most of his club football in his home country, only for a short spell in New Zealand. He then joined Papua New Guinea side Hekari in 2009. In May 2010, he won the Oceania Champions League with Hekari United. Omokirio made his debut for the Solomon Islands in a May 1996 OFC Nations Cup match against Tahiti and has represented his country in every age group',\n",
       "   'score': 14.768398,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Omokirio'},\n",
       "  {'psg_id': '20596419',\n",
       "   'text': '2017, Waja made his international debut at senior level in a 1–1 draw against Benin. In September 2017, he was called up for two FIFA World Cup qualifying matches against Congo but was an unused substitute in both matches. Gideon Waja Gideon Waja (born December 15, 1996) is a Ghanaian footballer who plays as a midfielder for United Soccer League club Toronto FC II. He also featured for Ghana Premier League club WAFA before a move to Canada in 2018. After being capped three times for Ghana Under-17s, he made his senior international debut in May 2017. Waja began his',\n",
       "   'score': 14.768398,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Waja'},\n",
       "  {'psg_id': '20596417',\n",
       "   'text': 'Gideon Waja Gideon Waja (born December 15, 1996) is a Ghanaian footballer who plays as a midfielder for United Soccer League club Toronto FC II. He also featured for Ghana Premier League club WAFA before a move to Canada in 2018. After being capped three times for Ghana Under-17s, he made his senior international debut in May 2017. Waja began his career in the Feyenoord Fetteh Football Academy, which was re-branded as the West African Football Academy in 2014. He captained the team to second place in the 2017 Ghana Premier League season. Falling six points short of champions Aduana',\n",
       "   'score': 14.768398,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Waja'},\n",
       "  {'psg_id': '18588363',\n",
       "   'text': \"national team for the first time when he was nominated for the test match against Denmark and for the European Championship qualifier against Azerbaijan. He could not participate in the game due to a hit on the calf. On 26 August 2016, Jung was again invited by Stefan Kuntz, Hrubesch's successor. Again he could not participate because of an injury. Gideon Jung Gideon Jung (born 12 September 1994) is a German professional footballer who currently plays as a defender or defensive midfielder for Hamburger SV. He made his professional debut on 13 September 2013 for Rot-Weiß Oberhausen in a Regionalliga\",\n",
       "   'score': 14.768398,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Jung'},\n",
       "  {'psg_id': '18588361',\n",
       "   'text': 'Gideon Jung Gideon Jung (born 12 September 1994) is a German professional footballer who currently plays as a defender or defensive midfielder for Hamburger SV. He made his professional debut on 13 September 2013 for Rot-Weiß Oberhausen in a Regionalliga West match against Sportfreunde Lotte. On 5 April 2014, Jung scored his first professional goal in a game against SC Wiedenbrück 2000. He went on to make 22 appearances in the 2013-14 season before transferring to Hamburger SV on 1 July 2014. Upon arrival at Hamburger SV, Jung was immediately sent down to the second team, Hamburger SV II. On',\n",
       "   'score': 14.768398,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Jung'},\n",
       "  {'psg_id': '16034065',\n",
       "   'text': 'jersey number 8. Gideon Sani Gideon Adinoy Sani (born 8 June 1990 in Lagos, Nigeria) is a Nigerian football player who plays for Akhisar Belediyespor. Sani is a fast and aggressive attacker with excellent scoring and dribbling ability. He is also effective as an attacking midfielder, he is technically sound and average a 95% complete passes in a game. Sani moved from the Nigerian Magate FC football academy to Turkey. He joined Turkish amateur club Izmirspor where he played 3 matches and scored 3 goals. In 2011, he signed a professional contract with Akhisar Belediyespor, professional Turkish football club and',\n",
       "   'score': 14.768398,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Sani'},\n",
       "  {'psg_id': '16034064',\n",
       "   'text': 'Gideon Sani Gideon Adinoy Sani (born 8 June 1990 in Lagos, Nigeria) is a Nigerian football player who plays for Akhisar Belediyespor. Sani is a fast and aggressive attacker with excellent scoring and dribbling ability. He is also effective as an attacking midfielder, he is technically sound and average a 95% complete passes in a game. Sani moved from the Nigerian Magate FC football academy to Turkey. He joined Turkish amateur club Izmirspor where he played 3 matches and scored 3 goals. In 2011, he signed a professional contract with Akhisar Belediyespor, professional Turkish football club and was assigned the',\n",
       "   'score': 14.768398,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Sani'},\n",
       "  {'psg_id': '15085820',\n",
       "   'text': 'that Baah had signed for their second team Kairat-A. Baah left Kairat-A on 20 May 2018 by mutual consent having scored once for the club. In 2009, he received a call-up to Ghana U20 national team. In October 2015, Baah received his first senior call up to the Ghana national team. He made his debut for Ghana in a 13 October friendly against Canada, coming into the match as a substitute in the 87th minute. Asante Kotoko HJK Helsinki Gideon Baah Gideon Baah (born 1 October 1991) is a Ghanaian footballer who plays as a defender for Gomel. In 2007,',\n",
       "   'score': 14.768398,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Baah'},\n",
       "  {'psg_id': '15085813',\n",
       "   'text': \"Gideon Baah Gideon Baah (born 1 October 1991) is a Ghanaian footballer who plays as a defender for Gomel. In 2007, Baah won a football reality show (MTN Soccer Academy) in his home country, Ghana. He received a number of prizes which included cash, car, trip to watch the 2010 FIFA World Cup, and two-week trial at Chelsea FC academy. Chelsea player and Ghanaian international Michael Essien stated that he was very happy with Baah's performance and urged the Club to offer him a contract. Baah later returned to Ghana. In March 2010, Baah sustained a broken shin in a\",\n",
       "   'score': 14.768398,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Baah'},\n",
       "  {'psg_id': '12318473',\n",
       "   'text': 'Gideon Boateng Gideon Acheampong Boateng (born 26 August 1991 in Accra) is a Ghanaian professional footballer, who plays in Belgium for CS Visé as a striker. He holds both a Ghanaian passport and a Belgian passport. Boateng began his career 2004 by Royal Antwerp, he joined later to Lierse in 2005. He played with Lierse one year before scouted in 2006 from Anderlecht. Boateng played in Brussels 3 years before he transferred to MVV Maastricht on 15 December 2008. He signed a three and half year contract. In January 2012, Boateng transferred from Dutch club MVV Maastricht to Belgian club',\n",
       "   'score': 14.768398,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Boateng'},\n",
       "  {'psg_id': '17864707',\n",
       "   'text': 'Gideon Rises \"Gideon Rises\" is the twentieth aired episode of the animated television series \"Gravity Falls\". It is also the final episode of the series\\' first season. The episode premiered on August 2, 2013, on the Disney Channel. It was directed by John Aoshima and Joe Pitt, and written by Alex Hirsch, Matt Chapman, and Michael Rianda. The series follows twins Dipper (voiced by Jason Ritter) and Mabel (voiced by Kristen Schaal) as they spend their summer vacation at their great uncle\\'s tourist trap, where they are introduced to the paranormal side of the town Gravity Falls. The episode is',\n",
       "   'score': 14.627123,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Rises'},\n",
       "  {'psg_id': '4953734',\n",
       "   'text': 'in Famine\", a two-page comic strip in \"Food for Thought\" (a British benefit comic to aid Ethiopian famine relief) in 1985. The character next made an appearance in Morrison\\'s \"The Invisibles\" (Vol. 1, #17–19, 1995) as an alter-ego of King Mob, one of that title\\'s main characters, who in literary terms is reported to have been based on Stargrave. In this incarnation, Stargrave is used by King Mob to confuse his enemies during interrogation. Gideon is a \\'70s spy modelled after James Bond and Jason King who spends every scene he appears in seducing his partner, and is supposedly the',\n",
       "   'score': 14.513006,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Stargrave'},\n",
       "  {'psg_id': '16520194',\n",
       "   'text': 'he did not know his destination or how he would know when he had reached it. He then left the diner and drove off, as his voiceover off-screen narrated the final lines of his letter (also marking his very final words), \"I guess I\\'m just looking for it again. For the belief I had back in college. The belief I had when I first met Sarah and it all seemed so right. The belief in happy endings.\" In the Season 10 episode \"Nelson\\'s Sparrow,\" Gideon was murdered off-screen, having been shot dead at a close range by a serial killer',\n",
       "   'score': 14.308208,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Gideon'},\n",
       "  {'psg_id': '16520180',\n",
       "   'text': 'advancement by shouting at the top of his lungs with pleas of mercy and, when questioned by his team, he said that the victims were being threatened to be kept quiet as neighbors would have heard the pleas if they were unrestrained. He blamed himself for the torture Reid received from Tobias Hankel as he had ordered Penelope Garcia to add a virus warning to the videos Hankel posted. He also blamed himself for the reason Agent Elle Greenaway was shot. Gideon also had a son named Stephen. The nature of their relationship has not been directly stated, but it',\n",
       "   'score': 14.308208,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Gideon'},\n",
       "  {'psg_id': '16520179',\n",
       "   'text': 'him to \"think outside the box.\" Prior to the series, he was said to have had a \"nervous breakdown\" (or \"major depressive episode\") after he sent six agents into a warehouse with a bomb in it; all six agents and a hostage were killed, and he was heavily criticized about the event. He showed particular dislike for the practice of using religion as a defense or motivation for one\\'s crimes. Gideon participated in some field operations during his time with the BAU and had the rest of his team \"think outside the box\" as well, as he made a major',\n",
       "   'score': 14.308208,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Gideon'},\n",
       "  {'psg_id': '16520178',\n",
       "   'text': \"were killed, and he was heavily criticized about the event. He took a six-month medical leave because he was suffering from post-traumatic stress disorder. Upon his return from medical leave, he was given the Senior Agent position, as Hotch was confirmed as Unit Chief. Not much is known about his personal life, other than he has a son named Stephen, with whom he was estranged because of his commitment to his job. Through the first two seasons, Gideon was portrayed to be very good at chess, winning against Agent Spencer Reid many times (only exception being Reid's birthday) and encouraging\",\n",
       "   'score': 14.308208,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Gideon'},\n",
       "  {'psg_id': '5901677',\n",
       "   'text': 'Jason Kane (Doctor Who) Jason Peter Kane is a fictional character from Virgin Publishing\\'s range of original full-length \"Doctor Who\" novels, the \"New Adventures\". The \"New Adventures\" were fully licensed novels carrying on from where the \"Doctor Who\" television series had left off. Jason was introduced in Dave Stone\\'s novel \"Death and Diplomacy\" in 1996. Jason was born on Christmas Eve 1983 and grew up around London, although his father Peter was abusive towards him and his sister, leading Jason to eventually run away. In 1996, Jason was caught in an alien transportation beam, causing him to be deposited in',\n",
       "   'score': 14.063021,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Kane (Doctor Who)'},\n",
       "  {'psg_id': '808661',\n",
       "   'text': 'would be reason for the Israelites to claim the victory as their own instead of acknowledging that God had saved them. God first instructed Gideon to send home those men who were afraid. Gideon invited any man who wanted to leave, to do so; 22,000 men returned home and 10,000 remained. Yet with the number, God told Gideon they were still too many and instructed him to bring them to the water. All those who lap the water with their tongues, as a dog laps, you shall put to one side; all those who kneel down to drink, putting their',\n",
       "   'score': 13.984623,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon'},\n",
       "  {'psg_id': '9050306',\n",
       "   'text': '1 Trainer Certification course. Jason MacDonald Jason Anthony MacDonald (born June 3, 1975) is a Canadian former mixed martial artist who is perhaps best known for his two stints with the Ultimate Fighting Championship as a middleweight. He is also a veteran of the Maximum Fighting Championship and TKO Major League MMA in his native country of Canada. MacDonald began his career in local Canadian promotions, including the MFC, racking up a 16-7 professional record which included wins over UFC veterans Joe Doerksen, Gideon Ray, and Bill Mahood. MacDonald made his UFC debut on October 10, 2006, at \"\" against',\n",
       "   'score': 13.912502,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason MacDonald'},\n",
       "  {'psg_id': '9050297',\n",
       "   'text': 'Jason MacDonald Jason Anthony MacDonald (born June 3, 1975) is a Canadian former mixed martial artist who is perhaps best known for his two stints with the Ultimate Fighting Championship as a middleweight. He is also a veteran of the Maximum Fighting Championship and TKO Major League MMA in his native country of Canada. MacDonald began his career in local Canadian promotions, including the MFC, racking up a 16-7 professional record which included wins over UFC veterans Joe Doerksen, Gideon Ray, and Bill Mahood. MacDonald made his UFC debut on October 10, 2006, at \"\" against the favored \"The Ultimate',\n",
       "   'score': 13.912502,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason MacDonald'},\n",
       "  {'psg_id': '7057959',\n",
       "   'text': \"return for Sunspot's life. Gideon attempted a hostile takeover of Genetech and the Taylor Foundation, but was thwarted by Night Thrasher and was defeated by him in physical combat. Gideon witnessed the External Nicodemus's death. Gideon was then offered a position with HYDRA, but refused and battled a HYDRA strike force. He was aided in defeating them by Nick Fury and S.H.I.E.L.D. Gideon was attacked and captured by X-Force, who then rescued Boomer, Siryn, and Warpath. All of the Externals were eventually killed (except for Cannonball); Gideon was not spared and was killed by the energy vampire, Selene. Gideon mysteriously\",\n",
       "   'score': 13.890944,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon (comics)'},\n",
       "  {'psg_id': '808666',\n",
       "   'text': 'out of the gold won in battle, which eventually caused the whole of Israel to turn away from God yet again. Gideon had 70 sons from the many women he took as wives. He also had a Shechemite concubine who bore him a son whom he named Abimelech, which means \"my father is king\" (). There was peace in Israel for 40 years during the life of Gideon. As soon as Gideon died of old age, the Israelites again turned to worship the false god Baal-Berith and ignored the family of Gideon (). In the early twentieth century, the text',\n",
       "   'score': 13.854918,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon'},\n",
       "  {'psg_id': '808659',\n",
       "   'text': \"between Abraham and the visitors who came to him in the terebinth trees of Mamre and promised Abraham and Sarah, in their old age, that they would have a son (). The Angel of the Lord greeted Gideon: Gideon requested proof of God's will by three miracles: firstly a sign from the Angel of the Lord, in which the angel appeared to Gideon and caused fire to shoot up out of a rock (), and then two signs involving a fleece, performed on consecutive nights and the exact opposite of each other (). On God's instruction, Gideon destroyed the town's\",\n",
       "   'score': 13.854918,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon'},\n",
       "  {'psg_id': '5901681',\n",
       "   'text': 'Doctor and Peri journey to the 32nd century and meet a man named Kane, who expected the Doctor to recognise him. Kane\\'s first name (never revealed) is \"one of those...that were unisexual\". Jason Kane (Doctor Who) Jason Peter Kane is a fictional character from Virgin Publishing\\'s range of original full-length \"Doctor Who\" novels, the \"New Adventures\". The \"New Adventures\" were fully licensed novels carrying on from where the \"Doctor Who\" television series had left off. Jason was introduced in Dave Stone\\'s novel \"Death and Diplomacy\" in 1996. Jason was born on Christmas Eve 1983 and grew up around London, although',\n",
       "   'score': 13.830921,\n",
       "   'title_score': 0,\n",
       "   'title': 'Jason Kane (Doctor Who)'},\n",
       "  {'psg_id': '19620815',\n",
       "   'text': 'with the Durban-based franchise. Gideon Koegelenberg Gideon Koegelenberg (born 25 November 1994) is a South African rugby union player for the in Super Rugby and in the Currie Cup and the in the Rugby Challenge. He usually plays as a lock. Koegelenberg was born in Wellington and played for the at youth level. He earned inclusion in the 2012 South Africa Schools squad and made appearances against France and England. He then joined the Academy, where he made a single appearances against former side Boland Cavaliers. A knee injury hampered his progress at the Durban-based side, ruling him out of',\n",
       "   'score': 13.802501,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Koegelenberg'},\n",
       "  {'psg_id': '19620813',\n",
       "   'text': 'Gideon Koegelenberg Gideon Koegelenberg (born 25 November 1994) is a South African rugby union player for the in Super Rugby and in the Currie Cup and the in the Rugby Challenge. He usually plays as a lock. Koegelenberg was born in Wellington and played for the at youth level. He earned inclusion in the 2012 South Africa Schools squad and made appearances against France and England. He then joined the Academy, where he made a single appearances against former side Boland Cavaliers. A knee injury hampered his progress at the Durban-based side, ruling him out of the entire 2014 season.',\n",
       "   'score': 13.802501,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Koegelenberg'},\n",
       "  {'psg_id': '7156112',\n",
       "   'text': \"is one of the namesakes of Greathouse/Shryock Traditional Elementary School in Louisville, Kentucky. Gideon Shryock Gideon Shryock (November 15, 1802 – June 19, 1880) was Kentucky's first professional architect, known for his work in the Greek Revival style. His name has frequently been misspelled as Gideon Shyrock. Shryock was a native of Lexington, Kentucky, the son of a housebuilder and contractor, Mathias Shryock, who had moved to Kentucky from Maryland and who would father 10 other children in Kentucky besides Gideon. One of Gideon's younger brothers, Cincinnatus Shryock, would also become an architect. Shryock studied at Lancastrian Academy in Lexington,\",\n",
       "   'score': 13.74243,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Shryock'},\n",
       "  {'psg_id': '7156110',\n",
       "   'text': \"Gideon Shryock Gideon Shryock (November 15, 1802 – June 19, 1880) was Kentucky's first professional architect, known for his work in the Greek Revival style. His name has frequently been misspelled as Gideon Shyrock. Shryock was a native of Lexington, Kentucky, the son of a housebuilder and contractor, Mathias Shryock, who had moved to Kentucky from Maryland and who would father 10 other children in Kentucky besides Gideon. One of Gideon's younger brothers, Cincinnatus Shryock, would also become an architect. Shryock studied at Lancastrian Academy in Lexington, worked in the family business, and then was apprenticed to architect William Strickland\",\n",
       "   'score': 13.74243,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Shryock'},\n",
       "  {'psg_id': '8739382',\n",
       "   'text': 'Gideon (album) Gideon is the ninth studio album by Kenny Rogers. Issued by United Artists Records in 1980, it reached #1 on the country charts and the top 20 of the pop charts. It includes the worldwide hit \"Don\\'t Fall in Love with a Dreamer\" (a duet with Kim Carnes, who co-wrote the entire album with her husband Dave Ellingson). \"Gideon\" is a concept album about a Texas cowboy, and all the songs stick to this theme. The album is a look back at his life in retrospect. In the first song \"Gideon Tanner\", it is known that Gideon is',\n",
       "   'score': 13.706682,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon (album)'},\n",
       "  {'psg_id': '7057963',\n",
       "   'text': \"technology developed by Ophrah Industries. In the alternate reality known as the Age of Apocalypse, Gideon was drafted to be one of the Horsemen of Apocalypse. Gideon, alongside Sabretooth, Candra, Death and War, planned to fire nuclear missiles at Cape Citadel. Gideon was selected to hack the computer system and fire the missiles. He was interrupted by Magneto, who he nearly defeated, until Magneto drew upon the Earth's Magnetic Field to overload Gideon's powers, apparently killing him. Gideon (comics) Gideon is a fictional character, a mutant supervillain appearing in American comic books published by Marvel Comics. He was created by\",\n",
       "   'score': 13.706682,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon (comics)'},\n",
       "  {'psg_id': '18468545',\n",
       "   'text': \"Sara Gideon Sara Gideon (born December 4, 1971) is an American politician from Maine who is currently Speaker of the Maine House of Representatives. A Democrat from Freeport, a suburb of Portland, Gideon represents District 48 of the Maine House of Representatives, which encompasses part of Freeport and Pownal in Cumberland County. First elected in 2012, Gideon was reelected in 2014 and chosen as Assistant Majority Leader of the Maine House of Representatives. In 1994, Gideon earned a B.A. in international affairs from George Washington University's Elliott School of International Affairs in Washington D.C. She moved to Freeport in 2004\",\n",
       "   'score': 13.706682,\n",
       "   'title_score': 0,\n",
       "   'title': 'Sara Gideon'},\n",
       "  {'psg_id': '15039242',\n",
       "   'text': 'of the SS and Police Leader in occupied Denmark until the surrender in 1945. Gideon was found in 1975 when Israeli historian Tom Segev interviewed him for his book \"Soldiers of Evil\", a study of the concentration camp commandants. However, after initially cooperating with Segev, Gideon terminated the interview when he suddenly claimed that he was a different person who happened to be named Wilhelm Gideon rather than the former commandant of Gross-Rosen. Wilhelm Gideon Wilhelm Gideon (born 15 November 1898 in Oldenburg – died 23 February 1977) was a Schutzstaffel officer and Nazi concentration camp commandant. A native of',\n",
       "   'score': 13.706682,\n",
       "   'title_score': 0,\n",
       "   'title': 'Wilhelm Gideon'},\n",
       "  {'psg_id': '10441740',\n",
       "   'text': 'Armoured Gideon Armoured Gideon is a comics character (and their eponymous story) who first appeared in British science fiction anthology \"2000 AD\". The stories were written by John Tomlinson, with art by Simon Jacob. Armoured Gideon is a robot created by a race known as The Silent Ones to prevent evil beings escaping from a parallel dimension to that of Earth\\'s. Gideon is armed with a wide variety of weaponry to destroy anything it finds trying to escape the dimension known as \"The Edge\". When Gideon attacks, he does so uttering the word \"Annihilate!\" In 2018 the character made a',\n",
       "   'score': 13.706682,\n",
       "   'title_score': 0,\n",
       "   'title': 'Armoured Gideon'},\n",
       "  {'psg_id': '14724355',\n",
       "   'text': \"of Representatives from 1801–1808 and senator from North Carolina from 1815-1828. Upon Gideon Macon's death in 1702, his widow, Martha Woodward Macon, married Captain Nathaniel West, who was also a representative in the House of Burgesses. They had two children, and their daughter, Unity West, married Frances Jones's brother-in-law, William Dandridge. Gideon Macon married Martha Woodward in 1680. They had eight children: Gideon Macon Gideon (or Gedeon) Macon (c. 1648–1702) was an early American settler. There are conflicting theories regarding Gideon Macon's lineage. The one which has been commonly set forth is that his parents were from Loire, France, but\",\n",
       "   'score': 13.657651,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Macon'},\n",
       "  {'psg_id': '16527611',\n",
       "   'text': 'Gideon Cornell Gideon Cornell (1710–1766) was a farmer, trader and judge who became the first Chief Justice of the Rhode Island Supreme Court, serving from 1747 to 1749. Born July. 5, 1710 in Portsmouth, Rhode Island, Gideon Cornell was the son of Martha Freeborn and Thomas Cornell, who was elected several times as an assistant and deputy (representative) from Portsmouth. Cornell descends from Thomas Cornell who came from Saffron Walden, County Essex, England, and settled in Portsmouth in the Rhode Island colony, and later in New Netherland. He also descends from Thomas Hazard, one of the nine founding settlers of',\n",
       "   'score': 13.492078,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Cornell'},\n",
       "  {'psg_id': '3419817',\n",
       "   'text': 'opened revealed the results of a search for \"Gideon Sundback\". Sundback\\'s (filed in 1914, issued in 1917): <br> Gideon Sundback Gideon Sundback (April 24, 1880 – June 21, 1954) was a Swedish-American electrical engineer, who is most commonly associated with his work in the development of the zipper. Otto Fredrik Gideon Sundback was born on Sonarp farm in Ödestugu Parish, in Jönköping County, Småland, Sweden. He was the son of Jonas Otto Magnusson Sundback, a prosperous farmer, and his wife Kristina Karolina Klasdotter. After his studies in Sweden, Sundback moved to Germany, where he studied at the polytechnic school in',\n",
       "   'score': 13.446929,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Sundback'},\n",
       "  {'psg_id': '18468546',\n",
       "   'text': 'and served as Vice Chair of the Freeport Town Council. She also worked as an advertising account executive at USA Today. The daughter of an Indian immigrant father and an Armenian immigrant mother, Gideon has indicated she is considering challenging incumbent United States Senator Susan Collins in 2020. Sara Gideon Sara Gideon (born December 4, 1971) is an American politician from Maine who is currently Speaker of the Maine House of Representatives. A Democrat from Freeport, a suburb of Portland, Gideon represents District 48 of the Maine House of Representatives, which encompasses part of Freeport and Pownal in Cumberland County.',\n",
       "   'score': 13.446929,\n",
       "   'title_score': 0,\n",
       "   'title': 'Sara Gideon'},\n",
       "  {'psg_id': '14724349',\n",
       "   'text': \"income from the building was paid to his widow, Ann (Garland) Macon. Upon her death in 1699, her will left items to Gideon Macon and his children. This will provides additional evidence as proof that Ann (Garland) Macon was the mother of Gideon Macon. Similar evidence is unavailable to prove that Gideon Macon is of Huguenot descent. Gideon Macon moved to Virginia sometime before 1672. Macon served as secretary to Sir William Berkeley, who was appointed Governor of Virginia by King Charles I for two nonconsecutive terms. Berkeley's first term was from 1642-1652. In 1652 Berkeley was forced from office\",\n",
       "   'score': 13.446929,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Macon'},\n",
       "  {'psg_id': '10851093',\n",
       "   'text': 'Gideon Planish Gideon Planish is a 1943 novel by American writer Sinclair Lewis. The novel tells the story of Gideon Planish, an unprincipled social climber who becomes involved in various shady philanthropic organizations in his quest for stature without accountability. The work did not fare as well with critics as some of Lewis\\' earlier social novels, and is considered one of his minor works. \"Gideon Planish\" (1943) takes aim at less-than-honorable fundraising organizations. In a similar manner of his other works, the reader follows the self-titled character through his life and numerous (but slightly related) professions dealing with professional \"organizationality\"',\n",
       "   'score': 13.446929,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Planish'},\n",
       "  {'psg_id': '10067869',\n",
       "   'text': 'in which 300 Israelites will defeat 120,000 Midianites. In the second act, which a \"Time\" magazine review described as the weaker of the play\\'s two acts, Gideon asks to be released from his \"covenant of love\" with God. Gideon ignores God\\'s order to kill some idolatrous Hebrew tribal chiefs, one of whom has a daughter who performs a seductive dance. Gideon tells God, \"You are too vast a concept for me.\" Gideon explains that his pity for fellow humans is above God\\'s law. The Lord acknowledges that man wants to be \"a proper god. You know, he might some day.\"',\n",
       "   'score': 13.446929,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon (play)'},\n",
       "  {'psg_id': '3833066',\n",
       "   'text': \"of young men who had stolen the beer and coins from Bay Harbor Pool Room. (Turner had been Cook's lawyer in previous cases.) Turner also received a statement from the taxicab driver who transported Gideon from the Bay Harbor Pool Room to a bar in Panama City, Florida, stating that Gideon was carrying neither wine, beer nor Coke when he picked him up, even though Cook testified that he watched Gideon walk from the pool hall to the phone, then wait for a cab. Furthermore, although in the first trial Gideon had not cross-examined the driver about his statement that\",\n",
       "   'score': 13.386744,\n",
       "   'title_score': 0,\n",
       "   'title': 'Clarence Earl Gideon'},\n",
       "  {'psg_id': '1302068',\n",
       "   'text': 'had been a lookout for a group of young men who broke into the poolroom to steal beer, then grabbed the coins while they were there. Turner also obtained a statement from the cab driver who had taken Gideon from Bay Harbor to a bar in Panama City, stating that Gideon was carrying neither wine, beer, nor Coke when he picked him up, even though Cook testified that he had watched Gideon walk from the pool hall to the phone and then wait for a cab. This testimony completely discredited Cook. The jury acquitted Gideon after one hour of deliberation.',\n",
       "   'score': 13.386744,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon v. Wainwright'},\n",
       "  {'psg_id': '3833069',\n",
       "   'text': 'for his portrayal of Gideon. Clarence Earl Gideon Clarence Earl Gideon (August 30, 1910 – January 18, 1972) was a poor drifter and amateur attorney accused in a Florida state court of felony theft. His case resulted in the landmark U.S. Supreme Court decision \"Gideon v. Wainwright\", holding that a criminal defendant who cannot afford to hire a lawyer must be provided one at no cost. At Gideon\\'s first trial, he represented himself and was convicted. After the Supreme Court ruled that the state had to provide defense counsel for the indigent, Florida retried Gideon. At his second trial, which',\n",
       "   'score': 13.350996,\n",
       "   'title_score': 0,\n",
       "   'title': 'Clarence Earl Gideon'},\n",
       "  {'psg_id': '7057961',\n",
       "   'text': \"time travelling Gideon himself, who reveals that he spent 3,000 years in stasis and when he woke up, humanity had changed considerably. Deciding to prevent this outcome, Gideon traveled back in time to kill his fellow companions. Gideon is a mutant who has the ability of Super Human Enhancement Assimilation: the power to temporarily endow himself with the super powers of any beings in his proximity, whether they are a superhuman, android, or mechanical battlesuit. He scans and replicates his target's energy signatures and genetic templates, granting him a full understanding of the potential applications of the powers he acquires\",\n",
       "   'score': 13.348835,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon (comics)'},\n",
       "  {'psg_id': '20155064',\n",
       "   'text': 'Eliot was paid 100 merks while the physician who accompanied him was paid 200 merks - about ten pounds sterling. Gideon Eliot Gideon Eliot (1664-1713) of North Sintoun in Roxburghshire was an Edinburgh surgeon who served as Deacon (President) of the Incorporation of Surgeons of Edinburgh on two occasions. Gideon Eliot, son of Thomas Eliot of Beirlie, was apprenticed to the surgeon George Stirling on 19 October 1681. Eliot was the first surgeon to the 26th (Cameronian) Regiment of Foot which was raised in April 1689. The regiment was raised to fight the Jacobite forces under Graham of Claverhouse, Viscount',\n",
       "   'score': 13.348835,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Eliot'},\n",
       "  {'psg_id': '20155058',\n",
       "   'text': \"Gideon Eliot Gideon Eliot (1664-1713) of North Sintoun in Roxburghshire was an Edinburgh surgeon who served as Deacon (President) of the Incorporation of Surgeons of Edinburgh on two occasions. Gideon Eliot, son of Thomas Eliot of Beirlie, was apprenticed to the surgeon George Stirling on 19 October 1681. Eliot was the first surgeon to the 26th (Cameronian) Regiment of Foot which was raised in April 1689. The regiment was raised to fight the Jacobite forces under Graham of Claverhouse, Viscount Dundee, who opposed King William's accession to the throne of Great Britain and Ireland. In their first action, in August\",\n",
       "   'score': 13.348835,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Eliot'},\n",
       "  {'psg_id': '16674399',\n",
       "   'text': 'Gideon Remez Gideon Remez (Hebrew: גדעון רמז, born 2 June 1946) is an Israeli journalist and an analyst on post-Soviet affairs. Gideon Remez was born in Tel Aviv on June 2, 1946. His father, Aharon Remez, was an Israeli diplomat and military officer who served as the second commander of the Israeli Air Force. His grandfather, David Remez, was an Israeli politician who was a signatory to the Israeli Declaration of Independence. Remez headed the foreign news desk at the Voice of Israel. He is a fellow of the Harry S. Truman Research Institute for the Advancement of Peace at',\n",
       "   'score': 13.348835,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Remez'},\n",
       "  {'psg_id': '16527617',\n",
       "   'text': 'signatories for the petition creating Brown University. The Historical Society of Pennsylvania contains Cornell\\'s commissions of appointment as judge from 1743 to 1748. Cornell had two known children, the oldest being a son, Gideon, born October 10, 1740, who appears to have died in infancy. His only other known child was a daughter, Rebecca, born February 17, 1755, who married Colonel Clement Biddle of the Biddle family and had numerous descendants. Cornell\\'s ancestry after the first generation comes mostly from John O. Austin\\'s \"Genealogical Dictionary of Rhode Island\". The George Lawton ancestry is from Shurtleff and Shurtleff. Gideon Cornell Gideon',\n",
       "   'score': 13.348835,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Cornell'},\n",
       "  {'psg_id': '15483365',\n",
       "   'text': \"Wanton kept active mostly in his dealings within the Friends (Quaker) society. He died on September 12, 1767, and was buried in the Friends' Burial Ground, sometimes called Governor's Cemetery, on Tilden Street in Newport. Gideon Wanton Gideon Wanton (October 20, 1693 – September 12, 1767) was a governor of the Colony of Rhode Island and Providence Plantations who served for two separate one-year terms. His father was Joseph Wanton, a shipbuilder in Tiverton, and his mother was Sarah Freeborn, the daughter of Gideon and Sarah (Brownell) Freeborn. One of his great grandfathers was William Freeborn, who signed the Portsmouth\",\n",
       "   'score': 13.348835,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Wanton'},\n",
       "  {'psg_id': '15483362',\n",
       "   'text': \"Gideon Wanton Gideon Wanton (October 20, 1693 – September 12, 1767) was a governor of the Colony of Rhode Island and Providence Plantations who served for two separate one-year terms. His father was Joseph Wanton, a shipbuilder in Tiverton, and his mother was Sarah Freeborn, the daughter of Gideon and Sarah (Brownell) Freeborn. One of his great grandfathers was William Freeborn, who signed the Portsmouth Compact, becoming a founder of Portsmouth in the Rhode Island colony. Both of Wanton's parents were Quakers, and both were public speakers within the denomination. Wanton was admitted as a freeman to Newport in 1718,\",\n",
       "   'score': 13.348835,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Wanton'},\n",
       "  {'psg_id': '13757565',\n",
       "   'text': 'over-investing during a down market. Gideon Nye, known as Gideon Nye, Jr., was a 7th generation descendant of Benjamin Nye, the founder of the Nye family, who settled in Sandwich, Mass., in 1637. He was an eldest child. His father, Gideon Nye, was born in 1786 and died in 1875. His mother, Sylvia S. Hathaway, was born in 1790, and died in 1883. Mr Nye was married in 1846, to Mary E. Washburn, who died in New York in 1870. Their only child was a daughter, born in Paris, France in 1846, Ellen E. Washburn. She died in Brooklyn, NY,',\n",
       "   'score': 13.348835,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Nye'},\n",
       "  {'psg_id': '808671',\n",
       "   'text': 'numerical odds. The 12th-century \"Prefatio de Almaria\" invokes \"the strength of Samson and the sword of Gideon\" in the context of the Reconquista of Almería led by Ponce Giraldo de Cabrera (1147). Benedikt Gletting (16th century) invokes the \"Sword of Gideon\" in a call for a pious and confident defense of the Old Swiss Confederacy against the threat of the Franco-Ottoman alliance. The Gideon narrative was invoked by Covenanter commander Archibald Strachan prior to Battle of Carbisdale (1650). The Gideon Force was a small British-led special force in the East African Campaign during World War II. Gideon Gideon () or',\n",
       "   'score': 13.333035,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon'},\n",
       "  {'psg_id': '1125796',\n",
       "   'text': 'High School. The bulldog is the mascot for the Gideon schools. The novel \"Sins of the Flesh\" by Don and Jay Davis begins in Gideon, Missouri. Gideon, Missouri Gideon is a city in New Madrid County, Missouri, United States. The population was 1,093 at the 2010 census. Gideon had its start in 1900 as a lumber company town. The town site was platted in 1903, and named in honor of Frank Gideon, a businessperson in the lumber industry. A post office called Gideon has been in operation since 1902. Gideon is located at (36.454799, -89.918691). According to the United States',\n",
       "   'score': 13.16909,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon, Missouri'},\n",
       "  {'psg_id': '808665',\n",
       "   'text': 'and Zalmunna called on Gideon to perform the deed himself. Gideon then killed Zebah and Zalmunna as justice for the death of his brothers (). The Israelites invited Gideon to become their king and to found a dynasty, but he refused, telling them that only God was their ruler (). G. A. Cooke, writing in the Cambridge Bible for Schools and Colleges notes the discontinuity between Ephraimite anger towards Gideon shown in and the proposition of kingship over [all] Israel, and therefore concludes that \"these verses appear to come from a [secondary] source\". Gideon went on to make an \"ephod\"',\n",
       "   'score': 13.148773,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon'},\n",
       "  {'psg_id': '3833061',\n",
       "   'text': 'hall and beer bar that belonged to Ira Strickland Jr. Strickland also alleged that $50 was taken from the jukebox. Henry Cook, a 22-year-old resident who lived nearby, told the police that he had seen Gideon walk out of the bar with a bottle of wine and his pockets filled with coins, and then get into a cab. Gideon was later arrested in a tavern. Being too poor to pay for counsel, Gideon was forced to defend himself at his trial after being denied a lawyer by the trial judge, Robert McCrary Jr. On August 4, 1961, Gideon was convicted',\n",
       "   'score': 13.091242,\n",
       "   'title_score': 0,\n",
       "   'title': 'Clarence Earl Gideon'},\n",
       "  {'psg_id': '3833057',\n",
       "   'text': 'Clarence Earl Gideon Clarence Earl Gideon (August 30, 1910 – January 18, 1972) was a poor drifter and amateur attorney accused in a Florida state court of felony theft. His case resulted in the landmark U.S. Supreme Court decision \"Gideon v. Wainwright\", holding that a criminal defendant who cannot afford to hire a lawyer must be provided one at no cost. At Gideon\\'s first trial, he represented himself and was convicted. After the Supreme Court ruled that the state had to provide defense counsel for the indigent, Florida retried Gideon. At his second trial, which took place in August 1963,',\n",
       "   'score': 13.091242,\n",
       "   'title_score': 0,\n",
       "   'title': 'Clarence Earl Gideon'},\n",
       "  {'psg_id': '18304649',\n",
       "   'text': 'Gideon Hart House The Gideon Hart House is the oldest home in Westerville, Ohio, United States. Built in 1820, the home is listed on the National Register of Historic Places. Located at 636 S. Hempstead Road, it was originally built by Gideon Hart on land awarded to his father for service in the Revolutionary War. Gideon Hart and family moved from Connecticut to Ohio in 1816 to take advantage of the land tract of 380 acres. The original tract went from the current land east as far as the current Hoover Reservoir. Hart was a prominent man who built multiple',\n",
       "   'score': 13.091242,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Hart House'},\n",
       "  {'psg_id': '10592396',\n",
       "   'text': 'Gideon (TV series) Gideon was a late 1970s/early 1980s animated UK children\\'s television series. This basic animation was centred on Gideon, a duck with an unusually long neck. Gideon\\'s abnormality was the subject of cruel taunts and jibes from the other ducks – who all had normal length necks – but good always came out in the end. Gideon originated as a series of French storybooks, written by Benjamin Rabier in 1923, under the name \"Gédéon\". In the 1970s French television produced the cartoon series, directed and co-written by Michel Ocelot, which was then sold to the United Kingdom television',\n",
       "   'score': 13.091242,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon (TV series)'},\n",
       "  {'psg_id': '808658',\n",
       "   'text': 'again turned away from Yahweh after 40 years of peace brought by Deborah\\'s victory over Canaan, and Midianites, Amalekites and other Bedouin peoples who harried Israel for seven years. God chose Gideon, a young man from the tribe of Manasseh, to free the people of Israel and to condemn their idolatry. The Angel of the Lord, or \"the Lord’s angelic messenger () came \"in the character ... of a traveller who sat down in the shade [of the terebinth tree] to enjoy a little refreshment and repose\" and entered into conversation with Gideon. The narrative has echoes of the meeting',\n",
       "   'score': 13.09005,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon'},\n",
       "  {'psg_id': '17864712',\n",
       "   'text': \"robot look-alike and goes after their bus. Upon watching the Gideon-bot, Dipper and Mabel tell the bus driver, Soos, to run. Gideon chases and corners the bus at the edge of a cliff. Dipper and Mabel escape the bus, but Gideon corners them. Gideon grabs Mabel and throws Dipper aside, planning to rule Gravity Falls with Mabel as his queen. Dipper jumps off the cliff into the Gideon-bot, where he and Gideon start to fight, with Dipper beating Gideon. However, the bot loses balance and falls off the bridge, but Mabel and Dipper are saved by Mabel's grappling hook. A\",\n",
       "   'score': 13.06255,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Rises'},\n",
       "  {'psg_id': '7057956',\n",
       "   'text': \"able to amass a vast personal wealth. He also encountered and allied himself with several other Externals. He became the owner and CEO of Ophrah Industries in Denver, Colorado. At the end of the 20th century, the group began seeking out their newest member, whom Gideon erroneously believed to be Roberto da Costa, a young mutant who had joined the New Mutants, the junior division of the X-Men, and taken the codename Sunspot. Gideon had known Roberto from a young age, having business relations with his father, a wealthy Brazilian businessman. Gideon had his servant Eve poison Roberto's father Emmanuel,\",\n",
       "   'score': 13.053334,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon (comics)'},\n",
       "  {'psg_id': '5057197',\n",
       "   'text': \"O S 1727 graduated at Yale College 1749 ordained in Boston July 31, 1754 a missionary to the Indians at Onohaguage or the Six Nations installed at Mashpee April 10, 1758 died Oct'r 3 1807 AEt 80 There the wicked cease from troubling and the weary are at rest Gideon Hawley Gideon Hawley (1727–1807) was a missionary to the Iroquois Indians in Massachusetts and on the Susquehanna River in New York. He was born in the Stratfield section of Stratford, now Bridgeport, Connecticut, in New England on November 5, 1727. The son of Gideon Hawley and Hannah Bennett who was\",\n",
       "   'score': 13.053334,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Hawley'},\n",
       "  {'psg_id': '5057191',\n",
       "   'text': \"Gideon Hawley Gideon Hawley (1727–1807) was a missionary to the Iroquois Indians in Massachusetts and on the Susquehanna River in New York. He was born in the Stratfield section of Stratford, now Bridgeport, Connecticut, in New England on November 5, 1727. The son of Gideon Hawley and Hannah Bennett who was the daughter of Lieutenant James Bennett. Hawley's mother died at his birth and his father died three years later. He was the grandson of Ephraim and Sarah (Welles) Hawley from Trumbull. He was the great grandson of Joseph Hawley (Captain), first of the Hawley name to come to America\",\n",
       "   'score': 13.053334,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Hawley'},\n",
       "  {'psg_id': '4953740',\n",
       "   'text': 'who was ill at the time, by writing the letters column for \"The Invisibles\" (Vol. 1, #22). Gideon Stargrave Gideon Stargrave is a comics character created by Grant Morrison in 1978 for the anthology comic \"Near Myths\", and later incorporated into his series \"The Invisibles\". The character is based on J. G. Ballard\\'s \"The Day of Forever\" and Michael Moorcock\\'s Jerry Cornelius, which led to accusations of plagiarism from Moorcock. The first published Stargrave story appeared in \"Near Myths\" #3 (December 1978), as part one of \"Gideon Stargrave in The Vatican Conspiracy\", written and drawn by Morrison. Parts two and',\n",
       "   'score': 13.053334,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Stargrave'},\n",
       "  {'psg_id': '4953735',\n",
       "   'text': 'main character of King Mob\\'s works as an author. In these sequence, we see not only the actual Stargrave story (quoting his earlier unpublished Stargrave stories directly) but King Mob\\'s cover identity (or probable real world identity) as Gideon Starorzewski, who produces his work under the pen name Kirk Morrison. This ties the real creator (Grant Morrison) in with his various fictional creations (Gideon Stargrave and King Mob/Gideon Starorzewski/Kirk Morrison) and bringing together the various creations in a metafictional conceit. Much of the premise of \"The Invisibles\" involves the philosophy that language is a perfectly acceptable method of creation so',\n",
       "   'score': 13.053334,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Stargrave'},\n",
       "  {'psg_id': '4953733',\n",
       "   'text': 'I can still read the stuff without cringing\". In the early 1980s, Morrison and Tony O\\'Donnell went to London for a meeting with the publishers of \"Pssst!\" magazine, who said they wanted to publish Morrison\\'s Gideon Stargrave stories as well as some of their other work. Morrison said \"I\\'d done a new Gideon Stargrave story... it\\'s my favourite one I\\'ve ever done in my life and it\\'s never been seen anywhere.\" Like \"Near Myths\" though, \"Pssst!\" was cancelled before it was published, leading Morrison to \"feel that [he] was some kind of albatross\". Stargrave\\'s next appearance was in \"Gideon Stargrave',\n",
       "   'score': 13.053334,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Stargrave'},\n",
       "  {'psg_id': '3419809',\n",
       "   'text': 'Gideon Sundback Gideon Sundback (April 24, 1880 – June 21, 1954) was a Swedish-American electrical engineer, who is most commonly associated with his work in the development of the zipper. Otto Fredrik Gideon Sundback was born on Sonarp farm in Ödestugu Parish, in Jönköping County, Småland, Sweden. He was the son of Jonas Otto Magnusson Sundback, a prosperous farmer, and his wife Kristina Karolina Klasdotter. After his studies in Sweden, Sundback moved to Germany, where he studied at the polytechnic school in Bingen am Rhein. In 1903, Sundback took his engineer exam. In 1905, he emigrated to the United States.',\n",
       "   'score': 13.053334,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Sundback'},\n",
       "  {'psg_id': '2746256',\n",
       "   'text': 'troop ship, much to the relief of the general staff in Cairo, who had feared that he would meddle in the post-war politics of Ethiopia. Gideon Force Gideon Force was a small British and African special force, which acted as a \"Corps d\\'Elite\" amongst the Sudan Defence Force, Ethiopian regular forces and \"Arbegnoch\" (Patriots) fighting the Italian occupation in Ethiopia, during the East African Campaign of World War II. The leader and creator of the force was Major (later Colonel) Orde Wingate. At its peak, Gideon Force had fifty officers, twenty British NCOs, 800 trained Sudanese troops and 800 partially-trained',\n",
       "   'score': 13.053334,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Force'},\n",
       "  {'psg_id': '2746254',\n",
       "   'text': 'NCOs, Sudanese troops and Ethiopian regulars, a few mortars, no artillery and no air support, only intermittent bombing sorties. The force operated in difficult country at the end of a long and tenuous supply-line, on which nearly all of the perished. Assisted by the \"Arbegnoch\" Gideon Force ejected the Italian forces under Nasi in six weeks and captured and troops, twelve guns, many machine-guns, rifles and ammunition and over animals. Gideon Force was disbanded on 1 June 1941, Wingate was demoted to Major and returned to Egypt, as did many of the troops of Gideon Force, who joined the Long',\n",
       "   'score': 13.053334,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Force'},\n",
       "  {'psg_id': '2746232',\n",
       "   'text': 'end of a long, tenuous supply-line, on which nearly all of the used as beasts of burden, perished. Gideon Force and the \"Arbegnoch\" (Ethiopian Patriots) ejected the Italian forces under General Guglielmo Nasi, the conqueror of British Somaliland. The campaign took six weeks and captured and troops, twelve guns, many machine-guns, rifles and ammunition and over animals. Gideon Force was disbanded on 1 June 1941, Wingate was returned to his substantive rank of Major and returned to Egypt, as did many of the troops of Gideon Force, who joined the Long Range Desert Group (LRDG) of the Eighth Army. On',\n",
       "   'score': 13.053334,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Force'},\n",
       "  {'psg_id': '2689648',\n",
       "   'text': \"grandchild. Gideon Sa'ar Gideon Moshe Sa'ar (; born 9 December 1966) is a former Israeli politician who served as a member of the Knesset for the political party Likud between 2003 and 2014. During his time in government, he held the posts of Cabinet Secretary, Chairman of the Coalition Minister of the Interior and Education Minister. Gideon Moshe Zarechansky (later Sa'ar) was born in Tel Aviv. His mother, Bruriah, is of Bukharian Jewish descent while his father, Shmuel, immigrated to Israel from Argentina in the mid-1960s, settled in Sde Boker and became the personal physician of David Ben-Gurion. Sa'ar has\",\n",
       "   'score': 13.053334,\n",
       "   'title_score': 0,\n",
       "   'title': \"Gideon Sa'ar\"},\n",
       "  {'psg_id': '2689643',\n",
       "   'text': \"Gideon Sa'ar Gideon Moshe Sa'ar (; born 9 December 1966) is a former Israeli politician who served as a member of the Knesset for the political party Likud between 2003 and 2014. During his time in government, he held the posts of Cabinet Secretary, Chairman of the Coalition Minister of the Interior and Education Minister. Gideon Moshe Zarechansky (later Sa'ar) was born in Tel Aviv. His mother, Bruriah, is of Bukharian Jewish descent while his father, Shmuel, immigrated to Israel from Argentina in the mid-1960s, settled in Sde Boker and became the personal physician of David Ben-Gurion. Sa'ar has two\",\n",
       "   'score': 13.053334,\n",
       "   'title_score': 0,\n",
       "   'title': \"Gideon Sa'ar\"},\n",
       "  {'psg_id': '19399847',\n",
       "   'text': 'Carolyn Leonhart, Grace Weber and Elliot Skinner. \"The Huffington Post\" reviewed \"City Blog\" writing, \"An aurally rich group filled with sophisticated musicality, their newest self-titled album is full of vibrant arrangements, edgy lyrics, and chilled-out vibes.\" This was echoed by Music Crowns who raved that the record \"oozes pure class.\" Praise was not universal though, with Sputnikmusic saying, \"there are a few tracks that should have been left off.\" The reviewer did go on to say, \"despite this, Gideon King and City Blog\\'s self titled debut is jam packed with a little something for every music fan.\" Gideon King Gideon',\n",
       "   'score': 13.053334,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon King'},\n",
       "  {'psg_id': '17661665',\n",
       "   'text': 'up in Austria and Israel and was a member of the Palmach. Fisher has four siblings: Esti; David Fisher, who is a film director and producer; Ronel; and Amnon, a musician and an actor. Gideon Fisher is involved in a variety of public activities: The Fisher Foundation, founded by Fisher, provides scholarships and funds activities related to welfare and education. The foundation memorializes the Holocaust and helps the second generation of survivors, working to create recognition of the emotional toll they have suffered as a result of the Holocaust. Gideon Fisher Gideon Fisher () (b. August 1965) is an Israeli',\n",
       "   'score': 13.053334,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Fisher'},\n",
       "  {'psg_id': '14272183',\n",
       "   'text': \"buried at Nahalat Yitzhak cemetery in Tel Aviv on 23 September 2012. Gideon Gadot Gideon Gadot (, 1 April 1941 – 21 September 2012) was an Israeli journalist and politician who served as a member of the Knesset for Likud between 1984 and 1992. Gideon Foreman (later Gadot) was born in Bnei Brak during the Mandate era. He attended the Mikveh Israel agricultural high school before studying sociology and communications at university in South Africa. He joined the Betar youth movement in 1951, and was a member of the organisation's national leadership between 1965 and 1968. During his time in\",\n",
       "   'score': 13.053334,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Gadot'},\n",
       "  {'psg_id': '14272181',\n",
       "   'text': \"Gideon Gadot Gideon Gadot (, 1 April 1941 – 21 September 2012) was an Israeli journalist and politician who served as a member of the Knesset for Likud between 1984 and 1992. Gideon Foreman (later Gadot) was born in Bnei Brak during the Mandate era. He attended the Mikveh Israel agricultural high school before studying sociology and communications at university in South Africa. He joined the Betar youth movement in 1951, and was a member of the organisation's national leadership between 1965 and 1968. During his time in South Africa, he acted as an emissary for the organisation. He worked\",\n",
       "   'score': 13.053334,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Gadot'},\n",
       "  {'psg_id': '10851098',\n",
       "   'text': 'at the time made less than glowing comments and suggested Sinclair Lewis\\' best days were behind him. The book is not considered one of his best and is usually read by Lewis fans hoping to find a forgotten treasure similar to \"Dodsworth\" or \"The Job\". Gideon Planish Gideon Planish is a 1943 novel by American writer Sinclair Lewis. The novel tells the story of Gideon Planish, an unprincipled social climber who becomes involved in various shady philanthropic organizations in his quest for stature without accountability. The work did not fare as well with critics as some of Lewis\\' earlier social',\n",
       "   'score': 13.053334,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Planish'},\n",
       "  {'psg_id': '10579288',\n",
       "   'text': \"Gideon Greif Gideon Greif (; born 16 March 1951) is an Israeli historian who specializes in the history of the Holocaust, especially the history of the Auschwitz concentration camp and particularly the Sonderkommando in Auschwitz. Since 2011, he has been a Professor for Jewish and Israeli History at the Schusterman Center for Jewish Studies at the University of Texas at Austin. From 1965 until 1969 Gideon Greif attended Municipal High School (Gymnasium) in Tel Aviv. Later, from 1974 to 1976 he attended Tel Aviv University where he received his bachelor's degree in Jewish history, studying the history of the land\",\n",
       "   'score': 13.053334,\n",
       "   'title_score': 0,\n",
       "   'title': 'Gideon Greif'},\n",
       "  {'psg_id': '10429662',\n",
       "   'text': 'Sampson Gideon Sampson Gideon (February 1699 – 17 October 1762) was a Jewish-British banker in the City of London. He was born at London Wall, City of London, second son in five children of Rowland Gideon (\"né\" Abudiente), who traded with the West Indies, and his second wife Esther (also Jewish), daughter of Domingo (or Abraham) do Porto, a diamond buyer in Madras, India. Rowland\\'s parents were Portuguese immigrants. He was a trusted \"adviser of the Government,\" and a supporter of the Jew Bill of 1753. Early in the 1740s he married Jane (died 1778), daughter of Charles Ermell. His',\n",
       "   'score': 13.053334,\n",
       "   'title_score': 0,\n",
       "   'title': 'Sampson Gideon'}],\n",
       " 'negative_context': [],\n",
       " 'answers': ['Mandy Patinkin']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1bb012e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>raw_sample = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.samples[idx]                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 query_ids, query_types, query_pad_mask, ctx_ids, ctx_types, ctx_pad_mask = build_tokens_     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 │   </span>raw_sample[<span style=\"color: #808000; text-decoration-color: #808000\">'question'</span>],                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 │   </span>raw_sample[<span style=\"color: #808000; text-decoration-color: #808000\">'pos_context'</span>],                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6 │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.tokenizer,                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/zhangtianning/projects_local/llm/art/tasks/dense_retriever/supervised_training/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">train_data_</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">33</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">build_tokens_types_paddings_from_text</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 30 │   │   │   │   │   │   │   │   │   │     </span>tokenizer, max_seq_length):                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 31 │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Build token types and paddings, trim if needed, and pad if needed.\"\"\"</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 32 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 33 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>query_ids = tokenizer.tokenize(query)                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 34 │   </span>query_ids, query_types, query_pad_mask = build_tokens_types_paddings_from_ids(query_   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 35 │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │     </span>max_se   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 36 │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │     </span>tokeni   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'NoneType'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'tokenize'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0mraw_sample = \u001b[96mself\u001b[0m.samples[idx]                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 query_ids, query_types, query_pad_mask, ctx_ids, ctx_types, ctx_pad_mask = build_tokens_     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m\u001b[2m│   \u001b[0mraw_sample[\u001b[33m'\u001b[0m\u001b[33mquestion\u001b[0m\u001b[33m'\u001b[0m],                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[2m│   \u001b[0mraw_sample[\u001b[33m'\u001b[0m\u001b[33mpos_context\u001b[0m\u001b[33m'\u001b[0m],                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mself\u001b[0m.tokenizer,                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/zhangtianning/projects_local/llm/art/tasks/dense_retriever/supervised_training/\u001b[0m\u001b[1;33mtrain_data_\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mutils.py\u001b[0m:\u001b[94m33\u001b[0m in \u001b[92mbuild_tokens_types_paddings_from_text\u001b[0m                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 30 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │     \u001b[0mtokenizer, max_seq_length):                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 31 \u001b[0m\u001b[2m│   \u001b[0m\u001b[33m\"\"\"Build token types and paddings, trim if needed, and pad if needed.\"\"\"\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 32 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 33 \u001b[2m│   \u001b[0mquery_ids = tokenizer.tokenize(query)                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 34 \u001b[0m\u001b[2m│   \u001b[0mquery_ids, query_types, query_pad_mask = build_tokens_types_paddings_from_ids(query_   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 35 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │     \u001b[0mmax_se   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 36 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │     \u001b[0mtokeni   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'NoneType'\u001b[0m object has no attribute \u001b[32m'tokenize'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_sample = self.samples[idx]\n",
    "\n",
    "query_ids, query_types, query_pad_mask, ctx_ids, ctx_types, ctx_pad_mask = build_tokens_types_paddings_from_text(\n",
    "    raw_sample['question'],\n",
    "    raw_sample['pos_context'],\n",
    "    self.tokenizer,\n",
    "    self.max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06853b1c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if self.evaluate:\n",
    "    neg_ctx_list = raw_sample['negative_context'][:self.val_av_rank_other_neg] + \\\n",
    "                   raw_sample['hard_negative_context'][:self.val_av_rank_hard_neg]\n",
    "    neg_ctx_id_list, neg_ctx_types_list = build_token_types_from_context_list(neg_ctx_list,\n",
    "                                                                              self.tokenizer,\n",
    "                                                                              self.max_seq_length)\n",
    "elif self.train_with_neg:\n",
    "    hard_negative_ctx = raw_sample['hard_negative_context']\n",
    "    negative_ctx = raw_sample['negative_context']\n",
    "    if True:  # TODO: fix this or remove this condition\n",
    "        random.shuffle(hard_negative_ctx)\n",
    "        random.shuffle(negative_ctx)\n",
    "\n",
    "    neg_ctx_list = hard_negative_ctx[:self.train_hard_neg]\n",
    "    # In the Google NQ dataset by DPR paper, there are around more than 50 missing hard negatives in training data.\n",
    "    # In those cases, substitute hard negatives by simple negatives.\n",
    "    if len(neg_ctx_list) < self.train_hard_neg:\n",
    "        neg_ctx_list += negative_ctx[:self.train_hard_neg - len(neg_ctx_list)]\n",
    "\n",
    "    neg_ctx_id_list, neg_ctx_types_list = build_token_types_from_context_list(neg_ctx_list,\n",
    "                                                                              self.tokenizer,\n",
    "                                                                              self.max_seq_length)\n",
    "else:\n",
    "    neg_ctx_id_list = None\n",
    "    neg_ctx_types_list = None\n",
    "\n",
    "sample = build_sample(query_ids, query_types, query_pad_mask,\n",
    "                      ctx_ids, ctx_types, ctx_pad_mask,\n",
    "                      raw_sample['answers'],\n",
    "                      neg_ctx_id_list, neg_ctx_types_list,\n",
    "                      include_neg=self.evaluate or self.train_with_neg)\n",
    "return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e7b4d9",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dominance ordering {{cite:4f8f559a4b2647def6e5c22a8f895bb9610fd10b}} is defined in the following way.\\nConsider two partitions of the integer {{formula:52949879-7f7d-4f72-8b48-6efdfe8d02c0}} : {{formula:4df4d21f-2211-4ef1-98c2-e78bec14a089}}  and\\n{{formula:988399d8-5bb4-483e-adaa-23ca94affa19}} . Then\\n{{formula:e72e5e80-2d37-4803-8c0f-578b10242eb6}} \\n i.e. the prefix sums of {{formula:26fef996-14ee-469f-abb6-56ff6a03f12b}}  are greater than or equal to\\nthe prefix sums of {{formula:e2d4f490-a378-42ae-9a7e-ae6a48b9e955}} .\\nFrom {{cite:2cedfc1a6c8cb2ab2d588fc26ca023e48c3e2241}}, it is known that the set of partitions of an\\ninteger {{formula:f29d3b3c-86ea-4781-aa9f-c38981972acc}}  equiped with the dominance ordering is a lattice denoted\\nby {{formula:1f7ac1c5-48fa-4a99-9d4c-4c05649b36e3}} . In this paper, Brylawski proposed a dynamical approach to study\\nthis lattice. We will introduce a few notations to explain\\nit intuitively. For more details about integer partitions, we refer\\nto {{cite:37672fc605a1ec41ecd79df884d74fd34ab944ee}}.\\n\n"
     ]
    }
   ],
   "source": [
    "print(\"The dominance ordering {{cite:4f8f559a4b2647def6e5c22a8f895bb9610fd10b}} is defined in the following way.\\\\nConsider two partitions of the integer {{formula:52949879-7f7d-4f72-8b48-6efdfe8d02c0}} : {{formula:4df4d21f-2211-4ef1-98c2-e78bec14a089}}  and\\\\n{{formula:988399d8-5bb4-483e-adaa-23ca94affa19}} . Then\\\\n{{formula:e72e5e80-2d37-4803-8c0f-578b10242eb6}} \\\\n i.e. the prefix sums of {{formula:26fef996-14ee-469f-abb6-56ff6a03f12b}}  are greater than or equal to\\\\nthe prefix sums of {{formula:e2d4f490-a378-42ae-9a7e-ae6a48b9e955}} .\\\\nFrom {{cite:2cedfc1a6c8cb2ab2d588fc26ca023e48c3e2241}}, it is known that the set of partitions of an\\\\ninteger {{formula:f29d3b3c-86ea-4781-aa9f-c38981972acc}}  equiped with the dominance ordering is a lattice denoted\\\\nby {{formula:1f7ac1c5-48fa-4a99-9d4c-4c05649b36e3}} . In this paper, Brylawski proposed a dynamical approach to study\\\\nthis lattice. We will introduce a few notations to explain\\\\nit intuitively. For more details about integer partitions, we refer\\\\nto {{cite:37672fc605a1ec41ecd79df884d74fd34ab944ee}}.\\\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5d70558",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'model': 'gala120b', 'prompt': \"A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\n",
      "### Human: What are the key differences between renewable and non-renewable energy sources?\n",
      "### Assistant: Renewable energy sources are those that can be replenished naturally in a relatively short amount of time, such as solar, wind, hydro, geothermal, and biomass. Non-renewable energy sources, on the other hand, are finite and will eventually be depleted, such as coal, oil, and natural gas. Here are some key differences between renewable and non-renewable energy sources:\n",
      "1. Availability: Renewable energy sources are virtually inexhaustible, while non-renewable energy sources are finite and will eventually run out.\n",
      "2. Environmental impact: Renewable energy sources have a much lower environmental impact than non-renewable sources, which can lead to air and water pollution, greenhouse gas emissions, and other negative effects.\n",
      "3. Cost: Renewable energy sources can be more expensive to initially set up, but they typically have lower operational costs than non-renewable sources.\n",
      "4. Reliability: Renewable energy sources are often more reliable and can be used in more remote locations than non-renewable sources.\n",
      "5. Flexibility: Renewable energy sources are often more flexible and can be adapted to different situations and needs, while non-renewable sources are more rigid and inflexible.\n",
      "6. Sustainability: Renewable energy sources are more sustainable over the long term, while non-renewable sources are not, and their depletion can lead to economic and social instability.\n",
      "### Human: Give me the derivation of Evidence Lower Bound (ELBO) algorithm step by step\n",
      "### Assistant:\", 'temperature': 0.7, 'max_new_tokens': 512, 'stop': '###', 'stop_token_ids': None, 'echo': False}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('''\n",
    "{'model': 'gala120b', 'prompt': \"A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\\n### Human: What are the key differences between renewable and non-renewable energy sources?\\n### Assistant: Renewable energy sources are those that can be replenished naturally in a relatively short amount of time, such as solar, wind, hydro, geothermal, and biomass. Non-renewable energy sources, on the other hand, are finite and will eventually be depleted, such as coal, oil, and natural gas. Here are some key differences between renewable and non-renewable energy sources:\\n1. Availability: Renewable energy sources are virtually inexhaustible, while non-renewable energy sources are finite and will eventually run out.\\n2. Environmental impact: Renewable energy sources have a much lower environmental impact than non-renewable sources, which can lead to air and water pollution, greenhouse gas emissions, and other negative effects.\\n3. Cost: Renewable energy sources can be more expensive to initially set up, but they typically have lower operational costs than non-renewable sources.\\n4. Reliability: Renewable energy sources are often more reliable and can be used in more remote locations than non-renewable sources.\\n5. Flexibility: Renewable energy sources are often more flexible and can be adapted to different situations and needs, while non-renewable sources are more rigid and inflexible.\\n6. Sustainability: Renewable energy sources are more sustainable over the long term, while non-renewable sources are not, and their depletion can lead to economic and social instability.\\n### Human: Give me the derivation of Evidence Lower Bound (ELBO) algorithm step by step\\n### Assistant:\", 'temperature': 0.7, 'max_new_tokens': 512, 'stop': '###', 'stop_token_ids': None, 'echo': False}\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd8623a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A partition of the integer {{formula:2565c197-8a60-4503-af8b-4efa1ca8d8ba}}  is a {{formula:c439eeb8-812b-497a-9a72-8407d90cfbfb}} -tuple {{formula:c49dea42-c345-470a-b733-41e10b7b3037}} \n",
      "of positive integers such that {{formula:fc81d36e-9235-4cb3-b00e-625611d221f7}}  and\n",
      "{{formula:9fa6291b-d38e-4c86-b986-61fd4ca91dd7}}  for all {{formula:4017aef1-e3ff-4e75-b078-e14c599b7c24}}  between 1 and {{formula:27266042-85d6-4805-99f2-fe0ac94aa4a2}}  (with the\n",
      "assumption that {{formula:7a491f87-bc22-4bae-856c-0d0d715cf4c0}} ).\n",
      "The Ferrers diagram of a partition {{formula:c4cac4f6-8a2a-4edc-abcc-3d8a68bd7fc4}}  is a\n",
      "drawing of {{formula:0d55a55c-ad9f-4e0f-b32a-2f9d2a42ac81}}  on {{formula:93c7a1d6-30f3-4cb1-bab3-3033de5484fe}}  adjacent columns such that the {{formula:e60ce57e-f521-4749-9fd3-cab0e609b26c}} -th column\n",
      "is a pile of {{formula:8c4b07e6-059e-4d01-81e2-26fb6a64b0cf}}  packed squares (called grains). See\n",
      "Figure REF  for examples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"A partition of the integer {{formula:2565c197-8a60-4503-af8b-4efa1ca8d8ba}}  is a {{formula:c439eeb8-812b-497a-9a72-8407d90cfbfb}} -tuple {{formula:c49dea42-c345-470a-b733-41e10b7b3037}} \\nof positive integers such that {{formula:fc81d36e-9235-4cb3-b00e-625611d221f7}}  and\\n{{formula:9fa6291b-d38e-4c86-b986-61fd4ca91dd7}}  for all {{formula:4017aef1-e3ff-4e75-b078-e14c599b7c24}}  between 1 and {{formula:27266042-85d6-4805-99f2-fe0ac94aa4a2}}  (with the\\nassumption that {{formula:7a491f87-bc22-4bae-856c-0d0d715cf4c0}} ).\\nThe Ferrers diagram of a partition {{formula:c4cac4f6-8a2a-4edc-abcc-3d8a68bd7fc4}}  is a\\ndrawing of {{formula:0d55a55c-ad9f-4e0f-b32a-2f9d2a42ac81}}  on {{formula:93c7a1d6-30f3-4cb1-bab3-3033de5484fe}}  adjacent columns such that the {{formula:e60ce57e-f521-4749-9fd3-cab0e609b26c}} -th column\\nis a pile of {{formula:8c4b07e6-059e-4d01-81e2-26fb6a64b0cf}}  packed squares (called grains). See\\nFigure\\u00a0REF  for examples.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f371beb1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80902b5d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2528223171.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [23], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    json.dumps({'question': '1-dim representations of the affine Hecke algebra for $G = \\text{SL}_2$', 'answer': 'geometric methods in representation theory of hecke algebras and quantum   groups', 'positive_ctxs': [{'title': 'geometric methods in representation theory of hecke algebras and quantum   groups', 'abstract': 'these lectures given in montreal in summer 1997 are mainly based on, and form a condensed survey of, the book by n. chriss and v. ginzburg: `representation theory and complex geometry', birkhauser 1997.   various algebras arising naturally in representation theory such as the group algebra of a weyl group, the universal enveloping algebra of a complex semisimple lie algebra, a quantum group or the iwahori-hecke algebra of bi-invariant functions (under convolution) on a p-adic group, are considered.   we give a uniform geometric construction of these algebras in terms of homology of an appropriate \"steinberg-type\" variety z (or its modification, such as k-theory or elliptic cohomology of z, or an equivariant version thereof). we then explain how to obtain a complete classification of finite dimensional irreducible representations of the algebras in question, using our geometric construction and perverse sheaves methods.   similar techniques can be applied to other algebras, e.g. the double-affine hecke algebras, elliptic algebras, quantum toroidal algebras.'}], 'negative_ctxs': [], 'hard_negative_ctxs': []})\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "json.dumps({'question': '1-dim representations of the affine Hecke algebra for $G = \\text{SL}_2$', 'answer': 'geometric methods in representation theory of hecke algebras and quantum   groups', 'positive_ctxs': [{'title': 'geometric methods in representation theory of hecke algebras and quantum   groups', 'abstract': 'these lectures given in montreal in summer 1997 are mainly based on, and form a condensed survey of, the book by n. chriss and v. ginzburg: `representation theory and complex geometry', birkhauser 1997.   various algebras arising naturally in representation theory such as the group algebra of a weyl group, the universal enveloping algebra of a complex semisimple lie algebra, a quantum group or the iwahori-hecke algebra of bi-invariant functions (under convolution) on a p-adic group, are considered.   we give a uniform geometric construction of these algebras in terms of homology of an appropriate \"steinberg-type\" variety z (or its modification, such as k-theory or elliptic cohomology of z, or an equivariant version thereof). we then explain how to obtain a complete classification of finite dimensional irreducible representations of the algebras in question, using our geometric construction and perverse sheaves methods.   similar techniques can be applied to other algebras, e.g. the double-affine hecke algebras, elliptic algebras, quantum toroidal algebras.'}], 'negative_ctxs': [], 'hard_negative_ctxs': []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a14cf",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Lets check the Tokenized_Knowledge_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89538dec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "args.indexed_evidence_bert_tokenized_data_path = \"./data/unarXive/evidence-unarxiv-indexed-mmap/bert/unarxiv-keyword-evidence-bert_text_document\"\n",
    "args.indexed_title_bert_tokenized_data_path    = \"./data/unarXive/evidence-unarxiv-indexed-mmap/bert/unarxiv-keyword-evidence-bert_title_document\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98d6b5d9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> building BertWordPieceLowerCase tokenizer with 0 extra vocab ids...\n",
      " > padded vocab (size: 30524) with 68 dummy tokens (new size: 30592)\n"
     ]
    }
   ],
   "source": [
    "_ = _build_tokenizer(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f722c32",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >>>>> will collect knowledge via [bert.both_query_and_passage] way\n",
      " >>>>> will collect knowledge information from  [('./data/unarXive/evidence-unarxiv-indexed-mmap/bert/unarxiv-keyword-evidence-bert_text_document', './data/unarXive/evidence-unarxiv-indexed-mmap/bert/unarxiv-keyword-evidence-bert_title_document')]\n",
      "  >> total collect 154646 passages\n"
     ]
    }
   ],
   "source": [
    "from megatron.data.pretokenized_evidence import Tokenized_Knowledge_Dataset\n",
    "bert_knowledge = Tokenized_Knowledge_Dataset((args.indexed_evidence_bert_tokenized_data_path, \n",
    "                                             args.indexed_title_bert_tokenized_data_path),\n",
    "        args.data_impl,\n",
    "        get_tokenizer(),args.seq_length_retriever, mode='bert.both_query_and_passage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab7d96ca",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc3da7c1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['row_id', 'title_text_ids'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_knowledge[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1df8439",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] what is minkowskian [SEP] we demonstrate that assuming the \" discrete \" vacuum geometry in the minkowskian higgs model with vacuum bps monopole solutions can justify the dirac fundamental quantization of that model. the important constituent of this quantization is getting various rotary effects, including collective solid rotations inside the physical bps monopole vacuum, and just assuming the \" discrete \" vacuum geometry seems to be that thing able to justify these rotary effects. more precisely, assuming the \" discrete \" geometry for the appropriate vacuum manifold implies the presence of thread topological defects ( side by side with point hedgehog topological defects and walls between different topological domains ) inside this manifold in the shape of specific ( rectilinear ) threads : gauge and higgs fields located in the spatial region intimately near the axis $ z $ of the chosen ( rest ) reference frame. this serves as the source of collective solid rotations proceeding inside the bps monopole vacuum suffered the dirac fundamental quantization. it will be argued that indeed the first - order phase transition occurs in the minkowskian higgs model with vacuum bps monopoles quantized by dirac. this comes to the coexistence of two thermodynamic phases inside the appropriate bp [SEP]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(bert_knowledge[0]['title_text_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6962d488",
   "metadata": {},
   "source": [
    "# lets start tracing - Supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1443fc9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### load config, data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a34f3e82",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tasks.dense_retriever.supervised_training.run import *\n",
    "\n",
    "from tasks.dense_retriever.supervised_training.train_data_utils import Dataset as dataset_cls\n",
    "\n",
    "import torch\n",
    "\n",
    "from megatron.global_vars import _build_tokenizer,_set_tensorboard_writer,_set_timers\n",
    "from megatron.initialize import initialize_megatron\n",
    "\n",
    "args = get_args()\n",
    "_ = _build_tokenizer(args)\n",
    "_set_tensorboard_writer(args)\n",
    "_set_timers()\n",
    "\n",
    "\n",
    "initialize_megatron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1908fd2a",
   "metadata": {
    "code_folding": [
     0,
     16,
     23,
     34
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train_valid_datasets_provider():\n",
    "        args = get_args()\n",
    "        tokenizer = get_tokenizer()\n",
    "\n",
    "        train_dataset = dataset_cls(\"training\",\n",
    "                                    args.train_data,\n",
    "                                    tokenizer,\n",
    "                                    args.seq_length_retriever,\n",
    "                                    evaluate=False)\n",
    "        valid_dataset = dataset_cls(\"validation\",\n",
    "                                    args.valid_data,\n",
    "                                    tokenizer,\n",
    "                                    args.seq_length_retriever,\n",
    "                                    evaluate=True)\n",
    "        return train_dataset, valid_dataset\n",
    "\n",
    "def model_provider():\n",
    "    args = get_args()\n",
    "    print_rank_0('building retriever model for {} ...'.format(args.task))\n",
    "    model = dualencoder_model_provider(only_context_model=False,\n",
    "                                       only_query_model=False)\n",
    "    return model\n",
    "\n",
    "def single_dataset_provider(datapath):\n",
    "    args = get_args()\n",
    "    tokenizer = get_tokenizer()\n",
    "    name_from_datapath = datapath[0].split('/')[-1].split('.')[0]\n",
    "\n",
    "    return dataset_cls(name_from_datapath,\n",
    "                       datapath,\n",
    "                       tokenizer,\n",
    "                       args.seq_length_retriever,\n",
    "                       evaluate=True)\n",
    "\n",
    "def distributed_metrics_func_provider(datapath):\n",
    "    return accuracy_func_provider(single_dataset_provider, datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65efeec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train(train_valid_datasets_provider,\n",
    "#       model_provider,\n",
    "#       end_of_epoch_callback_provider=distributed_metrics_func_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54053aef",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b036082",
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------> use fixed config <----------\n",
      " > building open-domain retrieval dataset for validation:\n",
      "  > paths: ./data/webq/biencoder-webquestions-train.json\n",
      "---------> use fixed config <----------\n",
      " > Processing ./data/webq/biencoder-webquestions-train.json ...\n",
      " >> processed 2447 samples.\n",
      "---------> use fixed config <----------\n",
      "  >> total number of samples: 2447\n",
      "---------> use fixed config <----------\n",
      " > building open-domain retrieval dataset for validation:\n",
      "  > paths: ./data/webq/biencoder-webquestions-dev.json\n",
      "---------> use fixed config <----------\n",
      " > Processing ./data/webq/biencoder-webquestions-dev.json ...\n",
      " >> processed 276 samples.\n",
      "---------> use fixed config <----------\n",
      "  >> total number of samples: 276\n"
     ]
    }
   ],
   "source": [
    "# train_dataset, valid_dataset = train_valid_datasets_provider()\n",
    "args=args = get_args()\n",
    "tokenizer = get_tokenizer()\n",
    "train_dataset = dataset_cls(\"validation\",\n",
    "                            args.train_data,\n",
    "                            tokenizer,\n",
    "                            args.seq_length_retriever,\n",
    "                            evaluate=False)\n",
    "valid_dataset = dataset_cls(\"validation\",\n",
    "                            args.valid_data,\n",
    "                            tokenizer,\n",
    "                            args.seq_length_retriever,\n",
    "                            evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3587764f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'query_mask', 'query_types', 'query_pad_mask', 'context', 'context_mask', 'context_types', 'context_pad_mask', 'reference', 'neg_context', 'neg_context_types', 'neg_context_mask'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "372714e4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tasks.dense_retriever.supervised_training.train_dense_retriever import _build_train_valid_dataloaders,setup_model_and_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6471e1b0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from megatron import mpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ec7486f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------> use fixed config <----------\n",
      "building train and validation dataloaders ...\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, valid_dataloader = _build_train_valid_dataloaders(train_dataset, valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7964090",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "building retriever model for RETRIEVER ...\n",
      "---------> use fixed config <----------\n",
      "building DualEncoderModel...\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      " > number of parameters on model parallel rank 0: 668327936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsw-23976-7d79d88dc8-j998v:250853:250853 [0] NCCL INFO Bootstrap : Using eth0:10.246.119.4<0>\n",
      "dsw-23976-7d79d88dc8-j998v:250853:250853 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation\n",
      "dsw-23976-7d79d88dc8-j998v:250853:250853 [0] NCCL INFO cudaDriverVersion 11040\n",
      "NCCL version 2.14.3+cuda11.7\n",
      "dsw-23976-7d79d88dc8-j998v:250853:250954 [0] NCCL INFO Failed to open libibverbs.so[.1]\n",
      "dsw-23976-7d79d88dc8-j998v:250853:250954 [0] NCCL INFO NET/Socket : Using [0]eth0:10.246.119.4<0>\n",
      "dsw-23976-7d79d88dc8-j998v:250853:250954 [0] NCCL INFO Using network Socket\n",
      "dsw-23976-7d79d88dc8-j998v:250853:250954 [0] NCCL INFO NCCL_MAX_NCHANNELS set by environment to 2.\n",
      "dsw-23976-7d79d88dc8-j998v:250853:250954 [0] NCCL INFO NCCL_MIN_NCHANNELS set by environment to 2.\n",
      "dsw-23976-7d79d88dc8-j998v:250853:250954 [0] NCCL INFO Channel 00/02 :    0\n",
      "dsw-23976-7d79d88dc8-j998v:250853:250954 [0] NCCL INFO Channel 01/02 :    0\n",
      "dsw-23976-7d79d88dc8-j998v:250853:250954 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1\n",
      "dsw-23976-7d79d88dc8-j998v:250853:250954 [0] NCCL INFO Connected all rings\n",
      "dsw-23976-7d79d88dc8-j998v:250853:250954 [0] NCCL INFO Connected all trees\n",
      "dsw-23976-7d79d88dc8-j998v:250853:250954 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "dsw-23976-7d79d88dc8-j998v:250853:250954 [0] NCCL INFO comm 0x58161320 rank 0 nranks 1 cudaDev 0 busId 70 - Init COMPLETE\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "> learning rate decay style: linear\n",
      "---------> use fixed config <----------\n",
      "WARNING: could not find the metadata file ./checkpoints/dualencoder-mss-dpr-large-epochs20-webq/latest_checkpointed_iteration.txt \n",
      "    will not load any checkpoints and will start from random\n",
      "Initializing from pretrained BERT model\n",
      "---------> use fixed config <----------\n",
      "global rank 0 is loading BERT checkpoint ./checkpoints/megatron_bert_345m/release/mp_rank_00/model_optim_rng.pt\n"
     ]
    }
   ],
   "source": [
    "model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "97dc285b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from megatron.model import get_params_for_weight_decay_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8f66ec2d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "param_groups = get_params_for_weight_decay_optimization(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d95698ba",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "param_groups[0]['params'][0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0d8ad6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## go into train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "601d7c5d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fetcher= iter(train_dataloader)\n",
    "batch = next(fetcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91aa1ca7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['query'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf02c779",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### go into `_cross_entropy_forward_step`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fddf8d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "losses_dict, skipped_iter = train_step(forward_step, batch, model,optimizer, lr_scheduler)\n",
    "--------------\n",
    "loss, loss_reduced = forward_step_func(data_iterator, model)\n",
    "--------------\n",
    "_cross_entropy_forward_step(batch, model)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed706463",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tasks.dense_retriever.supervised_training.train_dense_retriever import process_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dc87b9a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query_tokens, query_mask, query_types, query_pad_mask, \\\n",
    "    context_tokens, context_mask, context_types, context_pad_mask, \\\n",
    "    neg_context_tokens, neg_context_mask, neg_context_types, \\\n",
    "    reference = process_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32ba0e1b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "local_batch_size = query_tokens.shape[0]\n",
    "\n",
    "# Text representation of query and context\n",
    "query_list, context_list = [], []\n",
    "for i in range(local_batch_size):\n",
    "    query_list.append(tokenizer.decode(query_tokens[i].tolist()))\n",
    "    context_list.append(tokenizer.decode(context_tokens[i].tolist()))\n",
    "\n",
    "if neg_context_tokens is not None:\n",
    "    context_tokens = torch.cat([context_tokens, neg_context_tokens])\n",
    "    context_mask = torch.cat([context_mask, neg_context_mask])\n",
    "    context_types = torch.cat([context_types, neg_context_types])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc6a5c37",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] what inventions did leonardo da vinci made [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] what year did kobe bryant go to high school [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "18834199",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[CLS] science and inventions of leonardo da vinci [SEP] itself would have rotated in the opposite direction to the rotor. while he designed a number of man powered flying machines with mechanical wings that flapped, he also designed a parachute and a light hang glider which could have flown. the viola organista was an experimental musical instrument invented by leonardo da vinci. it was the first bowed keyboard instrument ( of which any record has survived ) ever to be devised. leonardo's original idea, as preserved in his notebooks of 1488 – 1489 and in the drawings in the codex atlanticus, was to use one or more wheels, continuously rotating, each of which [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\",\n",
       " '[CLS] kobe bryant [SEP] the most seasons playing with one franchise for an entire career and is widely regarded as one of the greatest basketball players of all time. bryant is the first guard in nba history to play at least 20 seasons. the son of former nba player joe bryant, kobe bryant enjoyed a successful high school basketball career at lower merion high school in pennsylvania, where he was recognized as the top high school basketball player in the country. he declared for the nba draft upon graduation and was selected in the 13th overall pick in the 1996 nba draft by the [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd195e31",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query_logits, context_logits = model(query_tokens,query_mask,query_types,\n",
    "                                   context_tokens,context_mask,context_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a7b384d0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from megatron.model.bert_model import bert_attention_mask_func, bert_position_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "78bcd271",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "28cd1ff9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.add_pooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a61a02bb",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.add_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b0a8fdf5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1024])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b32a899a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256, 1024])\n",
      "torch.Size([2, 256, 1024])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">28</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">25 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(encoder_output.shape)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> llm.add_pooler:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">27 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>pooled_output = llm.pooler(encoder_output,pooling_sequence_index)                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>28 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(pooled_output.shape)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">29 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">#lm_output = llm(input_ids,position_ids,extended_attention_mask,tokentype_ids=tokent</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">30 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">#query_logits = themodel(query_tokens,query_mask,query_types)</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'pooled_output'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m28\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m25 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mprint\u001b[0m(encoder_output.shape)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m26 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m llm.add_pooler:                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m27 \u001b[0m\u001b[2m│   │   \u001b[0mpooled_output = llm.pooler(encoder_output,pooling_sequence_index)                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m28 \u001b[2m│   \u001b[0m\u001b[96mprint\u001b[0m(pooled_output.shape)                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m29 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m#lm_output = llm(input_ids,position_ids,extended_attention_mask,tokentype_ids=tokent\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m30 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m#query_logits = themodel(query_tokens,query_mask,query_types)\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m31 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'pooled_output'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    themodel = model.module.module.query_model\n",
    "    input_ids, attention_mask, tokentype_ids = query_tokens,query_mask,query_types\n",
    "    extended_attention_mask = attention_mask.unsqueeze(1)\n",
    "    position_ids = bert_position_ids(input_ids)\n",
    "    llm = themodel.language_model\n",
    "    enc_input_ids = input_ids;\n",
    "    enc_position_ids = position_ids;\n",
    "    enc_attention_mask = extended_attention_mask;\n",
    "    tokentype_ids=tokentype_ids;\n",
    "    dec_input_ids=None;dec_position_ids=None;dec_attn_mask=None;enc_dec_attn_mask=None;\n",
    "    layer_past=None;get_key_value=False;pooling_sequence_index=0;\n",
    "    enc_hidden_states=None;output_enc_hidden=False;sim_scores=None;\n",
    "    print(enc_input_ids.shape)\n",
    "    print(enc_position_ids.shape)\n",
    "    print(tokentype_ids.shape)\n",
    "    enc_embedding_output = llm.embedding(enc_input_ids,\n",
    "                                      enc_position_ids,\n",
    "                                      tokentype_ids=tokentype_ids)\n",
    "    print(enc_embedding_output.shape)\n",
    "    if enc_hidden_states is None:\n",
    "        encoder_output = llm.encoder(enc_embedding_output,enc_attention_mask,layer_past=layer_past,get_key_value=get_key_value)\n",
    "    else:\n",
    "        encoder_output = enc_hidden_states.to(enc_embedding_output.dtype)\n",
    "    print(encoder_output.shape)\n",
    "    if llm.add_pooler:\n",
    "        pooled_output = llm.pooler(encoder_output,pooling_sequence_index)\n",
    "        print(pooled_output.shape)\n",
    "    #lm_output = llm(input_ids,position_ids,extended_attention_mask,tokentype_ids=tokentype_ids)\n",
    "    #query_logits = themodel(query_tokens,query_mask,query_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c82bc4f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tasks.dense_retriever.supervised_training.train_dense_retriever import get_group_world_size_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5cd19873",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "group, rank, world_size = get_group_world_size_rank()\n",
    "global_batch_size = world_size * local_batch_size  # recall we assert that model_parallel_size == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90489292",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_query_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73db5bd3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1747928f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_query_logits = query_logits\n",
    "all_context_logits = context_logits\n",
    "\n",
    "retrieval_scores = torch.matmul(all_query_logits,torch.transpose(all_context_logits, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3d7deb1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tasks.dense_retriever.supervised_training.train_dense_retriever import F,reduce_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01b8b110",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e285302c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1024])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8087f71a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12,  5], device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1976740b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_query_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3517dd4e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query                          --> torch.Size([2, 256])\n",
      "query_mask                     --> torch.Size([2, 256, 256])\n",
      "query_types                    --> torch.Size([2, 256])\n",
      "query_pad_mask                 --> torch.Size([2, 256])\n",
      "context                        --> torch.Size([2, 256])\n",
      "context_mask                   --> torch.Size([2, 256, 256])\n",
      "context_types                  --> torch.Size([2, 256])\n",
      "context_pad_mask               --> torch.Size([2, 256])\n",
      "reference                     \n",
      "neg_context                    --> torch.Size([14, 256])\n",
      "neg_context_types              --> torch.Size([14, 256])\n",
      "neg_context_mask               --> torch.Size([14, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for key, val in batch.items():\n",
    "    try:\n",
    "        print(f\"{key:30s} --> {val.shape}\")\n",
    "    except:\n",
    "        print(f\"{key:30s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76fd82fa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "labels = torch.arange(global_batch_size).long().cuda()\n",
    "\n",
    "# Cross-entropy loss.\n",
    "softmax_scores = F.log_softmax(retrieval_scores, dim=1)\n",
    "\n",
    "loss = F.nll_loss(softmax_scores, labels, reduction='mean')\n",
    "\n",
    "max_score, max_idxs = torch.max(softmax_scores, 1)\n",
    "correct_predictions_count = (max_idxs == labels).sum().float()\n",
    "\n",
    "# Reduce loss for logging.\n",
    "reduced_loss = reduce_losses([loss, correct_predictions_count])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "918e26a0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b27045f",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([26.7394,  0.0000], device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d3fc82",
   "metadata": {},
   "source": [
    "# lets start tracing - Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ff84aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------> use fixed config <----------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "os.environ[\"NCCL_DEBUG\"] = \"WARN\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "from tasks.dense_retriever.supervised_training.run import *\n",
    "from tasks.dense_retriever.zero_shot_training.train_data_utils import OpenQADataset as dataset_cls\n",
    "\n",
    "import torch\n",
    "from megatron.global_vars import _build_t0_tokenizer,_build_t0_model,_load_wikipedia_evidence,_build_tokenizer,_set_tensorboard_writer,_set_timers\n",
    "from megatron.initialize import initialize_megatron\n",
    "\n",
    "import torch\n",
    "from megatron.global_vars import _build_t0_tokenizer,_build_t0_model,_load_wikipedia_evidence,_build_tokenizer,_set_tensorboard_writer,_set_timers\n",
    "from megatron.initialize import initialize_megatron\n",
    "from megatron.global_vars import _build_knowledge_pool_in_bert,_build_knowledge_pool_in_t0\n",
    "\n",
    "args = get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37708c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> building BertWordPieceLowerCase tokenizer with 0 extra vocab ids...\n",
      " > padded vocab (size: 30524) with 68 dummy tokens (new size: 30592)\n"
     ]
    }
   ],
   "source": [
    "_ = _build_tokenizer(args)\n",
    "_ = _build_t0_tokenizer(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad1a01e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = get_bert_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b89c18de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.load(\"debug.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71a1b901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 256])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4107e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer as HFBertTokenizer\n",
    "\n",
    "\n",
    "hf_bert_tokenizer = HFBertTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "hf_bert_tokenizer.decode(tensor[2], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5712f4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"id elements are short interspersed elements ( sines ) found in high copy number in many rodent genomes. bc1 rna, an id - related transcript, is derived from the single copy bc1 rna gene. the bc1 rna gene has been shown to be a master gene for id element amplification in rodent genomes. id elements are dispersed through a process termed retroposition. the retroposition process involves a number of potential regulatory steps. these regulatory steps may include transcription in the appropriate tissue, transcript stability, priming of the rna transcript for reverse transcription and integration. this study focuses on priming of the rna transcript for reverse transcription. bc1 rna gene transcripts are shown to be able to prime their own reverse transcription in an efficient intramolecular and site - specific fashion. this self - priming ability is a consequence of the secondary structure of the 3'- unique region. the observation that a gene actively amplified throughout rodent evolution makes a rna capable of efficient self - primed reverse transcription strongly suggests that self - priming is at least one feature establishing the bc1 rna gene as a master gene for amplification of id elements.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aa1ef08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> building BertWordPieceLowerCase tokenizer with 0 extra vocab ids...\n",
      " > padded vocab (size: 30524) with 68 dummy tokens (new size: 30592)\n",
      " >>>>> will collect knowledge via [bert.only_passage] way\n",
      " >>>>> will collect knowledge information from  [('./data/evidence-wikipedia-indexed-mmap/bert/wikipedia-evidence-bert_text_document', './data/evidence-wikipedia-indexed-mmap/bert/wikipedia-evidence-bert_title_document')]\n",
      "Dataset does not exist: ./data/evidence-wikipedia-indexed-mmap/bert/wikipedia-evidence-bert_text_document\n",
      "Path should be a basename that both .idx and .bin can be appended to get full filenames.\n",
      "Dataset does not exist: ./data/evidence-wikipedia-indexed-mmap/bert/wikipedia-evidence-bert_title_document\n",
      "Path should be a basename that both .idx and .bin can be appended to get full filenames.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>_ = _build_tokenizer(args)                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>_ = _build_t0_tokenizer(args)                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 _ = _build_knowledge_pool_in_bert(args)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>_ = _build_knowledge_pool_in_t0(args)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">global_vars.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">531</span> in                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_build_knowledge_pool_in_bert</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">528 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Initialize T0 tokenizer.\"\"\"</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">529 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">global</span> _GLOBAL_KNOWLEDGE                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">530 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #808000; text-decoration-color: #808000\">'bert'</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> _GLOBAL_KNOWLEDGE                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>531 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>_GLOBAL_KNOWLEDGE[<span style=\"color: #808000; text-decoration-color: #808000\">'bert'</span>] = Tokenized_Knowledge_Dataset(                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">532 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>(args.indexed_evidence_bert_tokenized_data_path, args.indexed_title_bert_tokeniz   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">533 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │    </span>args.data_impl,                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">534 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>get_tokenizer(),args.seq_length_retriever                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">pretokenized_evidence.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">25</span> in   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 22 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>indexed_evidence_bert_tokenized_data_path, indexed_title_bert_tokenized_data_pat   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 23 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.passages_map_bert = make_indexed_dataset(indexed_evidence_bert_tokenized_da   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 24 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.title_map_bert    = make_indexed_dataset(indexed_title_bert_tokenized_data_   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 25 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>print_rank_0(<span style=\"color: #808000; text-decoration-color: #808000\">f'  &gt;&gt; total collect {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.passages_map_bert)<span style=\"color: #808000; text-decoration-color: #808000\">} passages'</span>)         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 26 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.passages_map_bert <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">f\"you must provide the passage knowle</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 27 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> mode == <span style=\"color: #808000; text-decoration-color: #808000\">'bert.both_query_and_passage'</span>:                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 28 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.title_map_bert <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">f\"you must provide the title pool fo</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span>object of type <span style=\"color: #008000; text-decoration-color: #008000\">'NoneType'</span> has no <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">len</span><span style=\"font-weight: bold\">()</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0m_ = _build_tokenizer(args)                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m_ = _build_t0_tokenizer(args)                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 _ = _build_knowledge_pool_in_bert(args)                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m_ = _build_knowledge_pool_in_t0(args)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/\u001b[0m\u001b[1;33mglobal_vars.py\u001b[0m:\u001b[94m531\u001b[0m in                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_build_knowledge_pool_in_bert\u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m528 \u001b[0m\u001b[2;90m│   \u001b[0m\u001b[33m\"\"\"Initialize T0 tokenizer.\"\"\"\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m529 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mglobal\u001b[0m _GLOBAL_KNOWLEDGE                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m530 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94massert\u001b[0m \u001b[33m'\u001b[0m\u001b[33mbert\u001b[0m\u001b[33m'\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m _GLOBAL_KNOWLEDGE                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m531 \u001b[2m│   \u001b[0m_GLOBAL_KNOWLEDGE[\u001b[33m'\u001b[0m\u001b[33mbert\u001b[0m\u001b[33m'\u001b[0m] = Tokenized_Knowledge_Dataset(                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m532 \u001b[0m\u001b[2m│   │   \u001b[0m(args.indexed_evidence_bert_tokenized_data_path, args.indexed_title_bert_tokeniz   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m533 \u001b[0m\u001b[2m│   │    \u001b[0margs.data_impl,                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m534 \u001b[0m\u001b[2m│   │   \u001b[0mget_tokenizer(),args.seq_length_retriever                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/data/\u001b[0m\u001b[1;33mpretokenized_evidence.py\u001b[0m:\u001b[94m25\u001b[0m in   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__init__\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 22 \u001b[0m\u001b[2m│   │   \u001b[0mindexed_evidence_bert_tokenized_data_path, indexed_title_bert_tokenized_data_pat   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 23 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.passages_map_bert = make_indexed_dataset(indexed_evidence_bert_tokenized_da   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 24 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.title_map_bert    = make_indexed_dataset(indexed_title_bert_tokenized_data_   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 25 \u001b[2m│   │   \u001b[0mprint_rank_0(\u001b[33mf\u001b[0m\u001b[33m'\u001b[0m\u001b[33m  >> total collect \u001b[0m\u001b[33m{\u001b[0m\u001b[96mlen\u001b[0m(\u001b[96mself\u001b[0m.passages_map_bert)\u001b[33m}\u001b[0m\u001b[33m passages\u001b[0m\u001b[33m'\u001b[0m)         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 26 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m.passages_map_bert \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m, \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33myou must provide the passage knowle\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 27 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m mode == \u001b[33m'\u001b[0m\u001b[33mbert.both_query_and_passage\u001b[0m\u001b[33m'\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 28 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m.title_map_bert \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m, \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33myou must provide the title pool fo\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0mobject of type \u001b[32m'NoneType'\u001b[0m has no \u001b[1;35mlen\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = _build_knowledge_pool_in_bert(args)\n",
    "_ = _build_knowledge_pool_in_t0(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b8f8bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:01<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#_ = _load_wikipedia_evidence(args)\n",
    "_ = _build_t0_model(args)\n",
    "_set_tensorboard_writer(args)\n",
    "_set_timers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ec26668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "> initializing torch distributed ...\n",
      "---------> use fixed config <----------\n",
      "> initializing model parallel with size 1\n",
      "---------> use fixed config <----------\n",
      "> initializing FAISS retriever groups\n",
      "> setting random seeds to 1234 ...\n",
      "> initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n"
     ]
    }
   ],
   "source": [
    "initialize_megatron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a7471b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megatron.global_vars import get_tokenizer as get_bert_tokenizer\n",
    "from tasks.dense_retriever.zero_shot_training.train_data_utils import OpenQADataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5abeb634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tasks.dense_retriever.zero_shot_training.train_data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82cba403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------> use fixed config <----------\n",
      " > building [What is?] dataset for [Judger~~~!]:\n",
      "  > paths: data/unArXiv.key_word_from_abstract.csv\n",
      " > Processing data/unArXiv.key_word_from_abstract.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/ai4earth/zhangtianning/projects/llm/art/tasks/dense_retriever/zero_shot_training/train_data_utils.py:186: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> processed 1546447 samples.\n"
     ]
    }
   ],
   "source": [
    "from tasks.dense_retriever.zero_shot_training.train_data_utils import WhatIsQuestionDataset \n",
    "bert_tokenizer = get_bert_tokenizer()\n",
    "args.train_data = ['data/unArXiv.key_word_from_abstract.csv']\n",
    "train_dataset = WhatIsQuestionDataset(\"OPENQA_DATASET\",\"training\",args.train_data,bert_tokenizer,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4de02ff9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 train_dataset.samples[i+<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>]                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'i'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 train_dataset.samples[i+\u001b[94m3\u001b[0m]                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'i'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset.samples[i+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6453543d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620fd6a0bc944e5bbf13ff503aeb9a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "for i,b in tqdm(enumerate(train_dataset)):\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f47a2bd9",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = OpenQADataset(\"OPENQA_DATASET\",\"training\",args.train_data,bert_tokenizer,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60cba0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4aa5f03b",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "from megatron.model import ARTModel, PreComputedEvidenceDocsRetriever\n",
    "from megatron.tokenizer import build_tokenizer\n",
    "from megatron.model.art_model import JRTModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9644d5ce",
   "metadata": {},
   "source": [
    "### go train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5733ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NCCL_DEBUG\"] = \"WARN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6e522f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megatron.global_vars import get_t0_model, get_t0_tokenizer, get_knowledge_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2840471",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from megatron.training import setup_model_and_optimizer\n",
    "def model_provider():\n",
    "        \"\"\"Build the model.\"\"\"\n",
    "        args = get_args()\n",
    "        print_rank_0('building ART model for {} ...'.format(args.task))\n",
    "        evidence_retriever = PreComputedEvidenceDocsRetriever()\n",
    "        model = JRTModel(evidence_retriever)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb864766",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "building ART model for ZERO-SHOT-RETRIEVER ...\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "we are going use random memory\n",
      "\n",
      "> Building Brute Force MIPS index\n",
      ">>> Finished adding block data to GPU index\n",
      "NCCL version 2.14.3+cuda11.7\n",
      "---------> use fixed config <----------\n",
      " > padded vocab (size: 30524) with 68 dummy tokens (new size: 30592)\n",
      "building Retriever for ART (Autoencoding-based Retriever Training) ...\n",
      "---------> use fixed config <----------\n",
      "building DualEncoderModel...\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "building Retriever for ART, done ...\n",
      " > number of parameters on model parallel rank 0: 217890816\n",
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n",
      "> learning rate decay style: linear\n",
      "---------> use fixed config <----------\n",
      "WARNING: could not find the metadata file ./checkpoints/nq-mss-base-init/latest_checkpointed_iteration.txt \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    will not load any checkpoints and will start from random\n"
     ]
    }
   ],
   "source": [
    "model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)\n",
    "model = model.module.module\n",
    "model.evidence_retriever.local_rank = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4374c5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tasks.dense_retriever.zero_shot_training.train import _build_train_dataloader\n",
    "from tasks.dense_retriever.zero_shot_training.train import process_batch\n",
    "from megatron.global_vars import get_t0_model, get_t0_tokenizer\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09c33002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0bf74d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------> use fixed config <----------\n",
      "building training dataloader ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e33705fda29455aa8af37a62c7579a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/386615 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>train_dataloader = _build_train_dataloader(train_dataset)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2 <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> batch <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> tqdm(train_dataloader):                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">pass</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/tqdm/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">notebook.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">254</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">251 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">252 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">253 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>it = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>(tqdm_notebook, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>).<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>()                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>254 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> obj <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> it:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">255 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># return super(tqdm...) will not catch exception</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">256 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">yield</span> obj                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">257 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># NB: except ... [ as ...] breaks IPython async KeyboardInterrupt</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/tqdm/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">std.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1178</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1175 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>time = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._time                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1176 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1177 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1178 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> obj <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> iterable:                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1179 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">yield</span> obj                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1180 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Update and possibly print the progressbar.</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1181 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Note: does not call self.update(1) for speed optimisation.</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">633</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__next__</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 630 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._sampler_iter <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 631 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># TODO(https://github.com/pytorch/pytorch/issues/76750)</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 632 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._reset()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[call-arg]</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 633 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._next_data()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 634 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._num_yielded += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 635 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_kind == _DatasetKind.Iterable <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 636 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._IterableDataset_len_called <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1345</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_next_data</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1342 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._task_info[idx] += (data,)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1343 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1344 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">del</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._task_info[idx]                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1345 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._process_data(data)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1346 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1347 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_try_put_index</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1348 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._tasks_outstanding &lt; <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._prefetch_factor * <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._num_workers        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1371</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_process_data</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1368 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._rcvd_idx += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1369 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._try_put_index()                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1370 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(data, ExceptionWrapper):                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1371 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data.reraise()                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1372 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> data                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1373 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1374 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_mark_worker_as_unavailable</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, worker_id, shutdown=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>):                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">644</span> in       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reraise</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">641 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># If the exception takes multiple arguments, don't try to</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">642 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># instantiate since we don't know how to</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">643 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(msg) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">None</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>644 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> exception                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">645 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">646 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">647 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_available_device_type</span>():                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>Caught ValueError in DataLoader worker process <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.\n",
       "Original Traceback <span style=\"font-weight: bold\">(</span>most recent call last<span style=\"font-weight: bold\">)</span>:\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\"</span>, \n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">308</span>, in _worker_loop\n",
       "    data = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">fetcher.fetch</span><span style=\"font-weight: bold\">(</span>index<span style=\"font-weight: bold\">)</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\"</span>, line\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span>, in fetch\n",
       "    data = <span style=\"font-weight: bold\">[</span>self.dataset<span style=\"font-weight: bold\">[</span>idx<span style=\"font-weight: bold\">]</span> for idx in possibly_batched_index<span style=\"font-weight: bold\">]</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\"</span>, line\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span>, in <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">listcomp</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    data = </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #000000; text-decoration-color: #000000\">self.dataset</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #000000; text-decoration-color: #000000\">idx</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\"> for idx in possibly_batched_index</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">  File </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/mnt/data/ai4earth/zhangtianning/projects/llm/art/tasks/dense_retriever/zero_shot_training/train_data_utils.py\"</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">line </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">171</span><span style=\"color: #000000; text-decoration-color: #000000\">, in __getitem__</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    paper_id, ques_tokens, tokentypes_enc, num_tokens_ques, prefixed_query_text = </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.get_item</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">idx</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">  File </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/mnt/data/ai4earth/zhangtianning/projects/llm/art/tasks/dense_retriever/zero_shot_training/train_data_utils.py\"</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">line </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">166</span><span style=\"color: #000000; text-decoration-color: #000000\">, in get_item</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    ques_tokens, tokentypes_enc, num_tokens_ques = </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">build_tokens_types_paddings_from_text</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">  File </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/mnt/data/ai4earth/zhangtianning/projects/llm/art/tasks/dense_retriever/zero_shot_training/train_data_utils.py\"</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">line </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span><span style=\"color: #000000; text-decoration-color: #000000\">, in build_tokens_types_paddings_from_text</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    src_text_ids = </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">bert_tokenizer.tokenize</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">src_text</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">  File </span><span style=\"color: #008000; text-decoration-color: #008000\">\"/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/tokenizer/tokenizer.py\"</span><span style=\"color: #000000; text-decoration-color: #000000\">, line </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">202</span><span style=\"color: #000000; text-decoration-color: #000000\">, in tokenize</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    text_tokens = </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.tokenizer.tokenize</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">text</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">  File </span><span style=\"color: #008000; text-decoration-color: #008000\">\"/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/tokenizer/bert_tokenization.py\"</span><span style=\"color: #000000; text-decoration-color: #000000\">, line </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span><span style=\"color: #000000; text-decoration-color: #000000\">, in </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">tokenize</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    for token in </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.basic_tokenizer.tokenize</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">text</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">:</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">  File </span><span style=\"color: #008000; text-decoration-color: #008000\">\"/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/tokenizer/bert_tokenization.py\"</span><span style=\"color: #000000; text-decoration-color: #000000\">, line </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">230</span><span style=\"color: #000000; text-decoration-color: #000000\">, in </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">tokenize</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    text = </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">convert_to_unicode</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">text</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">  File </span><span style=\"color: #008000; text-decoration-color: #008000\">\"/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/tokenizer/bert_tokenization.py\"</span><span style=\"color: #000000; text-decoration-color: #000000\">, line </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86</span><span style=\"color: #000000; text-decoration-color: #000000\">, in </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">convert_to_unicode</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    raise </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ValueError</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Unsupported string type: %s\"</span><span style=\"color: #000000; text-decoration-color: #000000\"> % </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">type</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">text</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)))</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">ValueError: Unsupported string type: &lt;class </span><span style=\"color: #008000; text-decoration-color: #008000\">'float'</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m2\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0mtrain_dataloader = _build_train_dataloader(train_dataset)                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2 \u001b[94mfor\u001b[0m batch \u001b[95min\u001b[0m tqdm(train_dataloader):                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mpass\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/tqdm/\u001b[0m\u001b[1;33mnotebook.py\u001b[0m:\u001b[94m254\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__iter__\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m251 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__iter__\u001b[0m(\u001b[96mself\u001b[0m):                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m252 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m253 \u001b[0m\u001b[2m│   │   │   \u001b[0mit = \u001b[96msuper\u001b[0m(tqdm_notebook, \u001b[96mself\u001b[0m).\u001b[92m__iter__\u001b[0m()                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m254 \u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m obj \u001b[95min\u001b[0m it:                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m255 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# return super(tqdm...) will not catch exception\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m256 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94myield\u001b[0m obj                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m257 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/tqdm/\u001b[0m\u001b[1;33mstd.py\u001b[0m:\u001b[94m1178\u001b[0m in \u001b[92m__iter__\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1175 \u001b[0m\u001b[2m│   │   \u001b[0mtime = \u001b[96mself\u001b[0m._time                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1176 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1177 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1178 \u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m obj \u001b[95min\u001b[0m iterable:                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1179 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94myield\u001b[0m obj                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1180 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Update and possibly print the progressbar.\u001b[0m                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1181 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Note: does not call self.update(1) for speed optimisation.\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m633\u001b[0m in \u001b[92m__next__\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 630 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._sampler_iter \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 631 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 632 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._reset()  \u001b[2m# type: ignore[call-arg]\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 633 \u001b[2m│   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m._next_data()                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 634 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._num_yielded += \u001b[94m1\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 635 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._dataset_kind == _DatasetKind.Iterable \u001b[95mand\u001b[0m \\                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 636 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._IterableDataset_len_called \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m \\                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m1345\u001b[0m in \u001b[92m_next_data\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1342 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._task_info[idx] += (data,)                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1343 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1344 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mdel\u001b[0m \u001b[96mself\u001b[0m._task_info[idx]                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1345 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._process_data(data)                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1346 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1347 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_try_put_index\u001b[0m(\u001b[96mself\u001b[0m):                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1348 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m._tasks_outstanding < \u001b[96mself\u001b[0m._prefetch_factor * \u001b[96mself\u001b[0m._num_workers        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m1371\u001b[0m in \u001b[92m_process_data\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1368 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._rcvd_idx += \u001b[94m1\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1369 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._try_put_index()                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1370 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(data, ExceptionWrapper):                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1371 \u001b[2m│   │   │   \u001b[0mdata.reraise()                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1372 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m data                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1373 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1374 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_mark_worker_as_unavailable\u001b[0m(\u001b[96mself\u001b[0m, worker_id, shutdown=\u001b[94mFalse\u001b[0m):                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/\u001b[0m\u001b[1;33m_utils.py\u001b[0m:\u001b[94m644\u001b[0m in       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mreraise\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m641 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# If the exception takes multiple arguments, don't try to\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m642 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# instantiate since we don't know how to\u001b[0m                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m643 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(msg) \u001b[94mfrom\u001b[0m \u001b[96mNone\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m644 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m exception                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m645 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m646 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m647 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_get_available_device_type\u001b[0m():                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mCaught ValueError in DataLoader worker process \u001b[1;36m1\u001b[0m.\n",
       "Original Traceback \u001b[1m(\u001b[0mmost recent call last\u001b[1m)\u001b[0m:\n",
       "  File \u001b[32m\"/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\"\u001b[0m, \n",
       "line \u001b[1;36m308\u001b[0m, in _worker_loop\n",
       "    data = \u001b[1;35mfetcher.fetch\u001b[0m\u001b[1m(\u001b[0mindex\u001b[1m)\u001b[0m\n",
       "  File \u001b[32m\"/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\"\u001b[0m, line\n",
       "\u001b[1;36m51\u001b[0m, in fetch\n",
       "    data = \u001b[1m[\u001b[0mself.dataset\u001b[1m[\u001b[0midx\u001b[1m]\u001b[0m for idx in possibly_batched_index\u001b[1m]\u001b[0m\n",
       "  File \u001b[32m\"/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\"\u001b[0m, line\n",
       "\u001b[1;36m51\u001b[0m, in \u001b[1m<\u001b[0m\u001b[1;95mlistcomp\u001b[0m\u001b[39m>\u001b[0m\n",
       "\u001b[39m    data = \u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mself.dataset\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39midx\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m for idx in possibly_batched_index\u001b[0m\u001b[1;39m]\u001b[0m\n",
       "\u001b[39m  File \u001b[0m\n",
       "\u001b[32m\"/mnt/data/ai4earth/zhangtianning/projects/llm/art/tasks/dense_retriever/zero_shot_training/train_data_utils.py\"\u001b[0m\u001b[39m, \u001b[0m\n",
       "\u001b[39mline \u001b[0m\u001b[1;36m171\u001b[0m\u001b[39m, in __getitem__\u001b[0m\n",
       "\u001b[39m    paper_id, ques_tokens, tokentypes_enc, num_tokens_ques, prefixed_query_text = \u001b[0m\u001b[1;35mself.get_item\u001b[0m\u001b[1;39m(\u001b[0m\u001b[39midx\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m  File \u001b[0m\n",
       "\u001b[32m\"/mnt/data/ai4earth/zhangtianning/projects/llm/art/tasks/dense_retriever/zero_shot_training/train_data_utils.py\"\u001b[0m\u001b[39m, \u001b[0m\n",
       "\u001b[39mline \u001b[0m\u001b[1;36m166\u001b[0m\u001b[39m, in get_item\u001b[0m\n",
       "\u001b[39m    ques_tokens, tokentypes_enc, num_tokens_ques = \u001b[0m\u001b[1;35mbuild_tokens_types_paddings_from_text\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m  File \u001b[0m\n",
       "\u001b[32m\"/mnt/data/ai4earth/zhangtianning/projects/llm/art/tasks/dense_retriever/zero_shot_training/train_data_utils.py\"\u001b[0m\u001b[39m, \u001b[0m\n",
       "\u001b[39mline \u001b[0m\u001b[1;36m13\u001b[0m\u001b[39m, in build_tokens_types_paddings_from_text\u001b[0m\n",
       "\u001b[39m    src_text_ids = \u001b[0m\u001b[1;35mbert_tokenizer.tokenize\u001b[0m\u001b[1;39m(\u001b[0m\u001b[39msrc_text\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m  File \u001b[0m\u001b[32m\"/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/tokenizer/tokenizer.py\"\u001b[0m\u001b[39m, line \u001b[0m\u001b[1;36m202\u001b[0m\u001b[39m, in tokenize\u001b[0m\n",
       "\u001b[39m    text_tokens = \u001b[0m\u001b[1;35mself.tokenizer.tokenize\u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mtext\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m  File \u001b[0m\u001b[32m\"/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/tokenizer/bert_tokenization.py\"\u001b[0m\u001b[39m, line \u001b[0m\u001b[1;36m172\u001b[0m\u001b[39m, in \u001b[0m\n",
       "\u001b[39mtokenize\u001b[0m\n",
       "\u001b[39m    for token in \u001b[0m\u001b[1;35mself.basic_tokenizer.tokenize\u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mtext\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m:\u001b[0m\n",
       "\u001b[39m  File \u001b[0m\u001b[32m\"/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/tokenizer/bert_tokenization.py\"\u001b[0m\u001b[39m, line \u001b[0m\u001b[1;36m230\u001b[0m\u001b[39m, in \u001b[0m\n",
       "\u001b[39mtokenize\u001b[0m\n",
       "\u001b[39m    text = \u001b[0m\u001b[1;35mconvert_to_unicode\u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mtext\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m  File \u001b[0m\u001b[32m\"/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/tokenizer/bert_tokenization.py\"\u001b[0m\u001b[39m, line \u001b[0m\u001b[1;36m86\u001b[0m\u001b[39m, in \u001b[0m\n",
       "\u001b[39mconvert_to_unicode\u001b[0m\n",
       "\u001b[39m    raise \u001b[0m\u001b[1;35mValueError\u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m\"Unsupported string type: %s\"\u001b[0m\u001b[39m % \u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;35mtype\u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mtext\u001b[0m\u001b[1;39m)\u001b[0m\u001b[1;39m)\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39mValueError: Unsupported string type: <class \u001b[0m\u001b[32m'float'\u001b[0m\u001b[1m>\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataloader = _build_train_dataloader(train_dataset)\n",
    "for batch in tqdm(train_dataloader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51f89a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetcher= iter(train_dataloader)\n",
    "batch = next(fetcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de96659d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "(query_uid, query_tokens_for_retriever, query_types, query_mask_bert,\n",
    "               prefixed_query_token_for_LLM, prefixed_query_mask_t0,\n",
    "               prefixed_query_token_len_for_LLM, reference) = process_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a666986",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = get_bert_tokenizer()\n",
    "t0_tokenizer = get_t0_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d2d5908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megatron.data.mask_creation_utils import make_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4326deb3",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------> use fixed config <----------\n"
     ]
    }
   ],
   "source": [
    "self = model\n",
    "with torch.no_grad():\n",
    "    query_embedding = self.get_query_embedding(query_tokens_for_retriever, query_mask_bert, query_types)\n",
    "    topk_evidence_data = self.get_topk_evidence(query_uid, query_embedding)\n",
    "    coarse_search_context_tokens_for_retriever, coarse_search_context_tokens_for_llm = self.evidence_retriever.postprocess(query_uid, topk_evidence_data,\n",
    "                              prefixed_query_token_for_LLM)\n",
    "    all_context_embedding = self.get_retriever_embedding(coarse_search_context_tokens_for_retriever)\n",
    "    topk_log_probs        = self.compute_log_probs(query_embedding, all_context_embedding)\n",
    "    prefixed_query_tuple  = (prefixed_query_token_for_LLM,prefixed_query_token_len_for_LLM)\n",
    "    gold_log_probs = self.get_LLM_score(coarse_search_context_tokens_for_llm, prefixed_query_tuple)\n",
    "    flattened_reference_ids = self.evidence_retriever.get_the_reference_id(topk_evidence_data)\n",
    "    all_reference_embedding = self.get_retriever_embedding(flattened_reference_ids,embedder_type = \"query\")\n",
    "    reference_sim = torch.einsum('bkd,bkd->bk',all_reference_embedding, all_context_embedding)\n",
    "    reference_sim = reference_sim/(args.inverse_temperature_multiplier * math.sqrt(args.hidden_size))\n",
    "    reference_sim = reference_sim.sigmoid() \n",
    "\n",
    "\n",
    "    reference_seted= torch.ones_like(gold_log_probs)\n",
    "\n",
    "    retriever_score = torch.concatenate([topk_log_probs,reference_sim ],-1) #(B, 2*k)\n",
    "    LLM_score       = torch.concatenate([gold_log_probs,reference_seted ],-1) #(B, 2*k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f26b6fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7261, device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.BCELoss(reduction=\"mean\")(retriever_score,LLM_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6835627d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(gold_log_probs>0.5).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e36937ad",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd2a62b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be84d2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ecb4954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1541, 0.0159, 0.0311, 0.1646, 0.0087, 0.0100, 0.0272, 0.0284, 0.0737,\n",
       "         0.0260, 0.0230, 0.0077, 0.0185, 0.0119, 0.0197, 0.0077, 0.0489, 0.0268,\n",
       "         0.0051, 0.0164, 0.0015, 0.0391, 0.0219, 0.0058, 0.0233, 0.0059, 0.0610,\n",
       "         0.0147, 0.0967, 0.0099, 0.0077, 0.0213],\n",
       "        [0.0637, 0.0592, 0.0421, 0.1481, 0.0839, 0.0362, 0.1688, 0.0592, 0.2510,\n",
       "         0.0440, 0.0695, 0.1348, 0.1624, 0.0914, 0.1208, 0.0293, 0.0396, 0.0566,\n",
       "         0.1561, 0.1943, 0.0421, 0.0336, 0.2147, 0.2227, 0.1442, 0.0666, 0.0792,\n",
       "         0.1176, 0.1366, 0.1312, 0.0592, 0.0481],\n",
       "        [0.0240, 0.0264, 0.0136, 0.1824, 0.0336, 0.0213, 0.0792, 0.0421, 0.0307,\n",
       "         0.0293, 0.0534, 0.0284, 0.0049, 0.1848, 0.0995, 0.0194, 0.0352, 0.0503,\n",
       "         0.0264, 0.3074, 0.0427, 0.0289, 0.0759, 0.1225, 0.1067, 0.0244, 0.0511,\n",
       "         0.0040, 0.0268, 0.0197, 0.0145, 0.0526],\n",
       "        [0.1176, 0.0090, 0.0147, 0.0427, 0.0264, 0.0244, 0.0174, 0.0122, 0.0191,\n",
       "         0.0174, 0.0177, 0.0143, 0.0197, 0.0396, 0.1052, 0.0298, 0.0628, 0.0064,\n",
       "         0.0132, 0.0102, 0.0272, 0.0174, 0.0174, 0.0026, 0.0113, 0.0152, 0.1160,\n",
       "         0.0542, 0.0141, 0.0108, 0.0145, 0.0331]], device='cuda:0',\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc67ad36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk><unk><unk><unk><unk><unk><unk><unk><unk><s> A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user\\'s questions. USER: Here is a passage about [ Antisemitism]:\"\"\" antisemitic—not just anti-Israel. Judith Popinski, an 86-year-old Holocaust survivor, stated that she is no longer invited to schools that have a large Muslim presence to tell her story of surviving the Holocaust. In December 2010, the Jewish human rights organization Simon Wiesenthal Center issued a travel advisory concerning Sweden, advising Jews to express \"extreme caution\" when visiting the southern parts of the country due to an alleged increase in verbal and physical harassment of Jewish citizens in the city of Malmö. Ilmar Reepalu, the mayor of Malmö for over 15 years, has been accused of failing to protect the Jewish\"\"\" Based on the given passage, formulate a question that aligns most accurately with the primary fact disclosed within the text. ASSISTANT: Who has the most turnovers in nba history</s><unk><unk><unk><unk><unk><unk>'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.llm_system.tokenizer.decode(output_ids.sequences[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f9b3ecd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user\\'s questions. USER: Given the passage:\"\"\" algebraically closed, because if \"a\", \"a\", …, \"a\" are the elements of \"F\", then the polynomial (\"x\" − \"a\")(\"x\" − \"a\") ··· (\"x\" − \"a\") + 1 has no zero in \"F\". By contrast, the fundamental theorem of algebra states that the field of complex numbers is algebraically closed. Another example of an algebraically closed field is the field of (complex) algebraic numbers. Given a field \"F\", the assertion \"\"F\" is algebraically closed\" is equivalent to other assertions: The field \"F\" is algebraically closed if and only if the only irreducible polynomials in the polynomial ring \"F\"[\"x\"] are those of\"\"\" Please check whether the passage is relative to the question: What is Lepton mass . Return Yes or No. ASSISTANT:'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0_tokenizer.decode(coarse_search_context_tokens_for_llm[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7f735b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_answer_token = answer_token[:,3:]\n",
    "if lm_logits.shape[1]<real_answer_token.shape[1]:\n",
    "    lm_logits=torch.nn.functional.pad(lm_logits,(0,0,0,real_answer_token.shape[1] - lm_logits.shape[1]),mode ='replicate')\n",
    "log_softmax    = F.log_softmax(lm_logits, dim=-1)\n",
    "gold_log_probs = log_softmax.gather(2, real_answer_token.unsqueeze(2)).squeeze(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "da82bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13572942",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_softmax    = F.log_softmax(lm_logits, dim=-1)\n",
    "gold_log_probs = alog_softmax.gather(2, answer_token.unsqueeze(2)).squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f11eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c18f1bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    'pretrain_weights/vicuna-7b-v1.1',\n",
    "    model_max_length=512,\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.unk_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99e5b4c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      ". with two friend person and a expert intelligence..\n",
      " user provides a advice inform answers and accurateite responses to the user'<s> questions.\n",
      "ER</s>I is a list from theobjectosism-Capitalism](\n",
      "An\n",
      "ud, thelary, theft, murder ev are\n",
      " stateiation of physical is the considered to as aggression, violenceercion.\n",
      " idea between anarcho-capitalism and min libertarians is that one of emphas means of which they believe the principleiom seriously Anarchists libertarians, for as the members who in thearian parties parties, believe limit a state as order form form more intrive form, suching only least most least the order and courts, defense. An, an, argue the argumentsances for the functions functions,\n",
      " an, anarcho-capitalists argue the and of state intervention, including the state as an violercive monopoly on advocby such use institution that society history\" history on this passage passage, which a a question for cans with closelyately with the main purpose thatsem in it passage.\n",
      ".\n",
      "an Answer What\n",
      " Who did seahawks play in super bowl 2014<unk><unk><unk><unk><unk>\n"
     ]
    }
   ],
   "source": [
    "_id = 0\n",
    "# print(model.llm_system.tokenizer.decode(question_token[0]))\n",
    "# print(\"==================================================\")\n",
    "# print(model.llm_system.tokenizer.decode(context_tensor[_id]))\n",
    "# print(\"==================================================\")\n",
    "#print(model.llm_system.tokenizer.decode(output_ids.sequences[_id]))\n",
    "#print(\"==================================================\")\n",
    "print(model.llm_system.tokenizer.decode(lm_logits.max(-1)[1][_id]))\n",
    "print(model.llm_system.tokenizer.decode(answer_token[_id][3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "9b8f85da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
    "from fastchat.conversation import get_conv_template\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"pretrain_weights/vicuna-7b-v1.1\", use_fast=False)\n",
    "conv = get_conv_template('vicuna_v1.1').copy()\n",
    "conv.append_message(conv.roles[0], 'Here is a passage about [Anatoly Karpov]:\"\"\"A rematch was set for later in 1985, also in Moscow. The events of the so-called Marathon Match forced FIDE to return to the previous format, with a match limited to 24 games (with Karpov remaining champion if the match should finish 12–12). Karpov needed to win the final game to draw the match and retain his title, but wound up losing, thus surrendering the title to his opponent. The final score was 13–11 (+3−5=16), in favour of Kasparov. Karpov remained a formidable opponent (and the world No. 2) until the early 1990s. He fought Kasparov in three more world\"\"\"Based on the given passage, formulate a question that aligns most accurately with the primary fact disclosed within the text.')\n",
    "conv.append_message(conv.roles[1], None)\n",
    "prompt = conv.get_prompt()\n",
    "input_ids = tokenizer([prompt]).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0f6dc4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user\\'s questions. USER: Here is a passage about [Anatoly Karpov]:\"\"\"A rematch was set for later in 1985, also in Moscow. The events of the so-called Marathon Match forced FIDE to return to the previous format, with a match limited to 24 games (with Karpov remaining champion if the match should finish 12–12). Karpov needed to win the final game to draw the match and retain his title, but wound up losing, thus surrendering the title to his opponent. The final score was 13–11 (+3−5=16), in favour of Kasparov. Karpov remained a formidable opponent (and the world No. 2) until the early 1990s. He fought Kasparov in three more world\"\"\"Based on the given passage, formulate a question that aligns most accurately with the primary fact disclosed within the text. ASSISTANT:'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.llm_system.tokenizer.decode(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "ecafeb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Here is a passage about [Anatoly Karpov]:\"\"\"A rematch was set for later in 1985, also in Moscow. The events of the so-called Marathon Match forced FIDE to return to the previous format, with a match limited to 24 games (with Karpov remaining champion if the match should finish 12–12). Karpov needed to win the final game to draw the match and retain his title, but wound up losing, thus surrendering the title to his opponent. The final score was 13–11 (+3−5=16), in favour of Kasparov. Karpov remained a formidable opponent (and the world No. 2) until the early 1990s. He fought Kasparov in three more world\"\"\"Based on the given passage, formulate a question that aligns most accurately with the primary fact disclosed within the text. ASSISTANT:\n",
      "------------------------------------------------\n",
      "<s> A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Here is a passage about [Anatoly Karpov]:\"\"\"A rematch was set for later in 1985, also in Moscow. The events of the so-called Marathon Match forced FIDE to return to the previous format, with a match limited to 24 games (with Karpov remaining champion if the match should finish 12–12). Karpov needed to win the final game to draw the match and retain his title, but wound up losing, thus surrendering the title to his opponent. The final score was 13–11 (+3−5=16), in favour of Kasparov. Karpov remained a formidable opponent (and the world No. 2) until the early 1990s. He fought Kasparov in three more world\"\"\"Based on the given passage, formulate a question that aligns most accurately with the primary fact disclosed within the text. ASSISTANT: What was the final score of the 1985 World Chess Championship rematch between Anatoly Karpov and Garry Kasparov?</s>\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output_ids = model.llm_system.model.generate(torch.as_tensor(input_ids).cuda(), return_dict_in_generate=False, output_scores=False,max_length=512)\n",
    "    print(model.llm_system.tokenizer.decode(input_ids[0]))\n",
    "    print(\"------------------------------------------------\")\n",
    "    print(model.llm_system.tokenizer.decode(output_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a6f7f34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsw-23976-7d79d88dc8-j998v:63957:64669 [0] NCCL INFO Using network Socket\n",
      "dsw-23976-7d79d88dc8-j998v:63957:64669 [0] NCCL INFO Channel 00/02 :    0\n",
      "dsw-23976-7d79d88dc8-j998v:63957:64669 [0] NCCL INFO Channel 01/02 :    0\n",
      "dsw-23976-7d79d88dc8-j998v:63957:64669 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1\n",
      "dsw-23976-7d79d88dc8-j998v:63957:64669 [0] NCCL INFO Connected all rings\n",
      "dsw-23976-7d79d88dc8-j998v:63957:64669 [0] NCCL INFO Connected all trees\n",
      "dsw-23976-7d79d88dc8-j998v:63957:64669 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "dsw-23976-7d79d88dc8-j998v:63957:64669 [0] NCCL INFO comm 0x77bc6bc0 rank 0 nranks 1 cudaDev 0 busId 70 - Init COMPLETE\n",
      "---------> use fixed config <----------\n"
     ]
    }
   ],
   "source": [
    "# model.module.module.evidence_retriever.local_rank = 0\n",
    "# with torch.no_grad():\n",
    "#     topk_log_probs, gold_log_probs = model(query_uid,\n",
    "#                                            query_ids_bert,\n",
    "#                                            query_types,\n",
    "#                                            query_mask_bert,\n",
    "#                                            prefixed_query_ids_t0,\n",
    "#                                            prefixed_query_ids_t0_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "374b88da",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_loss = torch.FloatTensor([0]).cuda()\n",
    "if args.update_retriever:\n",
    "    topk_log_probs = topk_log_probs.float()\n",
    "    gold_log_probs = gold_log_probs.float()\n",
    "    gold_log_probs_log_softmax = F.log_softmax(gold_log_probs, dim=1)\n",
    "    loss_func = torch.nn.KLDivLoss(reduction=\"batchmean\", log_target=True)\n",
    "    retriever_loss = loss_func(topk_log_probs, gold_log_probs_log_softmax)\n",
    "\n",
    "net_loss = retriever_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd836bc5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08155dbf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = model.module.module\n",
    "model.evidence_retriever.local_rank= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ac6ddae",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------> use fixed config <----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">14</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>topk_log_probs     = model.compute_log_probs(query_logits,all_context_logits)           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Compute the language model score of the retrieved passages</span>                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>prefixed_query_tuple = (prefixed_query_ids_t0,prefixed_query_ids_t0_len)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>14 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>gold_log_probs = model.get_LLM_score(all_title_context_ids_for_t0, prefixed_query_tu    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/model/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">art_model.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">133</span> in             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_LLM_score</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">130 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>all_title_context_ids_view = all_title_context_ids_one_question[i: i + a   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">131 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>decoder_prefix_tensor_view = decoder_prefix_tensor_one_question[i: i + a   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">132 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>133 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>gold_log_probs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.llm_system.get_gold_log_probs(all_title_contex   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">134 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this will work because the batch size is 1 and this implies all de</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>teacher_log_probs = torch.mean(gold_log_probs[:, :prefixed_query_ids   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>log_prob_list_one_question.append(teacher_log_probs)                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/model/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">art_model.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">33</span> in              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_gold_log_probs</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 30 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   </span>return_tensors=<span style=\"color: #808000; text-decoration-color: #808000\">'pt'</span>)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 31 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> input_encoding.input_ids.size(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>) &lt;= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">512</span>                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 32 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>context_tensor, attention_mask = input_encoding.input_ids.cuda(), input_encoding   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 33 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>lm_output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model(input_ids=context_tensor,attention_mask=attention_mask,la   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 34 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │    </span>output_attentions=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>,output_hidden_states=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>)                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 35 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(lm_output,<span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>):                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 36 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">### the llama return </span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/transformers/models/llama/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">mo</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">deling_llama.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">713</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">710 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>shift_labels = shift_labels.view(-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">711 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Enable model parallelism</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">712 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>shift_labels = shift_labels.to(shift_logits.device)                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>713 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>loss = loss_fct(shift_logits, shift_labels)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">714 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">715 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> return_dict:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">716 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>output = (logits,) + outputs[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:]                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">loss.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">117</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1171 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.label_smoothing = label_smoothing                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1172 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1173 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor, target: Tensor) -&gt; Tensor:                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1174 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.cross_entropy(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, target, weight=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight,                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1175 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │      </span>ignore_index=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ignore_index, reduction=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.reduction,  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1176 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │      </span>label_smoothing=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.label_smoothing)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1177 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3029</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cross_entropy</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3026 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3027 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> size_average <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> reduce <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3028 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>reduction = _Reduction.legacy_get_string(size_average, reduce)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3029 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch._C._nn.cross_entropy_loss(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, target, weight, _Reduction.get_enum(re  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3030 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3031 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3032 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">binary_cross_entropy</span>(                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OutOfMemoryError: </span>CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">266.00</span> MiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23.70</span> GiB total capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21.04</span> GiB \n",
       "already allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">106.56</span> MiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22.50</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span> If reserved memory is &gt;&gt; allocated \n",
       "memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m14\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m│   \u001b[0mtopk_log_probs     = model.compute_log_probs(query_logits,all_context_logits)           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m12 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Compute the language model score of the retrieved passages\u001b[0m                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m│   \u001b[0mprefixed_query_tuple = (prefixed_query_ids_t0,prefixed_query_ids_t0_len)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m14 \u001b[2m│   \u001b[0mgold_log_probs = model.get_LLM_score(all_title_context_ids_for_t0, prefixed_query_tu    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/model/\u001b[0m\u001b[1;33mart_model.py\u001b[0m:\u001b[94m133\u001b[0m in             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mget_LLM_score\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m130 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mall_title_context_ids_view = all_title_context_ids_one_question[i: i + a   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m131 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdecoder_prefix_tensor_view = decoder_prefix_tensor_one_question[i: i + a   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m132 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m133 \u001b[2m│   │   │   │   │   \u001b[0mgold_log_probs = \u001b[96mself\u001b[0m.llm_system.get_gold_log_probs(all_title_contex   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m134 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[2m# this will work because the batch size is 1 and this implies all de\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mteacher_log_probs = torch.mean(gold_log_probs[:, :prefixed_query_ids   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mlog_prob_list_one_question.append(teacher_log_probs)                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/model/\u001b[0m\u001b[1;33mart_model.py\u001b[0m:\u001b[94m33\u001b[0m in              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mget_gold_log_probs\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 30 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   \u001b[0mreturn_tensors=\u001b[33m'\u001b[0m\u001b[33mpt\u001b[0m\u001b[33m'\u001b[0m)                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 31 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m input_encoding.input_ids.size(\u001b[94m1\u001b[0m) <= \u001b[94m512\u001b[0m                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 32 \u001b[0m\u001b[2m│   │   \u001b[0mcontext_tensor, attention_mask = input_encoding.input_ids.cuda(), input_encoding   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 33 \u001b[2m│   │   \u001b[0mlm_output = \u001b[96mself\u001b[0m.model(input_ids=context_tensor,attention_mask=attention_mask,la   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 34 \u001b[0m\u001b[2m│   │   │   │   │    \u001b[0moutput_attentions=\u001b[94mFalse\u001b[0m,output_hidden_states=\u001b[94mFalse\u001b[0m)                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 35 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(lm_output,\u001b[96mtuple\u001b[0m):                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 36 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m### the llama return \u001b[0m                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/transformers/models/llama/\u001b[0m\u001b[1;33mmo\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mdeling_llama.py\u001b[0m:\u001b[94m713\u001b[0m in \u001b[92mforward\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m710 \u001b[0m\u001b[2m│   │   │   \u001b[0mshift_labels = shift_labels.view(-\u001b[94m1\u001b[0m)                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m711 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Enable model parallelism\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m712 \u001b[0m\u001b[2m│   │   │   \u001b[0mshift_labels = shift_labels.to(shift_logits.device)                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m713 \u001b[2m│   │   │   \u001b[0mloss = loss_fct(shift_logits, shift_labels)                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m714 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m715 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m return_dict:                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m716 \u001b[0m\u001b[2m│   │   │   \u001b[0moutput = (logits,) + outputs[\u001b[94m1\u001b[0m:]                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mloss.py\u001b[0m:\u001b[94m117\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m4\u001b[0m in \u001b[92mforward\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1171 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.label_smoothing = label_smoothing                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1172 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1173 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor, target: Tensor) -> Tensor:                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1174 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m F.cross_entropy(\u001b[96minput\u001b[0m, target, weight=\u001b[96mself\u001b[0m.weight,                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1175 \u001b[0m\u001b[2m│   │   │   │   │   │   │      \u001b[0mignore_index=\u001b[96mself\u001b[0m.ignore_index, reduction=\u001b[96mself\u001b[0m.reduction,  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1176 \u001b[0m\u001b[2m│   │   │   │   │   │   │      \u001b[0mlabel_smoothing=\u001b[96mself\u001b[0m.label_smoothing)                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1177 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/\u001b[0m\u001b[1;33mfunctional.py\u001b[0m:\u001b[94m3029\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mcross_entropy\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3026 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3027 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m size_average \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m reduce \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3028 \u001b[0m\u001b[2m│   │   \u001b[0mreduction = _Reduction.legacy_get_string(size_average, reduce)                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3029 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m torch._C._nn.cross_entropy_loss(\u001b[96minput\u001b[0m, target, weight, _Reduction.get_enum(re  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3030 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3031 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3032 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mbinary_cross_entropy\u001b[0m(                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m266.00\u001b[0m MiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m23.70\u001b[0m GiB total capacity; \u001b[1;36m21.04\u001b[0m GiB \n",
       "already allocated; \u001b[1;36m106.56\u001b[0m MiB free; \u001b[1;36m22.50\u001b[0m GiB reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated \n",
       "memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    #args = get_args()\n",
    "    args = model.args\n",
    "    # assert bsize == 1, \"for auto-encoder pre-training, we assume a local batch size of 1\"\n",
    "    assert args.initialize_t0_model_tokenizer_evidence, \"for auto-encoder pre-training, we need to pass the argument --initialize-t0-model-and-tokenizer\"\n",
    "    query_logits =  model.get_query_embedding(query_ids_bert, query_mask_bert, query_types)\n",
    "    all_title_context_ids_bert_tokenized, all_title_context_ids_for_t0 = model.get_topk_evidence(query_uid, query_logits)\n",
    "    # Compute the retriever score\n",
    "    all_context_logits = model.get_answer_embedding(all_title_context_ids_bert_tokenized)\n",
    "    topk_log_probs     = model.compute_log_probs(query_logits,all_context_logits)\n",
    "    # Compute the language model score of the retrieved passages\n",
    "    prefixed_query_tuple = (prefixed_query_ids_t0,prefixed_query_ids_t0_len)\n",
    "    gold_log_probs = model.get_LLM_score(all_title_context_ids_for_t0, prefixed_query_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85e05ebd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1717ead",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 272])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ainput_encoding.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c0fd4f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_encoding = self.tokenizer.pad({'input_ids': question_token},\n",
    "                                padding='longest',\n",
    "                                max_length=512,\n",
    "                                pad_to_multiple_of=8,\n",
    "                                return_attention_mask=True,\n",
    "                                return_tensors='pt')\n",
    "assert input_encoding.input_ids.size(1) <= 512\n",
    "context_tensor, attention_mask = input_encoding.input_ids.cuda(), input_encoding.attention_mask.cuda()\n",
    "lm_output = self.model(input_ids=context_tensor,\n",
    "                            attention_mask=attention_mask,\n",
    "                            labels=answer_token,\n",
    "                            output_attentions=False,\n",
    "                            output_hidden_states=False)\n",
    "lm_logits = lm_output.logits.float()\n",
    "log_softmax = F.log_softmax(lm_logits, dim=-1)\n",
    "gold_log_probs = log_softmax.gather(2, answer_token.unsqueeze(2)).squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5e07b7a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 model.llm_system.tokenizer.decode(all_title_context_ids_for_t0[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>])                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'all_title_context_ids_for_t0'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 model.llm_system.tokenizer.decode(all_title_context_ids_for_t0[\u001b[94m0\u001b[0m])                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'all_title_context_ids_for_t0'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.llm_system.tokenizer.decode(all_title_context_ids_for_t0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "62a1c2b0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Economy of Azerbaijan'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.llm_system.tokenizer.decode(topk_evidence_data[0][2][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d58fd4a5",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] us $ 1 ) for 28 january 2016, was azn 1. 60. there is a complex relationship between azerbaijan\\'s balance of trade, inflation, measured by the consumer price index and the value of its currency. despite allowing the value of the manat to \" float \", azerbaijan\\'s central bank has decisive ability to control its value with relationship to other currencies. two thirds of azerbaijan is rich in oil and natural gas. the region of the lesser caucasus accounts for most of the country\\'s gold, silver, iron, copper, titanium, chromium, manganese, cobalt, molybdenum, complex ore and antimony. in september 1994, a 30 - year contract was signed between [SEP] economy of azerbaijan [SEP]'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.decode(all_title_context_ids_bert_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5fcea8df",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_ids_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e91255b6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] who has the most turnovers in nba history [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.decode(query_ids_bert[3].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a6d8401d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'economy of azerbaijan'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.decode(topk_evidence_data[0][1][0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecdc87c",
   "metadata": {},
   "source": [
    "##### the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624ffac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megatron.model.art_model import postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3cef610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------> use fixed config <----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">11</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 # Compute the language model score of the retrieved passages</span>                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span>prefixed_query_tuple = (prefixed_query_ids_t0,                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>prefixed_query_ids_t0_len)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>11 gold_log_probs = model.get_LLM_score(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>all_title_context_ids_for_t0, prefixed_query_tuple)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 # Compute the retriever score</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 </span>topk_log_probs = model.get_fine_search_result(                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_LLM_score</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">126</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>decoder_prefix_tensor_view = decoder_prefix_tensor_one_question[i: i + a   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">124 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">125 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>126 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>lm_output = language_model(input_ids=context_tensor,                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   │      </span>attention_mask=attention_mask,              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   │      </span>labels=decoder_prefix_tensor_view,          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">129 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   │      </span>output_attentions=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>,                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/transformers/models/t5/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">model</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ing_t5.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1679</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1676 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Encode if needed (training, first prediction pass)</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1677 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> encoder_outputs <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1678 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Convert encoder inputs in embeddings if needed</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1679 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>encoder_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.encoder(                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1680 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>input_ids=input_ids,                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1681 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>attention_mask=attention_mask,                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1682 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>inputs_embeds=inputs_embeds,                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/transformers/models/t5/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">model</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ing_t5.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">985</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 982 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 983 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> inputs_embeds <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 984 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embed_tokens <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"You have to initialize the model with</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 985 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>inputs_embeds = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embed_tokens(input_ids)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 986 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 987 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>batch_size, seq_length = input_shape                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 988 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">sparse.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">62</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.padding_idx].fill_(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">160 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">161 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor) -&gt; Tensor:                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>162 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.embedding(                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.padding_idx, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.max_norm,                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.norm_type, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scale_grad_by_freq, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sparse)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">165 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2210</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">embedding</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2207 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">#   torch.embedding_renorm_</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2208 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># remove once script supports set_grad_enabled</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2209 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>_no_grad_embedding_renorm_(weight, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, max_norm, norm_type)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2210 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch.embedding(weight, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, padding_idx, scale_grad_by_freq, sparse)        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2211 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2212 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2213 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">embedding_bag</span>(                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>Expected all tensors to be on the same device, but found at least two devices, cpu and cu<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">da:0</span>! <span style=\"font-weight: bold\">(</span>when \n",
       "checking argument for argument index in method wrapper_CUDA__index_select<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m11\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m# Compute the language model score of the retrieved passages\u001b[0m                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0mprefixed_query_tuple = (prefixed_query_ids_t0,                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mprefixed_query_ids_t0_len)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m11 gold_log_probs = model.get_LLM_score(                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m12 \u001b[0m\u001b[2m│   \u001b[0mall_title_context_ids_for_t0, prefixed_query_tuple)                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m# Compute the retriever score\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0mtopk_log_probs = model.get_fine_search_result(                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mget_LLM_score\u001b[0m:\u001b[94m126\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdecoder_prefix_tensor_view = decoder_prefix_tensor_one_question[i: i + a   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m124 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m125 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m126 \u001b[2m│   │   │   │   │   \u001b[0mlm_output = language_model(input_ids=context_tensor,                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m127 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │      \u001b[0mattention_mask=attention_mask,              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m128 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │      \u001b[0mlabels=decoder_prefix_tensor_view,          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m129 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │      \u001b[0moutput_attentions=\u001b[94mFalse\u001b[0m,                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/transformers/models/t5/\u001b[0m\u001b[1;33mmodel\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33ming_t5.py\u001b[0m:\u001b[94m1679\u001b[0m in \u001b[92mforward\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1676 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Encode if needed (training, first prediction pass)\u001b[0m                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1677 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m encoder_outputs \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1678 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Convert encoder inputs in embeddings if needed\u001b[0m                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1679 \u001b[2m│   │   │   \u001b[0mencoder_outputs = \u001b[96mself\u001b[0m.encoder(                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1680 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minput_ids=input_ids,                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1681 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mattention_mask=attention_mask,                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1682 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minputs_embeds=inputs_embeds,                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/transformers/models/t5/\u001b[0m\u001b[1;33mmodel\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33ming_t5.py\u001b[0m:\u001b[94m985\u001b[0m in \u001b[92mforward\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 982 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 983 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m inputs_embeds \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 984 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m.embed_tokens \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mYou have to initialize the model with\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 985 \u001b[2m│   │   │   \u001b[0minputs_embeds = \u001b[96mself\u001b[0m.embed_tokens(input_ids)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 986 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 987 \u001b[0m\u001b[2m│   │   \u001b[0mbatch_size, seq_length = input_shape                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 988 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33msparse.py\u001b[0m:\u001b[94m1\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m62\u001b[0m in \u001b[92mforward\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.weight[\u001b[96mself\u001b[0m.padding_idx].fill_(\u001b[94m0\u001b[0m)                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m162 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m F.embedding(                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m.weight, \u001b[96mself\u001b[0m.padding_idx, \u001b[96mself\u001b[0m.max_norm,                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.norm_type, \u001b[96mself\u001b[0m.scale_grad_by_freq, \u001b[96mself\u001b[0m.sparse)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m165 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/\u001b[0m\u001b[1;33mfunctional.py\u001b[0m:\u001b[94m2210\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92membedding\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2207 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m#   torch.embedding_renorm_\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2208 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# remove once script supports set_grad_enabled\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2209 \u001b[0m\u001b[2m│   │   \u001b[0m_no_grad_embedding_renorm_(weight, \u001b[96minput\u001b[0m, max_norm, norm_type)                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2210 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m torch.embedding(weight, \u001b[96minput\u001b[0m, padding_idx, scale_grad_by_freq, sparse)        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2211 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2212 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2213 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92membedding_bag\u001b[0m(                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mExpected all tensors to be on the same device, but found at least two devices, cpu and cu\u001b[1;92mda:0\u001b[0m! \u001b[1m(\u001b[0mwhen \n",
       "checking argument for argument index in method wrapper_CUDA__index_select\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = get_args()\n",
    "topk = model.topk\n",
    "bsize, max_seq_len = query_ids_bert.shape\n",
    "\n",
    "# assert bsize == 1, \"for auto-encoder pre-training, we assume a local batch size of 1\"\n",
    "assert args.initialize_t0_model_tokenizer_evidence, \"for auto-encoder pre-training, we need to pass the argument --initialize-t0-model-and-tokenizer\"\n",
    "\n",
    "# Compute \"fresh\" query logits\n",
    "query_logits = model.retriever_embedder(query_ids_bert,\n",
    "                                        query_mask_bert,\n",
    "                                        query_types,\n",
    "                                        embedder_type=\"query\",\n",
    "                                        disable_dropout=args.disable_retriever_dropout)\n",
    "if args.no_query_embedder_training:\n",
    "    query_logits = query_logits.detach()\n",
    "\n",
    "# Get top-K evidence data for the BERT tokenized query\n",
    "with torch.no_grad():\n",
    "    topk_evidence_data, stale_topk_sim = model.evidence_retriever.get_topk(query_logits.clone().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "791d9c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------> use fixed config <----------\n",
      "---------> use fixed config <----------\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = postprocess(query_uid,topk_evidence_data)\n",
    "    all_title_context_ids_bert_tokenized, all_title_context_ids_for_t0 = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6df330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megatron.model.art_model import get_tokenizer,get_t0_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "150fddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = get_tokenizer()\n",
    "t0_tokenizer   = get_t0_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7f097b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the language model score of the retrieved passages\n",
    "decoder_prefix_tensor = torch.repeat_interleave(prefixed_query_ids_t0, topk, dim=0)\n",
    "log_prob_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1a65e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megatron import get_t0_model\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "77831814",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model = get_t0_model()\n",
    "language_model = language_model.cuda()\n",
    "\n",
    "## 按照每个 batch 来进行 inference\n",
    "for k in range(0, bsize * topk, topk):\n",
    "    log_prob_list_one_question = []\n",
    "    all_title_context_ids_one_question     = all_title_context_ids_for_t0[k: k + topk]\n",
    "    decoder_prefix_tensor_one_question     = decoder_prefix_tensor[k: k + topk]\n",
    "    prefixed_query_ids_t0_len_one_question = prefixed_query_ids_t0_len[k // topk]\n",
    "\n",
    "    ### 主要为了控制中间的计算消耗\n",
    "    for i in range(0, topk, args.shard_size):\n",
    "        all_title_context_ids_view = all_title_context_ids_one_question[i: i + args.shard_size]\n",
    "        # pad the sequences\n",
    "        input_encoding = model.t0_tokenizer.pad({'input_ids': all_title_context_ids_view},\n",
    "                                                  padding='longest',\n",
    "                                                  max_length=512,\n",
    "                                                  pad_to_multiple_of=8,\n",
    "                                                  return_attention_mask=True,\n",
    "                                                  return_tensors='pt')\n",
    "        assert input_encoding.input_ids.size(1) <= 512\n",
    "        context_tensor, attention_mask = input_encoding.input_ids.cuda(), input_encoding.attention_mask.cuda()\n",
    "        decoder_prefix_tensor_view     = decoder_prefix_tensor_one_question[i: i + args.shard_size]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            lm_output = language_model(input_ids           =context_tensor,\n",
    "                                       attention_mask      =attention_mask,\n",
    "                                       labels              =decoder_prefix_tensor_view,\n",
    "                                       output_attentions   =False,\n",
    "                                       output_hidden_states=False)\n",
    "            lm_logits = lm_output.logits.float()\n",
    "            _, decoder_seq_length, vocab_size = lm_logits.shape\n",
    "\n",
    "            log_softmax    = F.log_softmax(lm_logits, dim=-1)\n",
    "            # pick up the answer's log softmax value\n",
    "            # gather 第一行取哪几个， 第二行取哪几个\n",
    "            gold_log_probs = log_softmax.gather(2, decoder_prefix_tensor_view.unsqueeze(2)).squeeze(2)\n",
    "\n",
    "            # this will work because the batch size is 1 and this implies all decoder labels have the same length\n",
    "            teacher_log_probs = torch.mean(gold_log_probs[:, :prefixed_query_ids_t0_len_one_question], dim=1)\n",
    "            log_prob_list_one_question.append(teacher_log_probs)\n",
    "    log_prob_list_one_question = torch.cat(log_prob_list_one_question).unsqueeze(0)\n",
    "    log_prob_list.append(log_prob_list_one_question)\n",
    "\n",
    "\n",
    "gold_log_probs = torch.cat(log_prob_list, dim=0)\n",
    "\n",
    "# Compute the retriever score\n",
    "input_encoding = model.hf_bert_tokenizer.pad({'input_ids': all_title_context_ids_bert_tokenized},\n",
    "                                            padding='longest',\n",
    "                                            max_length=512,\n",
    "                                            pad_to_multiple_of=8,\n",
    "                                            return_attention_mask=True,\n",
    "                                            return_tensors='pt')\n",
    "assert input_encoding.input_ids.size(1) <= 512\n",
    "\n",
    "all_title_context_ids = input_encoding.input_ids.cuda()\n",
    "all_context_types     = torch.cuda.LongTensor(input_encoding.input_ids.size()).fill_(0)\n",
    "all_context_mask      = (all_title_context_ids[:, None, :] >= 1) * (all_title_context_ids[:, :, None] >= 1)\n",
    "\n",
    "# Inverting the mask\n",
    "all_context_mask      = ~all_context_mask\n",
    "\n",
    "# Compute \"fresh\" context logits\n",
    "all_context_logits = model.retriever_embedder(all_title_context_ids,\n",
    "                                                all_context_mask,\n",
    "                                                all_context_types,\n",
    "                                                embedder_type=\"context\",\n",
    "                                                disable_dropout=args.disable_retriever_dropout)\n",
    "all_context_logits = all_context_logits.reshape(bsize, topk, -1)\n",
    "\n",
    "if args.no_context_embedder_training:\n",
    "    all_context_logits = all_context_logits.detach()\n",
    "query_logits       = query_logits.unsqueeze(1).float()\n",
    "all_context_logits = all_context_logits.float()\n",
    "\n",
    "# [B, 1, K]\n",
    "topk_sim_scores    = torch.bmm(query_logits, all_context_logits.transpose(1, 2))\n",
    "if args.retriever_score_scaling:\n",
    "    topk_sim_scores = topk_sim_scores / (args.inverse_temperature_multiplier * math.sqrt(args.hidden_size))\n",
    "# [B, 1, K]\n",
    "topk_log_probs = F.log_softmax(topk_sim_scores, dim=2)\n",
    "# B x 1 x K -> B x K\n",
    "topk_log_probs = topk_log_probs.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "70c0bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2c39780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.module.module.evidence_retriever.local_rank = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5940183e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------> use fixed config <----------\n",
      "dsw-23976-7d79d88dc8-j998v:8547:8946 [0] NCCL INFO Using network Socket\n",
      "dsw-23976-7d79d88dc8-j998v:8547:8946 [0] NCCL INFO Channel 00/02 :    0\n",
      "dsw-23976-7d79d88dc8-j998v:8547:8946 [0] NCCL INFO Channel 01/02 :    0\n",
      "dsw-23976-7d79d88dc8-j998v:8547:8946 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1\n",
      "dsw-23976-7d79d88dc8-j998v:8547:8946 [0] NCCL INFO Connected all rings\n",
      "dsw-23976-7d79d88dc8-j998v:8547:8946 [0] NCCL INFO Connected all trees\n",
      "dsw-23976-7d79d88dc8-j998v:8547:8946 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "dsw-23976-7d79d88dc8-j998v:8547:8946 [0] NCCL INFO comm 0x786eea90 rank 0 nranks 1 cudaDev 0 busId 70 - Init COMPLETE\n",
      "---------> use fixed config <----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 train_iters, gold_log_probs = model(query_uid,                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │      </span>query_ids_bert,                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │      </span>query_types,                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │      </span>query_mask_bert,                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/model/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">distributed.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">76</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 73 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 74 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *inputs, **kwargs):                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 75 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.needs_reduction = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 76 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.module(*inputs, **kwargs)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 77 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 78 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">state_dict</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, destination=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, prefix=<span style=\"color: #808000; text-decoration-color: #808000\">''</span>, keep_vars=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>):                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 79 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">#[h.remove() for h in self.hook_handles]</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/fp16/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">fp16.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">74</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 71 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.add_module(<span style=\"color: #808000; text-decoration-color: #808000\">'module'</span>, module.half())                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 72 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 73 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *inputs, **kwargs):                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 74 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fp16_to_fp32(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.module(*(fp32_to_fp16(inputs)), **kwargs))                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 75 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 76 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">state_dict</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, destination=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, prefix=<span style=\"color: #808000; text-decoration-color: #808000\">''</span>, keep_vars=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>):                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 77 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.module.state_dict(destination, prefix, keep_vars)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/model/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">art_model.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">93</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 90 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>decoder_prefix_tensor = torch.repeat_interleave(prefixed_query_ids_t0, topk, dim   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 91 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>log_prob_list = []                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 92 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 93 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>language_model = get_t0_model()                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 94 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>language_model = language_model.cuda()                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 95 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 96 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, bsize * topk, topk):                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">global_vars.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">340</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_t0_model</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">337 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">338 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_t0_model</span>():                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">339 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Return T0 model.\"\"\"</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>340 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>_ensure_var_is_initialized(_GLOBAL_T0_MODEL, <span style=\"color: #808000; text-decoration-color: #808000\">'T0-model'</span>)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">341 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _GLOBAL_T0_MODEL                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">342 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">343 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_wikipedia_evidence</span>():                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">global_vars.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">462</span> in                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_ensure_var_is_initialized</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">459 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">460 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_ensure_var_is_initialized</span>(var, name):                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">461 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Make sure the input variable is not None.\"\"\"</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>462 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> var <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">'{} is not initialized.'</span>.format(name)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">463 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">464 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">465 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_ensure_var_is_not_initialized</span>(var, name):                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AssertionError: </span>T0-model is not initialized.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 train_iters, gold_log_probs = model(query_uid,                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │      \u001b[0mquery_ids_bert,                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │      \u001b[0mquery_types,                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │      \u001b[0mquery_mask_bert,                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/model/\u001b[0m\u001b[1;33mdistributed.py\u001b[0m:\u001b[94m76\u001b[0m in \u001b[92mforward\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 73 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 74 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, *inputs, **kwargs):                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 75 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.needs_reduction = \u001b[94mTrue\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 76 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.module(*inputs, **kwargs)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 77 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 78 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mstate_dict\u001b[0m(\u001b[96mself\u001b[0m, destination=\u001b[94mNone\u001b[0m, prefix=\u001b[33m'\u001b[0m\u001b[33m'\u001b[0m, keep_vars=\u001b[94mFalse\u001b[0m):                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 79 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m#[h.remove() for h in self.hook_handles]\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/fp16/\u001b[0m\u001b[1;33mfp16.py\u001b[0m:\u001b[94m74\u001b[0m in \u001b[92mforward\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 71 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.add_module(\u001b[33m'\u001b[0m\u001b[33mmodule\u001b[0m\u001b[33m'\u001b[0m, module.half())                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 72 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 73 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, *inputs, **kwargs):                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 74 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m fp16_to_fp32(\u001b[96mself\u001b[0m.module(*(fp32_to_fp16(inputs)), **kwargs))                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 75 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 76 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mstate_dict\u001b[0m(\u001b[96mself\u001b[0m, destination=\u001b[94mNone\u001b[0m, prefix=\u001b[33m'\u001b[0m\u001b[33m'\u001b[0m, keep_vars=\u001b[94mFalse\u001b[0m):                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 77 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.module.state_dict(destination, prefix, keep_vars)                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/zhangtianning/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/model/\u001b[0m\u001b[1;33mart_model.py\u001b[0m:\u001b[94m93\u001b[0m in \u001b[92mforward\u001b[0m      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 90 \u001b[0m\u001b[2m│   │   \u001b[0mdecoder_prefix_tensor = torch.repeat_interleave(prefixed_query_ids_t0, topk, dim   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 91 \u001b[0m\u001b[2m│   │   \u001b[0mlog_prob_list = []                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 92 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 93 \u001b[2m│   │   \u001b[0mlanguage_model = get_t0_model()                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m│   │   \u001b[0mlanguage_model = language_model.cuda()                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 96 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m k \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(\u001b[94m0\u001b[0m, bsize * topk, topk):                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/\u001b[0m\u001b[1;33mglobal_vars.py\u001b[0m:\u001b[94m340\u001b[0m in \u001b[92mget_t0_model\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m337 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m338 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mget_t0_model\u001b[0m():                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m339 \u001b[0m\u001b[2;90m│   \u001b[0m\u001b[33m\"\"\"Return T0 model.\"\"\"\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m340 \u001b[2m│   \u001b[0m_ensure_var_is_initialized(_GLOBAL_T0_MODEL, \u001b[33m'\u001b[0m\u001b[33mT0-model\u001b[0m\u001b[33m'\u001b[0m)                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m341 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _GLOBAL_T0_MODEL                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m342 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m343 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mget_wikipedia_evidence\u001b[0m():                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/mnt/data/ai4earth/zhangtianning/projects/llm/art/megatron/\u001b[0m\u001b[1;33mglobal_vars.py\u001b[0m:\u001b[94m462\u001b[0m in                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_ensure_var_is_initialized\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m459 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m460 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_ensure_var_is_initialized\u001b[0m(var, name):                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m461 \u001b[0m\u001b[2;90m│   \u001b[0m\u001b[33m\"\"\"Make sure the input variable is not None.\"\"\"\u001b[0m                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m462 \u001b[2m│   \u001b[0m\u001b[94massert\u001b[0m var \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m, \u001b[33m'\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m is not initialized.\u001b[0m\u001b[33m'\u001b[0m.format(name)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m463 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m464 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m465 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_ensure_var_is_not_initialized\u001b[0m(var, name):                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mAssertionError: \u001b[0mT0-model is not initialized.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_iters, gold_log_probs = model(query_uid,\n",
    "#                                            query_ids_bert,\n",
    "#                                            query_types,\n",
    "#                                            query_mask_bert,\n",
    "#                                            prefixed_query_ids_t0,\n",
    "#                                            prefixed_query_ids_t0_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d678c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 train_iters                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'train_iters'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 train_iters                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'train_iters'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_iters\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
