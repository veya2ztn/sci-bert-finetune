{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f090027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uniem.model import PoolingStrategy, create_uniem_embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df206472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from uniem.types import MixedPrecisionType, Tokenizer\n",
    "import pandas as pd\n",
    "from typing import Callable, Iterable, Sequence, Sized, cast\n",
    "from uniem.finetuner import FineTuner\n",
    "from uniem.training_strategy import BitFitTrainging\n",
    "from uniem.model import PoolingStrategy, create_uniem_embedder\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bed07a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uniem.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44636113",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"pretrain_weights/llama2/llama2-7b-hf/\"\n",
    "model_class=AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc8552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_strategy=PoolingStrategy.last_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0643aeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbeaf11931a42e3956c4cf53554d3e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"pretrain_weights/llama2/llama2-7b-hf/\")  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bedc71f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff349f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8b8f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,p in model.named_parameters():\n",
    "    prefix = \"->\" if 'bias' in n else \"\"\n",
    "    print(f\"{prefix}{n}->{p.shape}->{p.max()}-{p.min()}->{p.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018270f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c337d47",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight->torch.Size([32000, 4096])->0.26171875--0.13671875->torch.float32\n",
      "model.layers.0.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.72265625--0.7734375->torch.float32\n",
      "model.layers.0.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.703125--0.81640625->torch.float32\n",
      "model.layers.0.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.134765625--0.1240234375->torch.float32\n",
      "model.layers.0.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.416015625--0.451171875->torch.float32\n",
      "model.layers.0.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.7265625--0.890625->torch.float32\n",
      "model.layers.0.mlp.up_proj.weight->torch.Size([11008, 4096])->0.314453125--0.341796875->torch.float32\n",
      "model.layers.0.mlp.down_proj.weight->torch.Size([4096, 11008])->0.52734375--0.51171875->torch.float32\n",
      "model.layers.0.input_layernorm.weight->torch.Size([4096])->0.80078125--0.00092315673828125->torch.float32\n",
      "model.layers.0.post_attention_layernorm.weight->torch.Size([4096])->0.2197265625-6.341934204101562e-05->torch.float32\n",
      "model.layers.1.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.47265625--0.408203125->torch.float32\n",
      "model.layers.1.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.57421875--0.51953125->torch.float32\n",
      "model.layers.1.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.10791015625--0.1279296875->torch.float32\n",
      "model.layers.1.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.58984375--0.494140625->torch.float32\n",
      "model.layers.1.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.9765625--1.09375->torch.float32\n",
      "model.layers.1.mlp.up_proj.weight->torch.Size([11008, 4096])->0.294921875--0.40625->torch.float32\n",
      "model.layers.1.mlp.down_proj.weight->torch.Size([4096, 11008])->1.5625--1.421875->torch.float32\n",
      "model.layers.1.input_layernorm.weight->torch.Size([4096])->0.490234375--1.0073184967041016e-05->torch.float32\n",
      "model.layers.1.post_attention_layernorm.weight->torch.Size([4096])->0.197265625-0.00024127960205078125->torch.float32\n",
      "model.layers.2.self_attn.q_proj.weight->torch.Size([4096, 4096])->1.1015625--0.75390625->torch.float32\n",
      "model.layers.2.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.373046875--0.345703125->torch.float32\n",
      "model.layers.2.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.1474609375--0.1279296875->torch.float32\n",
      "model.layers.2.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.515625--0.60546875->torch.float32\n",
      "model.layers.2.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.41796875--0.52734375->torch.float32\n",
      "model.layers.2.mlp.up_proj.weight->torch.Size([11008, 4096])->0.455078125--0.310546875->torch.float32\n",
      "model.layers.2.mlp.down_proj.weight->torch.Size([4096, 11008])->0.8984375--0.66796875->torch.float32\n",
      "model.layers.2.input_layernorm.weight->torch.Size([4096])->0.49609375-4.172325134277344e-06->torch.float32\n",
      "model.layers.2.post_attention_layernorm.weight->torch.Size([4096])->0.1494140625-0.000698089599609375->torch.float32\n",
      "model.layers.3.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.78125--0.6875->torch.float32\n",
      "model.layers.3.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.32421875--0.41015625->torch.float32\n",
      "model.layers.3.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.138671875--0.1142578125->torch.float32\n",
      "model.layers.3.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.470703125--0.5390625->torch.float32\n",
      "model.layers.3.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.578125--0.451171875->torch.float32\n",
      "model.layers.3.mlp.up_proj.weight->torch.Size([11008, 4096])->0.50390625--0.451171875->torch.float32\n",
      "model.layers.3.mlp.down_proj.weight->torch.Size([4096, 11008])->0.68359375--0.66796875->torch.float32\n",
      "model.layers.3.input_layernorm.weight->torch.Size([4096])->0.59765625--0.0001316070556640625->torch.float32\n",
      "model.layers.3.post_attention_layernorm.weight->torch.Size([4096])->0.1865234375--8.487701416015625e-05->torch.float32\n",
      "model.layers.4.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.63671875--0.67578125->torch.float32\n",
      "model.layers.4.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.51171875--0.30859375->torch.float32\n",
      "model.layers.4.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.11865234375--0.142578125->torch.float32\n",
      "model.layers.4.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.52734375--0.62109375->torch.float32\n",
      "model.layers.4.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.44921875--0.51953125->torch.float32\n",
      "model.layers.4.mlp.up_proj.weight->torch.Size([11008, 4096])->0.353515625--0.478515625->torch.float32\n",
      "model.layers.4.mlp.down_proj.weight->torch.Size([4096, 11008])->0.80859375--0.9765625->torch.float32\n",
      "model.layers.4.input_layernorm.weight->torch.Size([4096])->0.63671875--4.506111145019531e-05->torch.float32\n",
      "model.layers.4.post_attention_layernorm.weight->torch.Size([4096])->0.1982421875-0.0230712890625->torch.float32\n",
      "model.layers.5.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.640625--0.59375->torch.float32\n",
      "model.layers.5.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.333984375--0.33203125->torch.float32\n",
      "model.layers.5.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.1669921875--0.265625->torch.float32\n",
      "model.layers.5.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.4453125--0.52734375->torch.float32\n",
      "model.layers.5.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.3359375--0.443359375->torch.float32\n",
      "model.layers.5.mlp.up_proj.weight->torch.Size([11008, 4096])->0.423828125--0.490234375->torch.float32\n",
      "model.layers.5.mlp.down_proj.weight->torch.Size([4096, 11008])->0.5625--0.734375->torch.float32\n",
      "model.layers.5.input_layernorm.weight->torch.Size([4096])->0.57421875--8.0108642578125e-05->torch.float32\n",
      "model.layers.5.post_attention_layernorm.weight->torch.Size([4096])->0.2177734375-0.019775390625->torch.float32\n",
      "model.layers.6.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.61328125--0.578125->torch.float32\n",
      "model.layers.6.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.30859375--0.263671875->torch.float32\n",
      "model.layers.6.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.27734375--0.287109375->torch.float32\n",
      "model.layers.6.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.53515625--0.60546875->torch.float32\n",
      "model.layers.6.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.41796875--0.37109375->torch.float32\n",
      "model.layers.6.mlp.up_proj.weight->torch.Size([11008, 4096])->0.56640625--0.337890625->torch.float32\n",
      "model.layers.6.mlp.down_proj.weight->torch.Size([4096, 11008])->0.7265625--0.921875->torch.float32\n",
      "model.layers.6.input_layernorm.weight->torch.Size([4096])->0.65625-6.532669067382812e-05->torch.float32\n",
      "model.layers.6.post_attention_layernorm.weight->torch.Size([4096])->0.228515625-0.037353515625->torch.float32\n",
      "model.layers.7.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.7578125--0.5625->torch.float32\n",
      "model.layers.7.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.31640625--0.25390625->torch.float32\n",
      "model.layers.7.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.224609375--0.2255859375->torch.float32\n",
      "model.layers.7.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.40625--0.55859375->torch.float32\n",
      "model.layers.7.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.427734375--0.455078125->torch.float32\n",
      "model.layers.7.mlp.up_proj.weight->torch.Size([11008, 4096])->0.35546875--0.3359375->torch.float32\n",
      "model.layers.7.mlp.down_proj.weight->torch.Size([4096, 11008])->0.70703125--0.9453125->torch.float32\n",
      "model.layers.7.input_layernorm.weight->torch.Size([4096])->0.6796875--0.0002040863037109375->torch.float32\n",
      "model.layers.7.post_attention_layernorm.weight->torch.Size([4096])->0.244140625-0.049072265625->torch.float32\n",
      "model.layers.8.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.470703125--0.55859375->torch.float32\n",
      "model.layers.8.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.29296875--0.30859375->torch.float32\n",
      "model.layers.8.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.19140625--0.2080078125->torch.float32\n",
      "model.layers.8.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.75390625--0.60546875->torch.float32\n",
      "model.layers.8.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.318359375--0.390625->torch.float32\n",
      "model.layers.8.mlp.up_proj.weight->torch.Size([11008, 4096])->0.6484375--0.435546875->torch.float32\n",
      "model.layers.8.mlp.down_proj.weight->torch.Size([4096, 11008])->0.76171875--0.796875->torch.float32\n",
      "model.layers.8.input_layernorm.weight->torch.Size([4096])->0.7109375-5.269050598144531e-05->torch.float32\n",
      "model.layers.8.post_attention_layernorm.weight->torch.Size([4096])->0.25390625-0.0537109375->torch.float32\n",
      "model.layers.9.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.44140625--0.77734375->torch.float32\n",
      "model.layers.9.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.263671875--0.35546875->torch.float32\n",
      "model.layers.9.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.203125--0.2470703125->torch.float32\n",
      "model.layers.9.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.5078125--0.546875->torch.float32\n",
      "model.layers.9.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.375--0.357421875->torch.float32\n",
      "model.layers.9.mlp.up_proj.weight->torch.Size([11008, 4096])->0.609375--0.380859375->torch.float32\n",
      "model.layers.9.mlp.down_proj.weight->torch.Size([4096, 11008])->0.640625--0.6640625->torch.float32\n",
      "model.layers.9.input_layernorm.weight->torch.Size([4096])->0.71484375-2.9921531677246094e-05->torch.float32\n",
      "model.layers.9.post_attention_layernorm.weight->torch.Size([4096])->0.2578125-0.055419921875->torch.float32\n",
      "model.layers.10.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.462890625--0.462890625->torch.float32\n",
      "model.layers.10.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.29296875--0.26953125->torch.float32\n",
      "model.layers.10.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.259765625--0.2041015625->torch.float32\n",
      "model.layers.10.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.404296875--0.4140625->torch.float32\n",
      "model.layers.10.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.373046875--0.52734375->torch.float32\n",
      "model.layers.10.mlp.up_proj.weight->torch.Size([11008, 4096])->0.2353515625--0.392578125->torch.float32\n",
      "model.layers.10.mlp.down_proj.weight->torch.Size([4096, 11008])->1.0234375--0.74609375->torch.float32\n",
      "model.layers.10.input_layernorm.weight->torch.Size([4096])->0.73828125-0.00010919570922851562->torch.float32\n",
      "model.layers.10.post_attention_layernorm.weight->torch.Size([4096])->0.263671875-0.058349609375->torch.float32\n",
      "model.layers.11.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.609375--0.419921875->torch.float32\n",
      "model.layers.11.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.271484375--0.279296875->torch.float32\n",
      "model.layers.11.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.267578125--0.298828125->torch.float32\n",
      "model.layers.11.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.578125--0.54296875->torch.float32\n",
      "model.layers.11.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.314453125--0.40234375->torch.float32\n",
      "model.layers.11.mlp.up_proj.weight->torch.Size([11008, 4096])->0.41796875--0.423828125->torch.float32\n",
      "model.layers.11.mlp.down_proj.weight->torch.Size([4096, 11008])->0.640625--0.765625->torch.float32\n",
      "model.layers.11.input_layernorm.weight->torch.Size([4096])->0.79296875-7.677078247070312e-05->torch.float32\n",
      "model.layers.11.post_attention_layernorm.weight->torch.Size([4096])->0.267578125-0.0546875->torch.float32\n",
      "model.layers.12.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.5234375--0.4609375->torch.float32\n",
      "model.layers.12.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.2578125--0.298828125->torch.float32\n",
      "model.layers.12.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.251953125--0.1904296875->torch.float32\n",
      "model.layers.12.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.50390625--0.51953125->torch.float32\n",
      "model.layers.12.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.35546875--0.33984375->torch.float32\n",
      "model.layers.12.mlp.up_proj.weight->torch.Size([11008, 4096])->0.24609375--0.2412109375->torch.float32\n",
      "model.layers.12.mlp.down_proj.weight->torch.Size([4096, 11008])->0.6484375--0.58984375->torch.float32\n",
      "model.layers.12.input_layernorm.weight->torch.Size([4096])->0.78515625-8.106231689453125e-05->torch.float32\n",
      "model.layers.12.post_attention_layernorm.weight->torch.Size([4096])->0.275390625-0.0634765625->torch.float32\n",
      "model.layers.13.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.6796875--0.421875->torch.float32\n",
      "model.layers.13.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.30078125--0.26171875->torch.float32\n",
      "model.layers.13.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.22265625--0.2294921875->torch.float32\n",
      "model.layers.13.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.5078125--0.462890625->torch.float32\n",
      "model.layers.13.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.3671875--0.31640625->torch.float32\n",
      "model.layers.13.mlp.up_proj.weight->torch.Size([11008, 4096])->0.416015625--0.431640625->torch.float32\n",
      "model.layers.13.mlp.down_proj.weight->torch.Size([4096, 11008])->1.0703125--0.61328125->torch.float32\n",
      "model.layers.13.input_layernorm.weight->torch.Size([4096])->0.71875--3.695487976074219e-05->torch.float32\n",
      "model.layers.13.post_attention_layernorm.weight->torch.Size([4096])->0.283203125-0.064453125->torch.float32\n",
      "model.layers.14.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.54296875--0.5703125->torch.float32\n",
      "model.layers.14.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.25390625--0.314453125->torch.float32\n",
      "model.layers.14.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.333984375--0.17578125->torch.float32\n",
      "model.layers.14.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.5390625--0.59765625->torch.float32\n",
      "model.layers.14.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.341796875--0.31640625->torch.float32\n",
      "model.layers.14.mlp.up_proj.weight->torch.Size([11008, 4096])->0.4765625--0.22265625->torch.float32\n",
      "model.layers.14.mlp.down_proj.weight->torch.Size([4096, 11008])->0.66015625--0.578125->torch.float32\n",
      "model.layers.14.input_layernorm.weight->torch.Size([4096])->0.7890625-0.00011110305786132812->torch.float32\n",
      "model.layers.14.post_attention_layernorm.weight->torch.Size([4096])->0.29296875-0.060302734375->torch.float32\n",
      "model.layers.15.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.58203125--0.55859375->torch.float32\n",
      "model.layers.15.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.259765625--0.255859375->torch.float32\n",
      "model.layers.15.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.2265625--0.2021484375->torch.float32\n",
      "model.layers.15.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.3828125--0.48828125->torch.float32\n",
      "model.layers.15.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.431640625--0.310546875->torch.float32\n",
      "model.layers.15.mlp.up_proj.weight->torch.Size([11008, 4096])->0.44140625--0.302734375->torch.float32\n",
      "model.layers.15.mlp.down_proj.weight->torch.Size([4096, 11008])->0.62890625--1.0625->torch.float32\n",
      "model.layers.15.input_layernorm.weight->torch.Size([4096])->0.84765625-0.027587890625->torch.float32\n",
      "model.layers.15.post_attention_layernorm.weight->torch.Size([4096])->0.3046875-0.0703125->torch.float32\n",
      "model.layers.16.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.7578125--1.0->torch.float32\n",
      "model.layers.16.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.2734375--0.2890625->torch.float32\n",
      "model.layers.16.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.2421875--0.2060546875->torch.float32\n",
      "model.layers.16.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.39453125--0.42578125->torch.float32\n",
      "model.layers.16.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.369140625--0.474609375->torch.float32\n",
      "model.layers.16.mlp.up_proj.weight->torch.Size([11008, 4096])->0.365234375--0.462890625->torch.float32\n",
      "model.layers.16.mlp.down_proj.weight->torch.Size([4096, 11008])->0.474609375--0.76953125->torch.float32\n",
      "model.layers.16.input_layernorm.weight->torch.Size([4096])->0.8359375-0.0245361328125->torch.float32\n",
      "model.layers.16.post_attention_layernorm.weight->torch.Size([4096])->0.322265625-0.0673828125->torch.float32\n",
      "model.layers.17.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.9453125--0.796875->torch.float32\n",
      "model.layers.17.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.279296875--0.306640625->torch.float32\n",
      "model.layers.17.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.2138671875--0.1962890625->torch.float32\n",
      "model.layers.17.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.498046875--0.490234375->torch.float32\n",
      "model.layers.17.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.34375--0.404296875->torch.float32\n",
      "model.layers.17.mlp.up_proj.weight->torch.Size([11008, 4096])->0.33984375--0.2734375->torch.float32\n",
      "model.layers.17.mlp.down_proj.weight->torch.Size([4096, 11008])->0.546875--1.1484375->torch.float32\n",
      "model.layers.17.input_layernorm.weight->torch.Size([4096])->0.79296875-1.4901161193847656e-06->torch.float32\n",
      "model.layers.17.post_attention_layernorm.weight->torch.Size([4096])->0.341796875-0.051025390625->torch.float32\n",
      "model.layers.18.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.6796875--0.7734375->torch.float32\n",
      "model.layers.18.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.3125--0.3125->torch.float32\n",
      "model.layers.18.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.2021484375--0.224609375->torch.float32\n",
      "model.layers.18.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.56640625--0.55859375->torch.float32\n",
      "model.layers.18.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.369140625--0.357421875->torch.float32\n",
      "model.layers.18.mlp.up_proj.weight->torch.Size([11008, 4096])->0.326171875--0.169921875->torch.float32\n",
      "model.layers.18.mlp.down_proj.weight->torch.Size([4096, 11008])->0.65625--1.1015625->torch.float32\n",
      "model.layers.18.input_layernorm.weight->torch.Size([4096])->0.87109375-1.138448715209961e-05->torch.float32\n",
      "model.layers.18.post_attention_layernorm.weight->torch.Size([4096])->0.359375-0.05908203125->torch.float32\n",
      "model.layers.19.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.66796875--0.71875->torch.float32\n",
      "model.layers.19.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.2890625--0.298828125->torch.float32\n",
      "model.layers.19.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.2236328125--0.138671875->torch.float32\n",
      "model.layers.19.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.67578125--0.6015625->torch.float32\n",
      "model.layers.19.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.349609375--0.38671875->torch.float32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.19.mlp.up_proj.weight->torch.Size([11008, 4096])->0.486328125--0.5703125->torch.float32\n",
      "model.layers.19.mlp.down_proj.weight->torch.Size([4096, 11008])->0.68359375--0.96875->torch.float32\n",
      "model.layers.19.input_layernorm.weight->torch.Size([4096])->0.8515625-5.2928924560546875e-05->torch.float32\n",
      "model.layers.19.post_attention_layernorm.weight->torch.Size([4096])->0.369140625-0.06591796875->torch.float32\n",
      "model.layers.20.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.8828125--1.0546875->torch.float32\n",
      "model.layers.20.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.328125--0.328125->torch.float32\n",
      "model.layers.20.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.126953125--0.1630859375->torch.float32\n",
      "model.layers.20.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.57421875--0.578125->torch.float32\n",
      "model.layers.20.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.287109375--0.322265625->torch.float32\n",
      "model.layers.20.mlp.up_proj.weight->torch.Size([11008, 4096])->0.30859375--0.318359375->torch.float32\n",
      "model.layers.20.mlp.down_proj.weight->torch.Size([4096, 11008])->1.109375--0.55078125->torch.float32\n",
      "model.layers.20.input_layernorm.weight->torch.Size([4096])->0.8515625-1.0073184967041016e-05->torch.float32\n",
      "model.layers.20.post_attention_layernorm.weight->torch.Size([4096])->0.3828125-0.052001953125->torch.float32\n",
      "model.layers.21.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.94140625--0.71484375->torch.float32\n",
      "model.layers.21.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.375--0.310546875->torch.float32\n",
      "model.layers.21.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.1796875--0.1728515625->torch.float32\n",
      "model.layers.21.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.5390625--0.55078125->torch.float32\n",
      "model.layers.21.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.28515625--0.296875->torch.float32\n",
      "model.layers.21.mlp.up_proj.weight->torch.Size([11008, 4096])->0.201171875--0.2333984375->torch.float32\n",
      "model.layers.21.mlp.down_proj.weight->torch.Size([4096, 11008])->0.734375--0.7109375->torch.float32\n",
      "model.layers.21.input_layernorm.weight->torch.Size([4096])->0.8671875--3.2901763916015625e-05->torch.float32\n",
      "model.layers.21.post_attention_layernorm.weight->torch.Size([4096])->0.39453125-0.048828125->torch.float32\n",
      "model.layers.22.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.875--0.5859375->torch.float32\n",
      "model.layers.22.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.287109375--0.31640625->torch.float32\n",
      "model.layers.22.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.1025390625--0.154296875->torch.float32\n",
      "model.layers.22.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.7734375--0.7421875->torch.float32\n",
      "model.layers.22.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.37109375--0.34375->torch.float32\n",
      "model.layers.22.mlp.up_proj.weight->torch.Size([11008, 4096])->0.275390625--0.177734375->torch.float32\n",
      "model.layers.22.mlp.down_proj.weight->torch.Size([4096, 11008])->0.33203125--0.388671875->torch.float32\n",
      "model.layers.22.input_layernorm.weight->torch.Size([4096])->1.0234375--0.00012493133544921875->torch.float32\n",
      "model.layers.22.post_attention_layernorm.weight->torch.Size([4096])->0.40625-0.044921875->torch.float32\n",
      "model.layers.23.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.69140625--0.81640625->torch.float32\n",
      "model.layers.23.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.3125--0.2890625->torch.float32\n",
      "model.layers.23.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.13671875--0.1533203125->torch.float32\n",
      "model.layers.23.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.484375--0.484375->torch.float32\n",
      "model.layers.23.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.416015625--0.361328125->torch.float32\n",
      "model.layers.23.mlp.up_proj.weight->torch.Size([11008, 4096])->0.2255859375--0.296875->torch.float32\n",
      "model.layers.23.mlp.down_proj.weight->torch.Size([4096, 11008])->1.3125--0.60546875->torch.float32\n",
      "model.layers.23.input_layernorm.weight->torch.Size([4096])->1.0078125-7.772445678710938e-05->torch.float32\n",
      "model.layers.23.post_attention_layernorm.weight->torch.Size([4096])->0.41796875-0.05078125->torch.float32\n",
      "model.layers.24.self_attn.q_proj.weight->torch.Size([4096, 4096])->1.03125--0.59765625->torch.float32\n",
      "model.layers.24.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.296875--0.330078125->torch.float32\n",
      "model.layers.24.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.1845703125--0.1103515625->torch.float32\n",
      "model.layers.24.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.65234375--0.73046875->torch.float32\n",
      "model.layers.24.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.306640625--0.34765625->torch.float32\n",
      "model.layers.24.mlp.up_proj.weight->torch.Size([11008, 4096])->0.1982421875--0.197265625->torch.float32\n",
      "model.layers.24.mlp.down_proj.weight->torch.Size([4096, 11008])->0.7265625--0.6640625->torch.float32\n",
      "model.layers.24.input_layernorm.weight->torch.Size([4096])->1.0234375-0.0001544952392578125->torch.float32\n",
      "model.layers.24.post_attention_layernorm.weight->torch.Size([4096])->0.43359375-0.050537109375->torch.float32\n",
      "model.layers.25.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.58203125--0.64453125->torch.float32\n",
      "model.layers.25.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.365234375--0.283203125->torch.float32\n",
      "model.layers.25.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.1259765625--0.1259765625->torch.float32\n",
      "model.layers.25.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.65234375--0.439453125->torch.float32\n",
      "model.layers.25.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.455078125--0.5546875->torch.float32\n",
      "model.layers.25.mlp.up_proj.weight->torch.Size([11008, 4096])->0.251953125--0.2392578125->torch.float32\n",
      "model.layers.25.mlp.down_proj.weight->torch.Size([4096, 11008])->0.322265625--1.03125->torch.float32\n",
      "model.layers.25.input_layernorm.weight->torch.Size([4096])->1.015625-4.3392181396484375e-05->torch.float32\n",
      "model.layers.25.post_attention_layernorm.weight->torch.Size([4096])->0.4453125-0.0634765625->torch.float32\n",
      "model.layers.26.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.6875--0.86328125->torch.float32\n",
      "model.layers.26.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.35546875--0.345703125->torch.float32\n",
      "model.layers.26.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.1962890625--0.1787109375->torch.float32\n",
      "model.layers.26.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.62890625--0.6875->torch.float32\n",
      "model.layers.26.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.30078125--0.408203125->torch.float32\n",
      "model.layers.26.mlp.up_proj.weight->torch.Size([11008, 4096])->0.2578125--0.3671875->torch.float32\n",
      "model.layers.26.mlp.down_proj.weight->torch.Size([4096, 11008])->0.578125--0.396484375->torch.float32\n",
      "model.layers.26.input_layernorm.weight->torch.Size([4096])->1.171875-3.2901763916015625e-05->torch.float32\n",
      "model.layers.26.post_attention_layernorm.weight->torch.Size([4096])->0.4609375-0.05029296875->torch.float32\n",
      "model.layers.27.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.70703125--0.79296875->torch.float32\n",
      "model.layers.27.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.2890625--0.28125->torch.float32\n",
      "model.layers.27.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.1328125--0.1201171875->torch.float32\n",
      "model.layers.27.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.6328125--0.5625->torch.float32\n",
      "model.layers.27.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.298828125--0.6328125->torch.float32\n",
      "model.layers.27.mlp.up_proj.weight->torch.Size([11008, 4096])->0.2255859375--0.345703125->torch.float32\n",
      "model.layers.27.mlp.down_proj.weight->torch.Size([4096, 11008])->0.50390625--0.76171875->torch.float32\n",
      "model.layers.27.input_layernorm.weight->torch.Size([4096])->1.1953125--6.198883056640625e-05->torch.float32\n",
      "model.layers.27.post_attention_layernorm.weight->torch.Size([4096])->0.470703125-0.047119140625->torch.float32\n",
      "model.layers.28.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.62890625--0.76953125->torch.float32\n",
      "model.layers.28.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.322265625--0.369140625->torch.float32\n",
      "model.layers.28.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.1669921875--0.1630859375->torch.float32\n",
      "model.layers.28.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.390625--0.78125->torch.float32\n",
      "model.layers.28.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.287109375--0.3984375->torch.float32\n",
      "model.layers.28.mlp.up_proj.weight->torch.Size([11008, 4096])->0.279296875--0.376953125->torch.float32\n",
      "model.layers.28.mlp.down_proj.weight->torch.Size([4096, 11008])->0.56640625--1.0->torch.float32\n",
      "model.layers.28.input_layernorm.weight->torch.Size([4096])->1.1484375-0.00012302398681640625->torch.float32\n",
      "model.layers.28.post_attention_layernorm.weight->torch.Size([4096])->0.49609375-0.06005859375->torch.float32\n",
      "model.layers.29.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.81640625--0.7421875->torch.float32\n",
      "model.layers.29.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.328125--0.3671875->torch.float32\n",
      "model.layers.29.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.1240234375--0.130859375->torch.float32\n",
      "model.layers.29.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.6328125--0.5859375->torch.float32\n",
      "model.layers.29.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.46484375--0.384765625->torch.float32\n",
      "model.layers.29.mlp.up_proj.weight->torch.Size([11008, 4096])->0.546875--0.51171875->torch.float32\n",
      "model.layers.29.mlp.down_proj.weight->torch.Size([4096, 11008])->0.498046875--0.984375->torch.float32\n",
      "model.layers.29.input_layernorm.weight->torch.Size([4096])->1.1640625-0.01177978515625->torch.float32\n",
      "model.layers.29.post_attention_layernorm.weight->torch.Size([4096])->0.55859375-0.060302734375->torch.float32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.30.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.81640625--0.75->torch.float32\n",
      "model.layers.30.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.369140625--0.34375->torch.float32\n",
      "model.layers.30.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.5--0.43359375->torch.float32\n",
      "model.layers.30.self_attn.o_proj.weight->torch.Size([4096, 4096])->0.625--0.51953125->torch.float32\n",
      "model.layers.30.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.7109375--0.796875->torch.float32\n",
      "model.layers.30.mlp.up_proj.weight->torch.Size([11008, 4096])->0.7109375--0.77734375->torch.float32\n",
      "model.layers.30.mlp.down_proj.weight->torch.Size([4096, 11008])->1.046875--1.3046875->torch.float32\n",
      "model.layers.30.input_layernorm.weight->torch.Size([4096])->1.125--8.153915405273438e-05->torch.float32\n",
      "model.layers.30.post_attention_layernorm.weight->torch.Size([4096])->0.6171875-0.08935546875->torch.float32\n",
      "model.layers.31.self_attn.q_proj.weight->torch.Size([4096, 4096])->0.41796875--0.66796875->torch.float32\n",
      "model.layers.31.self_attn.k_proj.weight->torch.Size([4096, 4096])->0.404296875--0.400390625->torch.float32\n",
      "model.layers.31.self_attn.v_proj.weight->torch.Size([4096, 4096])->0.3828125--0.390625->torch.float32\n",
      "model.layers.31.self_attn.o_proj.weight->torch.Size([4096, 4096])->1.3125--1.2734375->torch.float32\n",
      "model.layers.31.mlp.gate_proj.weight->torch.Size([11008, 4096])->0.30859375--0.380859375->torch.float32\n",
      "model.layers.31.mlp.up_proj.weight->torch.Size([11008, 4096])->0.578125--0.75390625->torch.float32\n",
      "model.layers.31.mlp.down_proj.weight->torch.Size([4096, 11008])->1.7734375--1.40625->torch.float32\n",
      "model.layers.31.input_layernorm.weight->torch.Size([4096])->1.1171875-0.083984375->torch.float32\n",
      "model.layers.31.post_attention_layernorm.weight->torch.Size([4096])->0.68359375-0.11474609375->torch.float32\n",
      "model.norm.weight->torch.Size([4096])->2.859375-0.0021209716796875->torch.float32\n",
      "lm_head.weight->torch.Size([32000, 4096])->0.34765625--0.3046875->torch.float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for n,p in model.named_parameters():\n",
    "    prefix = \"->\" if 'bias' in n else \"\"\n",
    "    print(f\"{prefix}{n}->{p.shape}->{p.max()}-{p.min()}->{p.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7d920f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
